
Random seeds have been fixed as 42


Random seeds have been fixed as 42

Indice of mice to load: ['01', '02', '03', '05']
136
Time (id:0): tot 00:00:00, prev 00:00:00 [hh:mm:ss]: Reporter has been initialized.

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8506301 (0.0%)]	Loss: 0.359758
Train Epoch: 1 [52224/8506301 (0.6%)]	Loss: 0.175087
Train Epoch: 1 [103424/8506301 (1.2%)]	Loss: 0.150161
Train Epoch: 1 [154624/8506301 (1.8%)]	Loss: 0.148663
Train Epoch: 1 [205824/8506301 (2.4%)]	Loss: 0.130479
Train Epoch: 1 [257024/8506301 (3.0%)]	Loss: 0.133226
Train Epoch: 1 [308224/8506301 (3.6%)]	Loss: 0.143746
Train Epoch: 1 [359424/8506301 (4.2%)]	Loss: 0.133144
Train Epoch: 1 [410624/8506301 (4.8%)]	Loss: 0.136611
Train Epoch: 1 [461824/8506301 (5.4%)]	Loss: 0.139554
Train Epoch: 1 [513024/8506301 (6.0%)]	Loss: 0.138296
Train Epoch: 1 [564224/8506301 (6.6%)]	Loss: 0.150966
Train Epoch: 1 [615424/8506301 (7.2%)]	Loss: 0.148027
Train Epoch: 1 [666624/8506301 (7.8%)]	Loss: 0.147823
Train Epoch: 1 [717824/8506301 (8.4%)]	Loss: 0.119277
Train Epoch: 1 [769024/8506301 (9.0%)]	Loss: 0.117992
Train Epoch: 1 [820224/8506301 (9.6%)]	Loss: 0.123552
Train Epoch: 1 [871424/8506301 (10.2%)]	Loss: 0.141422
Train Epoch: 1 [922624/8506301 (10.8%)]	Loss: 0.124228
Train Epoch: 1 [973824/8506301 (11.4%)]	Loss: 0.130881
Train Epoch: 1 [1025024/8506301 (12.1%)]	Loss: 0.129302
Train Epoch: 1 [1076224/8506301 (12.7%)]	Loss: 0.123196
Train Epoch: 1 [1127424/8506301 (13.3%)]	Loss: 0.119878
Train Epoch: 1 [1178624/8506301 (13.9%)]	Loss: 0.134082
Train Epoch: 1 [1229824/8506301 (14.5%)]	Loss: 0.137007
Train Epoch: 1 [1281024/8506301 (15.1%)]	Loss: 0.118978
Train Epoch: 1 [1332224/8506301 (15.7%)]	Loss: 0.132010
Train Epoch: 1 [1383424/8506301 (16.3%)]	Loss: 0.133144
Train Epoch: 1 [1434624/8506301 (16.9%)]	Loss: 0.123291
Train Epoch: 1 [1485824/8506301 (17.5%)]	Loss: 0.134399
Train Epoch: 1 [1537024/8506301 (18.1%)]	Loss: 0.146830
Train Epoch: 1 [1588224/8506301 (18.7%)]	Loss: 0.129387
Train Epoch: 1 [1639424/8506301 (19.3%)]	Loss: 0.117318
Train Epoch: 1 [1690624/8506301 (19.9%)]	Loss: 0.128631
Train Epoch: 1 [1741824/8506301 (20.5%)]	Loss: 0.115489
Train Epoch: 1 [1793024/8506301 (21.1%)]	Loss: 0.137838
Train Epoch: 1 [1844224/8506301 (21.7%)]	Loss: 0.141112
Train Epoch: 1 [1895424/8506301 (22.3%)]	Loss: 0.129534
Train Epoch: 1 [1946624/8506301 (22.9%)]	Loss: 0.121264
Train Epoch: 1 [1997824/8506301 (23.5%)]	Loss: 0.124105
Train Epoch: 1 [2049024/8506301 (24.1%)]	Loss: 0.135304
Train Epoch: 1 [2100224/8506301 (24.7%)]	Loss: 0.136516
Train Epoch: 1 [2151424/8506301 (25.3%)]	Loss: 0.122095
Train Epoch: 1 [2202624/8506301 (25.9%)]	Loss: 0.129777
Train Epoch: 1 [2253824/8506301 (26.5%)]	Loss: 0.133219
Train Epoch: 1 [2305024/8506301 (27.1%)]	Loss: 0.127278
Train Epoch: 1 [2356224/8506301 (27.7%)]	Loss: 0.129739
Train Epoch: 1 [2407424/8506301 (28.3%)]	Loss: 0.137930
Train Epoch: 1 [2458624/8506301 (28.9%)]	Loss: 0.113937
Train Epoch: 1 [2509824/8506301 (29.5%)]	Loss: 0.132193
Train Epoch: 1 [2561024/8506301 (30.1%)]	Loss: 0.131673
Train Epoch: 1 [2612224/8506301 (30.7%)]	Loss: 0.120616
Train Epoch: 1 [2663424/8506301 (31.3%)]	Loss: 0.130552
Train Epoch: 1 [2714624/8506301 (31.9%)]	Loss: 0.104548
Train Epoch: 1 [2765824/8506301 (32.5%)]	Loss: 0.125939
Train Epoch: 1 [2817024/8506301 (33.1%)]	Loss: 0.119072
Train Epoch: 1 [2868224/8506301 (33.7%)]	Loss: 0.109475
Train Epoch: 1 [2919424/8506301 (34.3%)]	Loss: 0.126498
Train Epoch: 1 [2970624/8506301 (34.9%)]	Loss: 0.133311
Train Epoch: 1 [3021824/8506301 (35.5%)]	Loss: 0.133702
Train Epoch: 1 [3073024/8506301 (36.1%)]	Loss: 0.128017
Train Epoch: 1 [3124224/8506301 (36.7%)]	Loss: 0.128185
Train Epoch: 1 [3175424/8506301 (37.3%)]	Loss: 0.124302
Train Epoch: 1 [3226624/8506301 (37.9%)]	Loss: 0.119306
Train Epoch: 1 [3277824/8506301 (38.5%)]	Loss: 0.125366
Train Epoch: 1 [3329024/8506301 (39.1%)]	Loss: 0.113033
Train Epoch: 1 [3380224/8506301 (39.7%)]	Loss: 0.120847
Train Epoch: 1 [3431424/8506301 (40.3%)]	Loss: 0.127960
Train Epoch: 1 [3482624/8506301 (40.9%)]	Loss: 0.130700
Train Epoch: 1 [3533824/8506301 (41.5%)]	Loss: 0.110292
Train Epoch: 1 [3585024/8506301 (42.1%)]	Loss: 0.123921
Train Epoch: 1 [3636224/8506301 (42.7%)]	Loss: 0.127085
Train Epoch: 1 [3687424/8506301 (43.3%)]	Loss: 0.132335
Train Epoch: 1 [3738624/8506301 (44.0%)]	Loss: 0.130494
Train Epoch: 1 [3789824/8506301 (44.6%)]	Loss: 0.125060
Train Epoch: 1 [3841024/8506301 (45.2%)]	Loss: 0.131924
Train Epoch: 1 [3892224/8506301 (45.8%)]	Loss: 0.126927
Train Epoch: 1 [3943424/8506301 (46.4%)]	Loss: 0.126007
Train Epoch: 1 [3994624/8506301 (47.0%)]	Loss: 0.129235
Train Epoch: 1 [4045824/8506301 (47.6%)]	Loss: 0.120607
Train Epoch: 1 [4097024/8506301 (48.2%)]	Loss: 0.118837
Train Epoch: 1 [4148224/8506301 (48.8%)]	Loss: 0.124671
Train Epoch: 1 [4199424/8506301 (49.4%)]	Loss: 0.137177
Train Epoch: 1 [4250624/8506301 (50.0%)]	Loss: 0.146034
Train Epoch: 1 [4301824/8506301 (50.6%)]	Loss: 0.130995
Train Epoch: 1 [4353024/8506301 (51.2%)]	Loss: 0.137273
Train Epoch: 1 [4404224/8506301 (51.8%)]	Loss: 0.127071
Train Epoch: 1 [4455424/8506301 (52.4%)]	Loss: 0.114210
Train Epoch: 1 [4506624/8506301 (53.0%)]	Loss: 0.121327
Train Epoch: 1 [4557824/8506301 (53.6%)]	Loss: 0.133650
Train Epoch: 1 [4609024/8506301 (54.2%)]	Loss: 0.126203
Train Epoch: 1 [4660224/8506301 (54.8%)]	Loss: 0.115566
Train Epoch: 1 [4711424/8506301 (55.4%)]	Loss: 0.117002
Train Epoch: 1 [4762624/8506301 (56.0%)]	Loss: 0.121835
Train Epoch: 1 [4813824/8506301 (56.6%)]	Loss: 0.132581
Train Epoch: 1 [4865024/8506301 (57.2%)]	Loss: 0.127610
Train Epoch: 1 [4916224/8506301 (57.8%)]	Loss: 0.132094
Train Epoch: 1 [4967424/8506301 (58.4%)]	Loss: 0.120243
Train Epoch: 1 [5018624/8506301 (59.0%)]	Loss: 0.151340
Train Epoch: 1 [5069824/8506301 (59.6%)]	Loss: 0.122607
Train Epoch: 1 [5121024/8506301 (60.2%)]	Loss: 0.127328
Train Epoch: 1 [5172224/8506301 (60.8%)]	Loss: 0.110070
Train Epoch: 1 [5223424/8506301 (61.4%)]	Loss: 0.118244
Train Epoch: 1 [5274624/8506301 (62.0%)]	Loss: 0.126072
Train Epoch: 1 [5325824/8506301 (62.6%)]	Loss: 0.127617
Train Epoch: 1 [5377024/8506301 (63.2%)]	Loss: 0.136274
Train Epoch: 1 [5428224/8506301 (63.8%)]	Loss: 0.116347
Train Epoch: 1 [5479424/8506301 (64.4%)]	Loss: 0.127940
Train Epoch: 1 [5530624/8506301 (65.0%)]	Loss: 0.117566
Train Epoch: 1 [5581824/8506301 (65.6%)]	Loss: 0.124130
Train Epoch: 1 [5633024/8506301 (66.2%)]	Loss: 0.104475
Train Epoch: 1 [5684224/8506301 (66.8%)]	Loss: 0.124605
Train Epoch: 1 [5735424/8506301 (67.4%)]	Loss: 0.132578
Train Epoch: 1 [5786624/8506301 (68.0%)]	Loss: 0.136190
Train Epoch: 1 [5837824/8506301 (68.6%)]	Loss: 0.116881
Train Epoch: 1 [5889024/8506301 (69.2%)]	Loss: 0.119730
Train Epoch: 1 [5940224/8506301 (69.8%)]	Loss: 0.116157
Train Epoch: 1 [5991424/8506301 (70.4%)]	Loss: 0.128159
Train Epoch: 1 [6042624/8506301 (71.0%)]	Loss: 0.128568
Train Epoch: 1 [6093824/8506301 (71.6%)]	Loss: 0.126233
Train Epoch: 1 [6145024/8506301 (72.2%)]	Loss: 0.123292
Train Epoch: 1 [6196224/8506301 (72.8%)]	Loss: 0.133886
Train Epoch: 1 [6247424/8506301 (73.4%)]	Loss: 0.136283
Train Epoch: 1 [6298624/8506301 (74.0%)]	Loss: 0.127214
Train Epoch: 1 [6349824/8506301 (74.6%)]	Loss: 0.117721
Train Epoch: 1 [6401024/8506301 (75.3%)]	Loss: 0.130114
Train Epoch: 1 [6452224/8506301 (75.9%)]	Loss: 0.139996
Train Epoch: 1 [6503424/8506301 (76.5%)]	Loss: 0.120052
Train Epoch: 1 [6554624/8506301 (77.1%)]	Loss: 0.106162
Train Epoch: 1 [6605824/8506301 (77.7%)]	Loss: 0.114843
Train Epoch: 1 [6657024/8506301 (78.3%)]	Loss: 0.114889
Train Epoch: 1 [6708224/8506301 (78.9%)]	Loss: 0.120246
Train Epoch: 1 [6759424/8506301 (79.5%)]	Loss: 0.133038
Train Epoch: 1 [6810624/8506301 (80.1%)]	Loss: 0.108620
Train Epoch: 1 [6861824/8506301 (80.7%)]	Loss: 0.129302
Train Epoch: 1 [6913024/8506301 (81.3%)]	Loss: 0.134611
Train Epoch: 1 [6964224/8506301 (81.9%)]	Loss: 0.110605
Train Epoch: 1 [7015424/8506301 (82.5%)]	Loss: 0.113362
Train Epoch: 1 [7066624/8506301 (83.1%)]	Loss: 0.118042
Train Epoch: 1 [7117824/8506301 (83.7%)]	Loss: 0.107704
Train Epoch: 1 [7169024/8506301 (84.3%)]	Loss: 0.131323
Train Epoch: 1 [7220224/8506301 (84.9%)]	Loss: 0.117846
Train Epoch: 1 [7271424/8506301 (85.5%)]	Loss: 0.118386
Train Epoch: 1 [7322624/8506301 (86.1%)]	Loss: 0.143759
Train Epoch: 1 [7373824/8506301 (86.7%)]	Loss: 0.134275
Train Epoch: 1 [7425024/8506301 (87.3%)]	Loss: 0.119401
Train Epoch: 1 [7476224/8506301 (87.9%)]	Loss: 0.124371
Train Epoch: 1 [7527424/8506301 (88.5%)]	Loss: 0.111978
Train Epoch: 1 [7578624/8506301 (89.1%)]	Loss: 0.128431
Train Epoch: 1 [7629824/8506301 (89.7%)]	Loss: 0.122180
Train Epoch: 1 [7681024/8506301 (90.3%)]	Loss: 0.117752
Train Epoch: 1 [7732224/8506301 (90.9%)]	Loss: 0.132286
Train Epoch: 1 [7783424/8506301 (91.5%)]	Loss: 0.119760
Train Epoch: 1 [7834624/8506301 (92.1%)]	Loss: 0.123909
Train Epoch: 1 [7885824/8506301 (92.7%)]	Loss: 0.137041
Train Epoch: 1 [7937024/8506301 (93.3%)]	Loss: 0.121133
Train Epoch: 1 [7988224/8506301 (93.9%)]	Loss: 0.117366
Train Epoch: 1 [8039424/8506301 (94.5%)]	Loss: 0.107056
Train Epoch: 1 [8090624/8506301 (95.1%)]	Loss: 0.122363
Train Epoch: 1 [8141824/8506301 (95.7%)]	Loss: 0.131410
Train Epoch: 1 [8193024/8506301 (96.3%)]	Loss: 0.116632
Train Epoch: 1 [8244224/8506301 (96.9%)]	Loss: 0.115791
Train Epoch: 1 [8295424/8506301 (97.5%)]	Loss: 0.105324
Train Epoch: 1 [8346624/8506301 (98.1%)]	Loss: 0.126028
Train Epoch: 1 [8397824/8506301 (98.7%)]	Loss: 0.125242
Train Epoch: 1 [8449024/8506301 (99.3%)]	Loss: 0.135252
Train Epoch: 1 [8500224/8506301 (99.9%)]	Loss: 0.111842
Train Epoch: 2 [1024/8506301 (0.0%)]	Loss: 0.118283
Train Epoch: 2 [52224/8506301 (0.6%)]	Loss: 0.143193
Train Epoch: 2 [103424/8506301 (1.2%)]	Loss: 0.120963
Train Epoch: 2 [154624/8506301 (1.8%)]	Loss: 0.144200
Train Epoch: 2 [205824/8506301 (2.4%)]	Loss: 0.117916
Train Epoch: 2 [257024/8506301 (3.0%)]	Loss: 0.110803
Train Epoch: 2 [308224/8506301 (3.6%)]	Loss: 0.104625
Train Epoch: 2 [359424/8506301 (4.2%)]	Loss: 0.124412
Train Epoch: 2 [410624/8506301 (4.8%)]	Loss: 0.140148
Train Epoch: 2 [461824/8506301 (5.4%)]	Loss: 0.108776
Train Epoch: 2 [513024/8506301 (6.0%)]	Loss: 0.112201
Train Epoch: 2 [564224/8506301 (6.6%)]	Loss: 0.117701
Train Epoch: 2 [615424/8506301 (7.2%)]	Loss: 0.131462
Train Epoch: 2 [666624/8506301 (7.8%)]	Loss: 0.116402
Train Epoch: 2 [717824/8506301 (8.4%)]	Loss: 0.110900
Train Epoch: 2 [769024/8506301 (9.0%)]	Loss: 0.113013
Train Epoch: 2 [820224/8506301 (9.6%)]	Loss: 0.139559
Train Epoch: 2 [871424/8506301 (10.2%)]	Loss: 0.133696
Train Epoch: 2 [922624/8506301 (10.8%)]	Loss: 0.126131
Train Epoch: 2 [973824/8506301 (11.4%)]	Loss: 0.114777
Train Epoch: 2 [1025024/8506301 (12.1%)]	Loss: 0.130620
Train Epoch: 2 [1076224/8506301 (12.7%)]	Loss: 0.125042
Train Epoch: 2 [1127424/8506301 (13.3%)]	Loss: 0.124354
Train Epoch: 2 [1178624/8506301 (13.9%)]	Loss: 0.121722
Train Epoch: 2 [1229824/8506301 (14.5%)]	Loss: 0.114852
Train Epoch: 2 [1281024/8506301 (15.1%)]	Loss: 0.129904
Train Epoch: 2 [1332224/8506301 (15.7%)]	Loss: 0.118551
Train Epoch: 2 [1383424/8506301 (16.3%)]	Loss: 0.117017
Train Epoch: 2 [1434624/8506301 (16.9%)]	Loss: 0.114114
Train Epoch: 2 [1485824/8506301 (17.5%)]	Loss: 0.107093
Train Epoch: 2 [1537024/8506301 (18.1%)]	Loss: 0.127484
Train Epoch: 2 [1588224/8506301 (18.7%)]	Loss: 0.117740
Train Epoch: 2 [1639424/8506301 (19.3%)]	Loss: 0.121788
Train Epoch: 2 [1690624/8506301 (19.9%)]	Loss: 0.124574
Train Epoch: 2 [1741824/8506301 (20.5%)]	Loss: 0.111754
Train Epoch: 2 [1793024/8506301 (21.1%)]	Loss: 0.113900
Train Epoch: 2 [1844224/8506301 (21.7%)]	Loss: 0.127525
Train Epoch: 2 [1895424/8506301 (22.3%)]	Loss: 0.134354
Train Epoch: 2 [1946624/8506301 (22.9%)]	Loss: 0.120802
Train Epoch: 2 [1997824/8506301 (23.5%)]	Loss: 0.130331
Train Epoch: 2 [2049024/8506301 (24.1%)]	Loss: 0.116461
Train Epoch: 2 [2100224/8506301 (24.7%)]	Loss: 0.126608
Train Epoch: 2 [2151424/8506301 (25.3%)]	Loss: 0.112663
Train Epoch: 2 [2202624/8506301 (25.9%)]	Loss: 0.125400
Train Epoch: 2 [2253824/8506301 (26.5%)]	Loss: 0.122368
Train Epoch: 2 [2305024/8506301 (27.1%)]	Loss: 0.127776
Train Epoch: 2 [2356224/8506301 (27.7%)]	Loss: 0.125210
Train Epoch: 2 [2407424/8506301 (28.3%)]	Loss: 0.125508
Train Epoch: 2 [2458624/8506301 (28.9%)]	Loss: 0.122023
Train Epoch: 2 [2509824/8506301 (29.5%)]	Loss: 0.109295
Train Epoch: 2 [2561024/8506301 (30.1%)]	Loss: 0.118882
Train Epoch: 2 [2612224/8506301 (30.7%)]	Loss: 0.113948
Train Epoch: 2 [2663424/8506301 (31.3%)]	Loss: 0.122034
Train Epoch: 2 [2714624/8506301 (31.9%)]	Loss: 0.124280
Train Epoch: 2 [2765824/8506301 (32.5%)]	Loss: 0.127613
Train Epoch: 2 [2817024/8506301 (33.1%)]	Loss: 0.121692
Train Epoch: 2 [2868224/8506301 (33.7%)]	Loss: 0.117648
Train Epoch: 2 [2919424/8506301 (34.3%)]	Loss: 0.109460
Train Epoch: 2 [2970624/8506301 (34.9%)]	Loss: 0.113480
Train Epoch: 2 [3021824/8506301 (35.5%)]	Loss: 0.116231
Train Epoch: 2 [3073024/8506301 (36.1%)]	Loss: 0.123219
Train Epoch: 2 [3124224/8506301 (36.7%)]	Loss: 0.119368
Train Epoch: 2 [3175424/8506301 (37.3%)]	Loss: 0.118281
Train Epoch: 2 [3226624/8506301 (37.9%)]	Loss: 0.118174
Train Epoch: 2 [3277824/8506301 (38.5%)]	Loss: 0.125037
Train Epoch: 2 [3329024/8506301 (39.1%)]	Loss: 0.113630
Train Epoch: 2 [3380224/8506301 (39.7%)]	Loss: 0.115233
Train Epoch: 2 [3431424/8506301 (40.3%)]	Loss: 0.127842
Train Epoch: 2 [3482624/8506301 (40.9%)]	Loss: 0.118262
Train Epoch: 2 [3533824/8506301 (41.5%)]	Loss: 0.134825
Train Epoch: 2 [3585024/8506301 (42.1%)]	Loss: 0.120733
Train Epoch: 2 [3636224/8506301 (42.7%)]	Loss: 0.118671
Train Epoch: 2 [3687424/8506301 (43.3%)]	Loss: 0.127076
Train Epoch: 2 [3738624/8506301 (44.0%)]	Loss: 0.131590
Train Epoch: 2 [3789824/8506301 (44.6%)]	Loss: 0.132211
Train Epoch: 2 [3841024/8506301 (45.2%)]	Loss: 0.139043
Train Epoch: 2 [3892224/8506301 (45.8%)]	Loss: 0.112898
Train Epoch: 2 [3943424/8506301 (46.4%)]	Loss: 0.121739
Train Epoch: 2 [3994624/8506301 (47.0%)]	Loss: 0.107818
Train Epoch: 2 [4045824/8506301 (47.6%)]	Loss: 0.127432
Train Epoch: 2 [4097024/8506301 (48.2%)]	Loss: 0.102891
Train Epoch: 2 [4148224/8506301 (48.8%)]	Loss: 0.106818
Train Epoch: 2 [4199424/8506301 (49.4%)]	Loss: 0.124660
Train Epoch: 2 [4250624/8506301 (50.0%)]	Loss: 0.116817
Train Epoch: 2 [4301824/8506301 (50.6%)]	Loss: 0.127240
Train Epoch: 2 [4353024/8506301 (51.2%)]	Loss: 0.121947
Train Epoch: 2 [4404224/8506301 (51.8%)]	Loss: 0.104278
Train Epoch: 2 [4455424/8506301 (52.4%)]	Loss: 0.127257
Train Epoch: 2 [4506624/8506301 (53.0%)]	Loss: 0.115152
Train Epoch: 2 [4557824/8506301 (53.6%)]	Loss: 0.125406
Train Epoch: 2 [4609024/8506301 (54.2%)]	Loss: 0.124908
Train Epoch: 2 [4660224/8506301 (54.8%)]	Loss: 0.124688
Train Epoch: 2 [4711424/8506301 (55.4%)]	Loss: 0.135024
Train Epoch: 2 [4762624/8506301 (56.0%)]	Loss: 0.118238
Train Epoch: 2 [4813824/8506301 (56.6%)]	Loss: 0.137418
Train Epoch: 2 [4865024/8506301 (57.2%)]	Loss: 0.128135
Train Epoch: 2 [4916224/8506301 (57.8%)]	Loss: 0.109449
Train Epoch: 2 [4967424/8506301 (58.4%)]	Loss: 0.120736
Train Epoch: 2 [5018624/8506301 (59.0%)]	Loss: 0.117592
Train Epoch: 2 [5069824/8506301 (59.6%)]	Loss: 0.142221
Train Epoch: 2 [5121024/8506301 (60.2%)]	Loss: 0.109567
Train Epoch: 2 [5172224/8506301 (60.8%)]	Loss: 0.125687
Train Epoch: 2 [5223424/8506301 (61.4%)]	Loss: 0.116676
Train Epoch: 2 [5274624/8506301 (62.0%)]	Loss: 0.124878
Train Epoch: 2 [5325824/8506301 (62.6%)]	Loss: 0.117941
Train Epoch: 2 [5377024/8506301 (63.2%)]	Loss: 0.107500
Train Epoch: 2 [5428224/8506301 (63.8%)]	Loss: 0.131409
Train Epoch: 2 [5479424/8506301 (64.4%)]	Loss: 0.105318
Train Epoch: 2 [5530624/8506301 (65.0%)]	Loss: 0.133335
Train Epoch: 2 [5581824/8506301 (65.6%)]	Loss: 0.114201
Train Epoch: 2 [5633024/8506301 (66.2%)]	Loss: 0.138964
Train Epoch: 2 [5684224/8506301 (66.8%)]	Loss: 0.129550
Train Epoch: 2 [5735424/8506301 (67.4%)]	Loss: 0.130111
Train Epoch: 2 [5786624/8506301 (68.0%)]	Loss: 0.130158
Train Epoch: 2 [5837824/8506301 (68.6%)]	Loss: 0.130645
Train Epoch: 2 [5889024/8506301 (69.2%)]	Loss: 0.093598
Train Epoch: 2 [5940224/8506301 (69.8%)]	Loss: 0.119959
Train Epoch: 2 [5991424/8506301 (70.4%)]	Loss: 0.133697
Train Epoch: 2 [6042624/8506301 (71.0%)]	Loss: 0.108271
Train Epoch: 2 [6093824/8506301 (71.6%)]	Loss: 0.115178
Train Epoch: 2 [6145024/8506301 (72.2%)]	Loss: 0.126136
Train Epoch: 2 [6196224/8506301 (72.8%)]	Loss: 0.127358
Train Epoch: 2 [6247424/8506301 (73.4%)]	Loss: 0.124275
Train Epoch: 2 [6298624/8506301 (74.0%)]	Loss: 0.133142
Train Epoch: 2 [6349824/8506301 (74.6%)]	Loss: 0.103876
Train Epoch: 2 [6401024/8506301 (75.3%)]	Loss: 0.123502
Train Epoch: 2 [6452224/8506301 (75.9%)]	Loss: 0.137192
Train Epoch: 2 [6503424/8506301 (76.5%)]	Loss: 0.115452
Train Epoch: 2 [6554624/8506301 (77.1%)]	Loss: 0.139325
Train Epoch: 2 [6605824/8506301 (77.7%)]	Loss: 0.135247
Train Epoch: 2 [6657024/8506301 (78.3%)]	Loss: 0.110934
Train Epoch: 2 [6708224/8506301 (78.9%)]	Loss: 0.123584
Train Epoch: 2 [6759424/8506301 (79.5%)]	Loss: 0.127718
Train Epoch: 2 [6810624/8506301 (80.1%)]	Loss: 0.119131
Train Epoch: 2 [6861824/8506301 (80.7%)]	Loss: 0.111742
Train Epoch: 2 [6913024/8506301 (81.3%)]	Loss: 0.127093
Train Epoch: 2 [6964224/8506301 (81.9%)]	Loss: 0.114501
Train Epoch: 2 [7015424/8506301 (82.5%)]	Loss: 0.121249
Train Epoch: 2 [7066624/8506301 (83.1%)]	Loss: 0.118842
Train Epoch: 2 [7117824/8506301 (83.7%)]	Loss: 0.107133
Train Epoch: 2 [7169024/8506301 (84.3%)]	Loss: 0.119657
Train Epoch: 2 [7220224/8506301 (84.9%)]	Loss: 0.106498
Train Epoch: 2 [7271424/8506301 (85.5%)]	Loss: 0.118138
Train Epoch: 2 [7322624/8506301 (86.1%)]	Loss: 0.120723
Train Epoch: 2 [7373824/8506301 (86.7%)]	Loss: 0.121123
Train Epoch: 2 [7425024/8506301 (87.3%)]	Loss: 0.120788
Train Epoch: 2 [7476224/8506301 (87.9%)]	Loss: 0.102998
Train Epoch: 2 [7527424/8506301 (88.5%)]	Loss: 0.111856
Train Epoch: 2 [7578624/8506301 (89.1%)]	Loss: 0.107748
Train Epoch: 2 [7629824/8506301 (89.7%)]	Loss: 0.117514
Train Epoch: 2 [7681024/8506301 (90.3%)]	Loss: 0.137537
Train Epoch: 2 [7732224/8506301 (90.9%)]	Loss: 0.122655
Train Epoch: 2 [7783424/8506301 (91.5%)]	Loss: 0.108626
Train Epoch: 2 [7834624/8506301 (92.1%)]	Loss: 0.105059
Train Epoch: 2 [7885824/8506301 (92.7%)]	Loss: 0.118357
Train Epoch: 2 [7937024/8506301 (93.3%)]	Loss: 0.113557
Train Epoch: 2 [7988224/8506301 (93.9%)]	Loss: 0.118827
Train Epoch: 2 [8039424/8506301 (94.5%)]	Loss: 0.127131
Train Epoch: 2 [8090624/8506301 (95.1%)]	Loss: 0.121442
Train Epoch: 2 [8141824/8506301 (95.7%)]	Loss: 0.101512
Train Epoch: 2 [8193024/8506301 (96.3%)]	Loss: 0.132217
Train Epoch: 2 [8244224/8506301 (96.9%)]	Loss: 0.135240
Train Epoch: 2 [8295424/8506301 (97.5%)]	Loss: 0.106564
Train Epoch: 2 [8346624/8506301 (98.1%)]	Loss: 0.121446
Train Epoch: 2 [8397824/8506301 (98.7%)]	Loss: 0.121080
Train Epoch: 2 [8449024/8506301 (99.3%)]	Loss: 0.118026
Train Epoch: 2 [8500224/8506301 (99.9%)]	Loss: 0.114971

 ---------------------------------------------------------------------- 


ACC in fold#0 was 0.897


Confusion Matrix in fold#0: 
           nonRipple   Ripple
nonRipple     706500    90748
Ripple        128753  1200575


Classification Report in fold#0: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.846        0.930     0.897        0.888         0.898
recall            0.886        0.903     0.897        0.895         0.897
f1-score          0.866        0.916     0.897        0.891         0.897
sample size  797248.000  1329328.000     0.897  2126576.000   2126576.000


PR_AUC in fold#0 was 0.970


ROC_AUC in fold#0 was 0.960

Time (id:1): tot 03:43:50, prev 03:43:50 [hh:mm:ss]: 
i_fold=0 ends.



 ---------------------------------------------------------------------- 

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8506301 (0.0%)]	Loss: 0.391590
Train Epoch: 1 [52224/8506301 (0.6%)]	Loss: 0.183926
Train Epoch: 1 [103424/8506301 (1.2%)]	Loss: 0.148366
Train Epoch: 1 [154624/8506301 (1.8%)]	Loss: 0.131485
Train Epoch: 1 [205824/8506301 (2.4%)]	Loss: 0.143334
Train Epoch: 1 [257024/8506301 (3.0%)]	Loss: 0.122680
Train Epoch: 1 [308224/8506301 (3.6%)]	Loss: 0.144196
Train Epoch: 1 [359424/8506301 (4.2%)]	Loss: 0.126424
Train Epoch: 1 [410624/8506301 (4.8%)]	Loss: 0.139481
Train Epoch: 1 [461824/8506301 (5.4%)]	Loss: 0.130586
Train Epoch: 1 [513024/8506301 (6.0%)]	Loss: 0.132031
Train Epoch: 1 [564224/8506301 (6.6%)]	Loss: 0.132494
Train Epoch: 1 [615424/8506301 (7.2%)]	Loss: 0.127582
Train Epoch: 1 [666624/8506301 (7.8%)]	Loss: 0.127336
Train Epoch: 1 [717824/8506301 (8.4%)]	Loss: 0.116064
Train Epoch: 1 [769024/8506301 (9.0%)]	Loss: 0.125901
Train Epoch: 1 [820224/8506301 (9.6%)]	Loss: 0.119941
Train Epoch: 1 [871424/8506301 (10.2%)]	Loss: 0.112828
Train Epoch: 1 [922624/8506301 (10.8%)]	Loss: 0.121840
Train Epoch: 1 [973824/8506301 (11.4%)]	Loss: 0.129989
Train Epoch: 1 [1025024/8506301 (12.1%)]	Loss: 0.124473
Train Epoch: 1 [1076224/8506301 (12.7%)]	Loss: 0.126156
Train Epoch: 1 [1127424/8506301 (13.3%)]	Loss: 0.131843
Train Epoch: 1 [1178624/8506301 (13.9%)]	Loss: 0.131842
Train Epoch: 1 [1229824/8506301 (14.5%)]	Loss: 0.129362
Train Epoch: 1 [1281024/8506301 (15.1%)]	Loss: 0.114640
Train Epoch: 1 [1332224/8506301 (15.7%)]	Loss: 0.132673
Train Epoch: 1 [1383424/8506301 (16.3%)]	Loss: 0.129564
Train Epoch: 1 [1434624/8506301 (16.9%)]	Loss: 0.119724
Train Epoch: 1 [1485824/8506301 (17.5%)]	Loss: 0.125033
Train Epoch: 1 [1537024/8506301 (18.1%)]	Loss: 0.116331
Train Epoch: 1 [1588224/8506301 (18.7%)]	Loss: 0.123056
Train Epoch: 1 [1639424/8506301 (19.3%)]	Loss: 0.127844
Train Epoch: 1 [1690624/8506301 (19.9%)]	Loss: 0.117066
Train Epoch: 1 [1741824/8506301 (20.5%)]	Loss: 0.125091
Train Epoch: 1 [1793024/8506301 (21.1%)]	Loss: 0.119104
Train Epoch: 1 [1844224/8506301 (21.7%)]	Loss: 0.117018
Train Epoch: 1 [1895424/8506301 (22.3%)]	Loss: 0.104863
Train Epoch: 1 [1946624/8506301 (22.9%)]	Loss: 0.120836
Train Epoch: 1 [1997824/8506301 (23.5%)]	Loss: 0.149237
Train Epoch: 1 [2049024/8506301 (24.1%)]	Loss: 0.129016
Train Epoch: 1 [2100224/8506301 (24.7%)]	Loss: 0.122222
Train Epoch: 1 [2151424/8506301 (25.3%)]	Loss: 0.122153
Train Epoch: 1 [2202624/8506301 (25.9%)]	Loss: 0.102562
Train Epoch: 1 [2253824/8506301 (26.5%)]	Loss: 0.125963
Train Epoch: 1 [2305024/8506301 (27.1%)]	Loss: 0.128367
Train Epoch: 1 [2356224/8506301 (27.7%)]	Loss: 0.127076
Train Epoch: 1 [2407424/8506301 (28.3%)]	Loss: 0.118715
Train Epoch: 1 [2458624/8506301 (28.9%)]	Loss: 0.111547
Train Epoch: 1 [2509824/8506301 (29.5%)]	Loss: 0.110269
Train Epoch: 1 [2561024/8506301 (30.1%)]	Loss: 0.123291
Train Epoch: 1 [2612224/8506301 (30.7%)]	Loss: 0.120485
Train Epoch: 1 [2663424/8506301 (31.3%)]	Loss: 0.111415
Train Epoch: 1 [2714624/8506301 (31.9%)]	Loss: 0.133081
Train Epoch: 1 [2765824/8506301 (32.5%)]	Loss: 0.107840
Train Epoch: 1 [2817024/8506301 (33.1%)]	Loss: 0.135755
Train Epoch: 1 [2868224/8506301 (33.7%)]	Loss: 0.116557
Train Epoch: 1 [2919424/8506301 (34.3%)]	Loss: 0.123825
Train Epoch: 1 [2970624/8506301 (34.9%)]	Loss: 0.124546
Train Epoch: 1 [3021824/8506301 (35.5%)]	Loss: 0.136740
Train Epoch: 1 [3073024/8506301 (36.1%)]	Loss: 0.114171
Train Epoch: 1 [3124224/8506301 (36.7%)]	Loss: 0.127280
Train Epoch: 1 [3175424/8506301 (37.3%)]	Loss: 0.122393
Train Epoch: 1 [3226624/8506301 (37.9%)]	Loss: 0.116351
Train Epoch: 1 [3277824/8506301 (38.5%)]	Loss: 0.137974
Train Epoch: 1 [3329024/8506301 (39.1%)]	Loss: 0.120945
Train Epoch: 1 [3380224/8506301 (39.7%)]	Loss: 0.131707
Train Epoch: 1 [3431424/8506301 (40.3%)]	Loss: 0.112604
Train Epoch: 1 [3482624/8506301 (40.9%)]	Loss: 0.121546
Train Epoch: 1 [3533824/8506301 (41.5%)]	Loss: 0.131967
Train Epoch: 1 [3585024/8506301 (42.1%)]	Loss: 0.146100
Train Epoch: 1 [3636224/8506301 (42.7%)]	Loss: 0.120617
Train Epoch: 1 [3687424/8506301 (43.3%)]	Loss: 0.127019
Train Epoch: 1 [3738624/8506301 (44.0%)]	Loss: 0.126539
Train Epoch: 1 [3789824/8506301 (44.6%)]	Loss: 0.121091
Train Epoch: 1 [3841024/8506301 (45.2%)]	Loss: 0.124658
Train Epoch: 1 [3892224/8506301 (45.8%)]	Loss: 0.129129
Train Epoch: 1 [3943424/8506301 (46.4%)]	Loss: 0.110717
Train Epoch: 1 [3994624/8506301 (47.0%)]	Loss: 0.121141
Train Epoch: 1 [4045824/8506301 (47.6%)]	Loss: 0.112778
Train Epoch: 1 [4097024/8506301 (48.2%)]	Loss: 0.119653
Train Epoch: 1 [4148224/8506301 (48.8%)]	Loss: 0.118989
Train Epoch: 1 [4199424/8506301 (49.4%)]	Loss: 0.136925
Train Epoch: 1 [4250624/8506301 (50.0%)]	Loss: 0.114719
Train Epoch: 1 [4301824/8506301 (50.6%)]	Loss: 0.117969
Train Epoch: 1 [4353024/8506301 (51.2%)]	Loss: 0.124530
Train Epoch: 1 [4404224/8506301 (51.8%)]	Loss: 0.112426
Train Epoch: 1 [4455424/8506301 (52.4%)]	Loss: 0.131851
Train Epoch: 1 [4506624/8506301 (53.0%)]	Loss: 0.123180
Train Epoch: 1 [4557824/8506301 (53.6%)]	Loss: 0.115848
Train Epoch: 1 [4609024/8506301 (54.2%)]	Loss: 0.118243
Train Epoch: 1 [4660224/8506301 (54.8%)]	Loss: 0.132063
Train Epoch: 1 [4711424/8506301 (55.4%)]	Loss: 0.120116
Train Epoch: 1 [4762624/8506301 (56.0%)]	Loss: 0.107301
Train Epoch: 1 [4813824/8506301 (56.6%)]	Loss: 0.126074
Train Epoch: 1 [4865024/8506301 (57.2%)]	Loss: 0.116068
Train Epoch: 1 [4916224/8506301 (57.8%)]	Loss: 0.124320
Train Epoch: 1 [4967424/8506301 (58.4%)]	Loss: 0.126829
Train Epoch: 1 [5018624/8506301 (59.0%)]	Loss: 0.106568
Train Epoch: 1 [5069824/8506301 (59.6%)]	Loss: 0.125435
Train Epoch: 1 [5121024/8506301 (60.2%)]	Loss: 0.119448
Train Epoch: 1 [5172224/8506301 (60.8%)]	Loss: 0.116101
Train Epoch: 1 [5223424/8506301 (61.4%)]	Loss: 0.118749
Train Epoch: 1 [5274624/8506301 (62.0%)]	Loss: 0.129894
Train Epoch: 1 [5325824/8506301 (62.6%)]	Loss: 0.115415
Train Epoch: 1 [5377024/8506301 (63.2%)]	Loss: 0.115988
Train Epoch: 1 [5428224/8506301 (63.8%)]	Loss: 0.110175
Train Epoch: 1 [5479424/8506301 (64.4%)]	Loss: 0.122811
Train Epoch: 1 [5530624/8506301 (65.0%)]	Loss: 0.114552
Train Epoch: 1 [5581824/8506301 (65.6%)]	Loss: 0.136529
Train Epoch: 1 [5633024/8506301 (66.2%)]	Loss: 0.117589
Train Epoch: 1 [5684224/8506301 (66.8%)]	Loss: 0.110538
Train Epoch: 1 [5735424/8506301 (67.4%)]	Loss: 0.123844
Train Epoch: 1 [5786624/8506301 (68.0%)]	Loss: 0.116096
Train Epoch: 1 [5837824/8506301 (68.6%)]	Loss: 0.114501
Train Epoch: 1 [5889024/8506301 (69.2%)]	Loss: 0.107518
Train Epoch: 1 [5940224/8506301 (69.8%)]	Loss: 0.117539
Train Epoch: 1 [5991424/8506301 (70.4%)]	Loss: 0.118384
Train Epoch: 1 [6042624/8506301 (71.0%)]	Loss: 0.120244
Train Epoch: 1 [6093824/8506301 (71.6%)]	Loss: 0.136123
Train Epoch: 1 [6145024/8506301 (72.2%)]	Loss: 0.109199
Train Epoch: 1 [6196224/8506301 (72.8%)]	Loss: 0.103555
Train Epoch: 1 [6247424/8506301 (73.4%)]	Loss: 0.122807
Train Epoch: 1 [6298624/8506301 (74.0%)]	Loss: 0.121706
Train Epoch: 1 [6349824/8506301 (74.6%)]	Loss: 0.116607
Train Epoch: 1 [6401024/8506301 (75.3%)]	Loss: 0.119019
Train Epoch: 1 [6452224/8506301 (75.9%)]	Loss: 0.112699
Train Epoch: 1 [6503424/8506301 (76.5%)]	Loss: 0.108896
Train Epoch: 1 [6554624/8506301 (77.1%)]	Loss: 0.113270
Train Epoch: 1 [6605824/8506301 (77.7%)]	Loss: 0.115078
Train Epoch: 1 [6657024/8506301 (78.3%)]	Loss: 0.135638
Train Epoch: 1 [6708224/8506301 (78.9%)]	Loss: 0.124458
Train Epoch: 1 [6759424/8506301 (79.5%)]	Loss: 0.133593
Train Epoch: 1 [6810624/8506301 (80.1%)]	Loss: 0.125559
Train Epoch: 1 [6861824/8506301 (80.7%)]	Loss: 0.119530
Train Epoch: 1 [6913024/8506301 (81.3%)]	Loss: 0.121548
Train Epoch: 1 [6964224/8506301 (81.9%)]	Loss: 0.107847
Train Epoch: 1 [7015424/8506301 (82.5%)]	Loss: 0.127786
Train Epoch: 1 [7066624/8506301 (83.1%)]	Loss: 0.134642
Train Epoch: 1 [7117824/8506301 (83.7%)]	Loss: 0.115567
Train Epoch: 1 [7169024/8506301 (84.3%)]	Loss: 0.112837
Train Epoch: 1 [7220224/8506301 (84.9%)]	Loss: 0.114230
Train Epoch: 1 [7271424/8506301 (85.5%)]	Loss: 0.115955
Train Epoch: 1 [7322624/8506301 (86.1%)]	Loss: 0.122343
Train Epoch: 1 [7373824/8506301 (86.7%)]	Loss: 0.118663
Train Epoch: 1 [7425024/8506301 (87.3%)]	Loss: 0.126030
Train Epoch: 1 [7476224/8506301 (87.9%)]	Loss: 0.122019
Train Epoch: 1 [7527424/8506301 (88.5%)]	Loss: 0.130853
Train Epoch: 1 [7578624/8506301 (89.1%)]	Loss: 0.122415
Train Epoch: 1 [7629824/8506301 (89.7%)]	Loss: 0.117988
Train Epoch: 1 [7681024/8506301 (90.3%)]	Loss: 0.108748
Train Epoch: 1 [7732224/8506301 (90.9%)]	Loss: 0.132477
Train Epoch: 1 [7783424/8506301 (91.5%)]	Loss: 0.107559
Train Epoch: 1 [7834624/8506301 (92.1%)]	Loss: 0.134909
Train Epoch: 1 [7885824/8506301 (92.7%)]	Loss: 0.117853
Train Epoch: 1 [7937024/8506301 (93.3%)]	Loss: 0.121967
Train Epoch: 1 [7988224/8506301 (93.9%)]	Loss: 0.118161
Train Epoch: 1 [8039424/8506301 (94.5%)]	Loss: 0.113981
Train Epoch: 1 [8090624/8506301 (95.1%)]	Loss: 0.129798
Train Epoch: 1 [8141824/8506301 (95.7%)]	Loss: 0.124640
Train Epoch: 1 [8193024/8506301 (96.3%)]	Loss: 0.121991
Train Epoch: 1 [8244224/8506301 (96.9%)]	Loss: 0.111430
Train Epoch: 1 [8295424/8506301 (97.5%)]	Loss: 0.126187
Train Epoch: 1 [8346624/8506301 (98.1%)]	Loss: 0.112521
Train Epoch: 1 [8397824/8506301 (98.7%)]	Loss: 0.125229
Train Epoch: 1 [8449024/8506301 (99.3%)]	Loss: 0.110469
Train Epoch: 1 [8500224/8506301 (99.9%)]	Loss: 0.111092
Train Epoch: 2 [1024/8506301 (0.0%)]	Loss: 0.123095
Train Epoch: 2 [52224/8506301 (0.6%)]	Loss: 0.120022
Train Epoch: 2 [103424/8506301 (1.2%)]	Loss: 0.121526
Train Epoch: 2 [154624/8506301 (1.8%)]	Loss: 0.130428
Train Epoch: 2 [205824/8506301 (2.4%)]	Loss: 0.126332
Train Epoch: 2 [257024/8506301 (3.0%)]	Loss: 0.118261
Train Epoch: 2 [308224/8506301 (3.6%)]	Loss: 0.124758
Train Epoch: 2 [359424/8506301 (4.2%)]	Loss: 0.131828
Train Epoch: 2 [410624/8506301 (4.8%)]	Loss: 0.116481
Train Epoch: 2 [461824/8506301 (5.4%)]	Loss: 0.109744
Train Epoch: 2 [513024/8506301 (6.0%)]	Loss: 0.130649
Train Epoch: 2 [564224/8506301 (6.6%)]	Loss: 0.129679
Train Epoch: 2 [615424/8506301 (7.2%)]	Loss: 0.113172
Train Epoch: 2 [666624/8506301 (7.8%)]	Loss: 0.102444
Train Epoch: 2 [717824/8506301 (8.4%)]	Loss: 0.107289
Train Epoch: 2 [769024/8506301 (9.0%)]	Loss: 0.115343
Train Epoch: 2 [820224/8506301 (9.6%)]	Loss: 0.117962
Train Epoch: 2 [871424/8506301 (10.2%)]	Loss: 0.108471
Train Epoch: 2 [922624/8506301 (10.8%)]	Loss: 0.133188
Train Epoch: 2 [973824/8506301 (11.4%)]	Loss: 0.115661
Train Epoch: 2 [1025024/8506301 (12.1%)]	Loss: 0.115954
Train Epoch: 2 [1076224/8506301 (12.7%)]	Loss: 0.127578
Train Epoch: 2 [1127424/8506301 (13.3%)]	Loss: 0.105661
Train Epoch: 2 [1178624/8506301 (13.9%)]	Loss: 0.099864
Train Epoch: 2 [1229824/8506301 (14.5%)]	Loss: 0.121437
Train Epoch: 2 [1281024/8506301 (15.1%)]	Loss: 0.111969
Train Epoch: 2 [1332224/8506301 (15.7%)]	Loss: 0.111700
Train Epoch: 2 [1383424/8506301 (16.3%)]	Loss: 0.133677
Train Epoch: 2 [1434624/8506301 (16.9%)]	Loss: 0.116651
Train Epoch: 2 [1485824/8506301 (17.5%)]	Loss: 0.124810
Train Epoch: 2 [1537024/8506301 (18.1%)]	Loss: 0.104677
Train Epoch: 2 [1588224/8506301 (18.7%)]	Loss: 0.097418
Train Epoch: 2 [1639424/8506301 (19.3%)]	Loss: 0.126776
Train Epoch: 2 [1690624/8506301 (19.9%)]	Loss: 0.095456
Train Epoch: 2 [1741824/8506301 (20.5%)]	Loss: 0.113220
Train Epoch: 2 [1793024/8506301 (21.1%)]	Loss: 0.119580
Train Epoch: 2 [1844224/8506301 (21.7%)]	Loss: 0.117057
Train Epoch: 2 [1895424/8506301 (22.3%)]	Loss: 0.112120
Train Epoch: 2 [1946624/8506301 (22.9%)]	Loss: 0.111584
Train Epoch: 2 [1997824/8506301 (23.5%)]	Loss: 0.127531
Train Epoch: 2 [2049024/8506301 (24.1%)]	Loss: 0.110919
Train Epoch: 2 [2100224/8506301 (24.7%)]	Loss: 0.105467
Train Epoch: 2 [2151424/8506301 (25.3%)]	Loss: 0.123609
Train Epoch: 2 [2202624/8506301 (25.9%)]	Loss: 0.112375
Train Epoch: 2 [2253824/8506301 (26.5%)]	Loss: 0.111116
Train Epoch: 2 [2305024/8506301 (27.1%)]	Loss: 0.130002
Train Epoch: 2 [2356224/8506301 (27.7%)]	Loss: 0.104113
Train Epoch: 2 [2407424/8506301 (28.3%)]	Loss: 0.102377
Train Epoch: 2 [2458624/8506301 (28.9%)]	Loss: 0.127263
Train Epoch: 2 [2509824/8506301 (29.5%)]	Loss: 0.126811
Train Epoch: 2 [2561024/8506301 (30.1%)]	Loss: 0.103009
Train Epoch: 2 [2612224/8506301 (30.7%)]	Loss: 0.103563
Train Epoch: 2 [2663424/8506301 (31.3%)]	Loss: 0.113844
Train Epoch: 2 [2714624/8506301 (31.9%)]	Loss: 0.124863
Train Epoch: 2 [2765824/8506301 (32.5%)]	Loss: 0.134575
Train Epoch: 2 [2817024/8506301 (33.1%)]	Loss: 0.122114
Train Epoch: 2 [2868224/8506301 (33.7%)]	Loss: 0.116173
Train Epoch: 2 [2919424/8506301 (34.3%)]	Loss: 0.112560
Train Epoch: 2 [2970624/8506301 (34.9%)]	Loss: 0.125108
Train Epoch: 2 [3021824/8506301 (35.5%)]	Loss: 0.113209
Train Epoch: 2 [3073024/8506301 (36.1%)]	Loss: 0.107615
Train Epoch: 2 [3124224/8506301 (36.7%)]	Loss: 0.111862
Train Epoch: 2 [3175424/8506301 (37.3%)]	Loss: 0.128075
Train Epoch: 2 [3226624/8506301 (37.9%)]	Loss: 0.113144
Train Epoch: 2 [3277824/8506301 (38.5%)]	Loss: 0.131129
Train Epoch: 2 [3329024/8506301 (39.1%)]	Loss: 0.111871
Train Epoch: 2 [3380224/8506301 (39.7%)]	Loss: 0.111215
Train Epoch: 2 [3431424/8506301 (40.3%)]	Loss: 0.119068
Train Epoch: 2 [3482624/8506301 (40.9%)]	Loss: 0.104979
Train Epoch: 2 [3533824/8506301 (41.5%)]	Loss: 0.106404
Train Epoch: 2 [3585024/8506301 (42.1%)]	Loss: 0.118438
Train Epoch: 2 [3636224/8506301 (42.7%)]	Loss: 0.119640
Train Epoch: 2 [3687424/8506301 (43.3%)]	Loss: 0.116522
Train Epoch: 2 [3738624/8506301 (44.0%)]	Loss: 0.101095
Train Epoch: 2 [3789824/8506301 (44.6%)]	Loss: 0.128006
Train Epoch: 2 [3841024/8506301 (45.2%)]	Loss: 0.122750
Train Epoch: 2 [3892224/8506301 (45.8%)]	Loss: 0.114184
Train Epoch: 2 [3943424/8506301 (46.4%)]	Loss: 0.124366
Train Epoch: 2 [3994624/8506301 (47.0%)]	Loss: 0.127451
Train Epoch: 2 [4045824/8506301 (47.6%)]	Loss: 0.109822
Train Epoch: 2 [4097024/8506301 (48.2%)]	Loss: 0.128072
Train Epoch: 2 [4148224/8506301 (48.8%)]	Loss: 0.117136
Train Epoch: 2 [4199424/8506301 (49.4%)]	Loss: 0.100933
Train Epoch: 2 [4250624/8506301 (50.0%)]	Loss: 0.096975
Train Epoch: 2 [4301824/8506301 (50.6%)]	Loss: 0.119192
Train Epoch: 2 [4353024/8506301 (51.2%)]	Loss: 0.122726
Train Epoch: 2 [4404224/8506301 (51.8%)]	Loss: 0.114113
Train Epoch: 2 [4455424/8506301 (52.4%)]	Loss: 0.124122
Train Epoch: 2 [4506624/8506301 (53.0%)]	Loss: 0.107722
Train Epoch: 2 [4557824/8506301 (53.6%)]	Loss: 0.118118
Train Epoch: 2 [4609024/8506301 (54.2%)]	Loss: 0.122163
Train Epoch: 2 [4660224/8506301 (54.8%)]	Loss: 0.114948
Train Epoch: 2 [4711424/8506301 (55.4%)]	Loss: 0.123297
Train Epoch: 2 [4762624/8506301 (56.0%)]	Loss: 0.118401
Train Epoch: 2 [4813824/8506301 (56.6%)]	Loss: 0.117012
Train Epoch: 2 [4865024/8506301 (57.2%)]	Loss: 0.116141
Train Epoch: 2 [4916224/8506301 (57.8%)]	Loss: 0.109134
Train Epoch: 2 [4967424/8506301 (58.4%)]	Loss: 0.125175
Train Epoch: 2 [5018624/8506301 (59.0%)]	Loss: 0.121963
Train Epoch: 2 [5069824/8506301 (59.6%)]	Loss: 0.114974
Train Epoch: 2 [5121024/8506301 (60.2%)]	Loss: 0.118012
Train Epoch: 2 [5172224/8506301 (60.8%)]	Loss: 0.104053
Train Epoch: 2 [5223424/8506301 (61.4%)]	Loss: 0.107827
Train Epoch: 2 [5274624/8506301 (62.0%)]	Loss: 0.122634
Train Epoch: 2 [5325824/8506301 (62.6%)]	Loss: 0.112776
Train Epoch: 2 [5377024/8506301 (63.2%)]	Loss: 0.124889
Train Epoch: 2 [5428224/8506301 (63.8%)]	Loss: 0.120987
Train Epoch: 2 [5479424/8506301 (64.4%)]	Loss: 0.119200
Train Epoch: 2 [5530624/8506301 (65.0%)]	Loss: 0.121105
Train Epoch: 2 [5581824/8506301 (65.6%)]	Loss: 0.117530
Train Epoch: 2 [5633024/8506301 (66.2%)]	Loss: 0.109756
Train Epoch: 2 [5684224/8506301 (66.8%)]	Loss: 0.137704
Train Epoch: 2 [5735424/8506301 (67.4%)]	Loss: 0.103393
Train Epoch: 2 [5786624/8506301 (68.0%)]	Loss: 0.138457
Train Epoch: 2 [5837824/8506301 (68.6%)]	Loss: 0.099978
Train Epoch: 2 [5889024/8506301 (69.2%)]	Loss: 0.110263
Train Epoch: 2 [5940224/8506301 (69.8%)]	Loss: 0.113542
Train Epoch: 2 [5991424/8506301 (70.4%)]	Loss: 0.118484
Train Epoch: 2 [6042624/8506301 (71.0%)]	Loss: 0.096990
Train Epoch: 2 [6093824/8506301 (71.6%)]	Loss: 0.109631
Train Epoch: 2 [6145024/8506301 (72.2%)]	Loss: 0.108374
Train Epoch: 2 [6196224/8506301 (72.8%)]	Loss: 0.126040
Train Epoch: 2 [6247424/8506301 (73.4%)]	Loss: 0.111466
Train Epoch: 2 [6298624/8506301 (74.0%)]	Loss: 0.122465
Train Epoch: 2 [6349824/8506301 (74.6%)]	Loss: 0.107005
Train Epoch: 2 [6401024/8506301 (75.3%)]	Loss: 0.112379
Train Epoch: 2 [6452224/8506301 (75.9%)]	Loss: 0.126846
Train Epoch: 2 [6503424/8506301 (76.5%)]	Loss: 0.123108
Train Epoch: 2 [6554624/8506301 (77.1%)]	Loss: 0.115272
Train Epoch: 2 [6605824/8506301 (77.7%)]	Loss: 0.103834
Train Epoch: 2 [6657024/8506301 (78.3%)]	Loss: 0.122400
Train Epoch: 2 [6708224/8506301 (78.9%)]	Loss: 0.109279
Train Epoch: 2 [6759424/8506301 (79.5%)]	Loss: 0.120322
Train Epoch: 2 [6810624/8506301 (80.1%)]	Loss: 0.106754
Train Epoch: 2 [6861824/8506301 (80.7%)]	Loss: 0.105919
Train Epoch: 2 [6913024/8506301 (81.3%)]	Loss: 0.109951
Train Epoch: 2 [6964224/8506301 (81.9%)]	Loss: 0.120145
Train Epoch: 2 [7015424/8506301 (82.5%)]	Loss: 0.123073
Train Epoch: 2 [7066624/8506301 (83.1%)]	Loss: 0.113220
Train Epoch: 2 [7117824/8506301 (83.7%)]	Loss: 0.112856
Train Epoch: 2 [7169024/8506301 (84.3%)]	Loss: 0.109711
Train Epoch: 2 [7220224/8506301 (84.9%)]	Loss: 0.116347
Train Epoch: 2 [7271424/8506301 (85.5%)]	Loss: 0.114450
Train Epoch: 2 [7322624/8506301 (86.1%)]	Loss: 0.128703
Train Epoch: 2 [7373824/8506301 (86.7%)]	Loss: 0.110376
Train Epoch: 2 [7425024/8506301 (87.3%)]	Loss: 0.122663
Train Epoch: 2 [7476224/8506301 (87.9%)]	Loss: 0.111536
Train Epoch: 2 [7527424/8506301 (88.5%)]	Loss: 0.117246
Train Epoch: 2 [7578624/8506301 (89.1%)]	Loss: 0.134104
Train Epoch: 2 [7629824/8506301 (89.7%)]	Loss: 0.108005
Train Epoch: 2 [7681024/8506301 (90.3%)]	Loss: 0.129634
Train Epoch: 2 [7732224/8506301 (90.9%)]	Loss: 0.104038
Train Epoch: 2 [7783424/8506301 (91.5%)]	Loss: 0.115138
Train Epoch: 2 [7834624/8506301 (92.1%)]	Loss: 0.107246
Train Epoch: 2 [7885824/8506301 (92.7%)]	Loss: 0.120861
Train Epoch: 2 [7937024/8506301 (93.3%)]	Loss: 0.119772
Train Epoch: 2 [7988224/8506301 (93.9%)]	Loss: 0.125853
Train Epoch: 2 [8039424/8506301 (94.5%)]	Loss: 0.125372
Train Epoch: 2 [8090624/8506301 (95.1%)]	Loss: 0.129843
Train Epoch: 2 [8141824/8506301 (95.7%)]	Loss: 0.116456
Train Epoch: 2 [8193024/8506301 (96.3%)]	Loss: 0.114792
Train Epoch: 2 [8244224/8506301 (96.9%)]	Loss: 0.111986
Train Epoch: 2 [8295424/8506301 (97.5%)]	Loss: 0.124221
Train Epoch: 2 [8346624/8506301 (98.1%)]	Loss: 0.104925
Train Epoch: 2 [8397824/8506301 (98.7%)]	Loss: 0.117532
Train Epoch: 2 [8449024/8506301 (99.3%)]	Loss: 0.124288
Train Epoch: 2 [8500224/8506301 (99.9%)]	Loss: 0.113883

 ---------------------------------------------------------------------- 


ACC in fold#1 was 0.884


Confusion Matrix in fold#1: 
           nonRipple   Ripple
nonRipple     682830   114419
Ripple        132239  1197088


Classification Report in fold#1: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.838        0.913     0.884        0.875         0.885
recall            0.856        0.901     0.884        0.879         0.884
f1-score          0.847        0.907     0.884        0.877         0.884
sample size  797249.000  1329327.000     0.884  2126576.000   2126576.000


PR_AUC in fold#1 was 0.964


ROC_AUC in fold#1 was 0.952

Time (id:2): tot 07:26:40, prev 03:42:49 [hh:mm:ss]: 
i_fold=1 ends.



 ---------------------------------------------------------------------- 

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8506302 (0.0%)]	Loss: 0.372473
Train Epoch: 1 [52224/8506302 (0.6%)]	Loss: 0.191762
Train Epoch: 1 [103424/8506302 (1.2%)]	Loss: 0.149839
Train Epoch: 1 [154624/8506302 (1.8%)]	Loss: 0.133238
Train Epoch: 1 [205824/8506302 (2.4%)]	Loss: 0.135973
Train Epoch: 1 [257024/8506302 (3.0%)]	Loss: 0.139808
Train Epoch: 1 [308224/8506302 (3.6%)]	Loss: 0.138441
Train Epoch: 1 [359424/8506302 (4.2%)]	Loss: 0.121448
Train Epoch: 1 [410624/8506302 (4.8%)]	Loss: 0.138861
Train Epoch: 1 [461824/8506302 (5.4%)]	Loss: 0.147794
Train Epoch: 1 [513024/8506302 (6.0%)]	Loss: 0.135120
Train Epoch: 1 [564224/8506302 (6.6%)]	Loss: 0.128325
Train Epoch: 1 [615424/8506302 (7.2%)]	Loss: 0.115862
Train Epoch: 1 [666624/8506302 (7.8%)]	Loss: 0.142796
Train Epoch: 1 [717824/8506302 (8.4%)]	Loss: 0.125101
Train Epoch: 1 [769024/8506302 (9.0%)]	Loss: 0.128366
Train Epoch: 1 [820224/8506302 (9.6%)]	Loss: 0.128882
Train Epoch: 1 [871424/8506302 (10.2%)]	Loss: 0.136010
Train Epoch: 1 [922624/8506302 (10.8%)]	Loss: 0.115949
Train Epoch: 1 [973824/8506302 (11.4%)]	Loss: 0.124729
Train Epoch: 1 [1025024/8506302 (12.1%)]	Loss: 0.139909
Train Epoch: 1 [1076224/8506302 (12.7%)]	Loss: 0.124106
Train Epoch: 1 [1127424/8506302 (13.3%)]	Loss: 0.127121
Train Epoch: 1 [1178624/8506302 (13.9%)]	Loss: 0.144681
Train Epoch: 1 [1229824/8506302 (14.5%)]	Loss: 0.127416
Train Epoch: 1 [1281024/8506302 (15.1%)]	Loss: 0.121693
Train Epoch: 1 [1332224/8506302 (15.7%)]	Loss: 0.108018
Train Epoch: 1 [1383424/8506302 (16.3%)]	Loss: 0.124299
Train Epoch: 1 [1434624/8506302 (16.9%)]	Loss: 0.116925
Train Epoch: 1 [1485824/8506302 (17.5%)]	Loss: 0.130344
Train Epoch: 1 [1537024/8506302 (18.1%)]	Loss: 0.108878
Train Epoch: 1 [1588224/8506302 (18.7%)]	Loss: 0.120732
Train Epoch: 1 [1639424/8506302 (19.3%)]	Loss: 0.131449
Train Epoch: 1 [1690624/8506302 (19.9%)]	Loss: 0.144551
Train Epoch: 1 [1741824/8506302 (20.5%)]	Loss: 0.115920
Train Epoch: 1 [1793024/8506302 (21.1%)]	Loss: 0.118464
Train Epoch: 1 [1844224/8506302 (21.7%)]	Loss: 0.132997
Train Epoch: 1 [1895424/8506302 (22.3%)]	Loss: 0.143558
Train Epoch: 1 [1946624/8506302 (22.9%)]	Loss: 0.137602
Train Epoch: 1 [1997824/8506302 (23.5%)]	Loss: 0.131984
Train Epoch: 1 [2049024/8506302 (24.1%)]	Loss: 0.117285
Train Epoch: 1 [2100224/8506302 (24.7%)]	Loss: 0.123782
Train Epoch: 1 [2151424/8506302 (25.3%)]	Loss: 0.125045
Train Epoch: 1 [2202624/8506302 (25.9%)]	Loss: 0.135580
Train Epoch: 1 [2253824/8506302 (26.5%)]	Loss: 0.125927
Train Epoch: 1 [2305024/8506302 (27.1%)]	Loss: 0.135056
Train Epoch: 1 [2356224/8506302 (27.7%)]	Loss: 0.128847
Train Epoch: 1 [2407424/8506302 (28.3%)]	Loss: 0.133278
Train Epoch: 1 [2458624/8506302 (28.9%)]	Loss: 0.124582
Train Epoch: 1 [2509824/8506302 (29.5%)]	Loss: 0.129643
Train Epoch: 1 [2561024/8506302 (30.1%)]	Loss: 0.131178
Train Epoch: 1 [2612224/8506302 (30.7%)]	Loss: 0.123789
Train Epoch: 1 [2663424/8506302 (31.3%)]	Loss: 0.129965
Train Epoch: 1 [2714624/8506302 (31.9%)]	Loss: 0.127150
Train Epoch: 1 [2765824/8506302 (32.5%)]	Loss: 0.116161
Train Epoch: 1 [2817024/8506302 (33.1%)]	Loss: 0.127624
Train Epoch: 1 [2868224/8506302 (33.7%)]	Loss: 0.118287
Train Epoch: 1 [2919424/8506302 (34.3%)]	Loss: 0.116649
Train Epoch: 1 [2970624/8506302 (34.9%)]	Loss: 0.133212
Train Epoch: 1 [3021824/8506302 (35.5%)]	Loss: 0.124761
Train Epoch: 1 [3073024/8506302 (36.1%)]	Loss: 0.120677
Train Epoch: 1 [3124224/8506302 (36.7%)]	Loss: 0.118235
Train Epoch: 1 [3175424/8506302 (37.3%)]	Loss: 0.137752
Train Epoch: 1 [3226624/8506302 (37.9%)]	Loss: 0.131612
Train Epoch: 1 [3277824/8506302 (38.5%)]	Loss: 0.129962
Train Epoch: 1 [3329024/8506302 (39.1%)]	Loss: 0.113457
Train Epoch: 1 [3380224/8506302 (39.7%)]	Loss: 0.126678
Train Epoch: 1 [3431424/8506302 (40.3%)]	Loss: 0.120836
Train Epoch: 1 [3482624/8506302 (40.9%)]	Loss: 0.118964
Train Epoch: 1 [3533824/8506302 (41.5%)]	Loss: 0.119203
Train Epoch: 1 [3585024/8506302 (42.1%)]	Loss: 0.113014
Train Epoch: 1 [3636224/8506302 (42.7%)]	Loss: 0.129591
Train Epoch: 1 [3687424/8506302 (43.3%)]	Loss: 0.128166
Train Epoch: 1 [3738624/8506302 (44.0%)]	Loss: 0.126152
Train Epoch: 1 [3789824/8506302 (44.6%)]	Loss: 0.133721
Train Epoch: 1 [3841024/8506302 (45.2%)]	Loss: 0.113723
Train Epoch: 1 [3892224/8506302 (45.8%)]	Loss: 0.121493
Train Epoch: 1 [3943424/8506302 (46.4%)]	Loss: 0.126349
Train Epoch: 1 [3994624/8506302 (47.0%)]	Loss: 0.143833
Train Epoch: 1 [4045824/8506302 (47.6%)]	Loss: 0.127218
Train Epoch: 1 [4097024/8506302 (48.2%)]	Loss: 0.122796
Train Epoch: 1 [4148224/8506302 (48.8%)]	Loss: 0.119677
Train Epoch: 1 [4199424/8506302 (49.4%)]	Loss: 0.127590
Train Epoch: 1 [4250624/8506302 (50.0%)]	Loss: 0.134788
Train Epoch: 1 [4301824/8506302 (50.6%)]	Loss: 0.123114
Train Epoch: 1 [4353024/8506302 (51.2%)]	Loss: 0.136894
Train Epoch: 1 [4404224/8506302 (51.8%)]	Loss: 0.118107
Train Epoch: 1 [4455424/8506302 (52.4%)]	Loss: 0.112516
Train Epoch: 1 [4506624/8506302 (53.0%)]	Loss: 0.133009
Train Epoch: 1 [4557824/8506302 (53.6%)]	Loss: 0.125239
Train Epoch: 1 [4609024/8506302 (54.2%)]	Loss: 0.125782
Train Epoch: 1 [4660224/8506302 (54.8%)]	Loss: 0.125288
Train Epoch: 1 [4711424/8506302 (55.4%)]	Loss: 0.130779
Train Epoch: 1 [4762624/8506302 (56.0%)]	Loss: 0.113983
Train Epoch: 1 [4813824/8506302 (56.6%)]	Loss: 0.121434
Train Epoch: 1 [4865024/8506302 (57.2%)]	Loss: 0.130072
Train Epoch: 1 [4916224/8506302 (57.8%)]	Loss: 0.105020
Train Epoch: 1 [4967424/8506302 (58.4%)]	Loss: 0.116644
Train Epoch: 1 [5018624/8506302 (59.0%)]	Loss: 0.111346
Train Epoch: 1 [5069824/8506302 (59.6%)]	Loss: 0.132875
Train Epoch: 1 [5121024/8506302 (60.2%)]	Loss: 0.131460
Train Epoch: 1 [5172224/8506302 (60.8%)]	Loss: 0.125572
Train Epoch: 1 [5223424/8506302 (61.4%)]	Loss: 0.132915
Train Epoch: 1 [5274624/8506302 (62.0%)]	Loss: 0.121406
Train Epoch: 1 [5325824/8506302 (62.6%)]	Loss: 0.121432
Train Epoch: 1 [5377024/8506302 (63.2%)]	Loss: 0.122737
Train Epoch: 1 [5428224/8506302 (63.8%)]	Loss: 0.123525
Train Epoch: 1 [5479424/8506302 (64.4%)]	Loss: 0.129851
Train Epoch: 1 [5530624/8506302 (65.0%)]	Loss: 0.122765
Train Epoch: 1 [5581824/8506302 (65.6%)]	Loss: 0.128083
Train Epoch: 1 [5633024/8506302 (66.2%)]	Loss: 0.123479
Train Epoch: 1 [5684224/8506302 (66.8%)]	Loss: 0.127497
Train Epoch: 1 [5735424/8506302 (67.4%)]	Loss: 0.129326
Train Epoch: 1 [5786624/8506302 (68.0%)]	Loss: 0.128612
Train Epoch: 1 [5837824/8506302 (68.6%)]	Loss: 0.116873
Train Epoch: 1 [5889024/8506302 (69.2%)]	Loss: 0.115663
Train Epoch: 1 [5940224/8506302 (69.8%)]	Loss: 0.113853
Train Epoch: 1 [5991424/8506302 (70.4%)]	Loss: 0.124946
Train Epoch: 1 [6042624/8506302 (71.0%)]	Loss: 0.124499
Train Epoch: 1 [6093824/8506302 (71.6%)]	Loss: 0.121433
Train Epoch: 1 [6145024/8506302 (72.2%)]	Loss: 0.111562
Train Epoch: 1 [6196224/8506302 (72.8%)]	Loss: 0.124185
Train Epoch: 1 [6247424/8506302 (73.4%)]	Loss: 0.132387
Train Epoch: 1 [6298624/8506302 (74.0%)]	Loss: 0.132107
Train Epoch: 1 [6349824/8506302 (74.6%)]	Loss: 0.130930
Train Epoch: 1 [6401024/8506302 (75.3%)]	Loss: 0.127794
Train Epoch: 1 [6452224/8506302 (75.9%)]	Loss: 0.117967
Train Epoch: 1 [6503424/8506302 (76.5%)]	Loss: 0.131504
Train Epoch: 1 [6554624/8506302 (77.1%)]	Loss: 0.126100
Train Epoch: 1 [6605824/8506302 (77.7%)]	Loss: 0.125131
Train Epoch: 1 [6657024/8506302 (78.3%)]	Loss: 0.136122
Train Epoch: 1 [6708224/8506302 (78.9%)]	Loss: 0.127599
Train Epoch: 1 [6759424/8506302 (79.5%)]	Loss: 0.119566
Train Epoch: 1 [6810624/8506302 (80.1%)]	Loss: 0.116669
Train Epoch: 1 [6861824/8506302 (80.7%)]	Loss: 0.121751
Train Epoch: 1 [6913024/8506302 (81.3%)]	Loss: 0.115788
Train Epoch: 1 [6964224/8506302 (81.9%)]	Loss: 0.131556
Train Epoch: 1 [7015424/8506302 (82.5%)]	Loss: 0.123620
Train Epoch: 1 [7066624/8506302 (83.1%)]	Loss: 0.140549
Train Epoch: 1 [7117824/8506302 (83.7%)]	Loss: 0.124473
Train Epoch: 1 [7169024/8506302 (84.3%)]	Loss: 0.107253
Train Epoch: 1 [7220224/8506302 (84.9%)]	Loss: 0.117972
Train Epoch: 1 [7271424/8506302 (85.5%)]	Loss: 0.127528
Train Epoch: 1 [7322624/8506302 (86.1%)]	Loss: 0.118127
Train Epoch: 1 [7373824/8506302 (86.7%)]	Loss: 0.142688
Train Epoch: 1 [7425024/8506302 (87.3%)]	Loss: 0.104169
Train Epoch: 1 [7476224/8506302 (87.9%)]	Loss: 0.123951
Train Epoch: 1 [7527424/8506302 (88.5%)]	Loss: 0.120319
Train Epoch: 1 [7578624/8506302 (89.1%)]	Loss: 0.137570
Train Epoch: 1 [7629824/8506302 (89.7%)]	Loss: 0.118803
Train Epoch: 1 [7681024/8506302 (90.3%)]	Loss: 0.115543
Train Epoch: 1 [7732224/8506302 (90.9%)]	Loss: 0.127782
Train Epoch: 1 [7783424/8506302 (91.5%)]	Loss: 0.116578
Train Epoch: 1 [7834624/8506302 (92.1%)]	Loss: 0.126463
Train Epoch: 1 [7885824/8506302 (92.7%)]	Loss: 0.134760
Train Epoch: 1 [7937024/8506302 (93.3%)]	Loss: 0.114732
Train Epoch: 1 [7988224/8506302 (93.9%)]	Loss: 0.128743
Train Epoch: 1 [8039424/8506302 (94.5%)]	Loss: 0.114346
Train Epoch: 1 [8090624/8506302 (95.1%)]	Loss: 0.109239
Train Epoch: 1 [8141824/8506302 (95.7%)]	Loss: 0.128856
Train Epoch: 1 [8193024/8506302 (96.3%)]	Loss: 0.118407
Train Epoch: 1 [8244224/8506302 (96.9%)]	Loss: 0.119034
Train Epoch: 1 [8295424/8506302 (97.5%)]	Loss: 0.116707
Train Epoch: 1 [8346624/8506302 (98.1%)]	Loss: 0.134389
Train Epoch: 1 [8397824/8506302 (98.7%)]	Loss: 0.116412
Train Epoch: 1 [8449024/8506302 (99.3%)]	Loss: 0.123388
Train Epoch: 1 [8500224/8506302 (99.9%)]	Loss: 0.122586
Train Epoch: 2 [1024/8506302 (0.0%)]	Loss: 0.133497
Train Epoch: 2 [52224/8506302 (0.6%)]	Loss: 0.113323
Train Epoch: 2 [103424/8506302 (1.2%)]	Loss: 0.118043
Train Epoch: 2 [154624/8506302 (1.8%)]	Loss: 0.129750
Train Epoch: 2 [205824/8506302 (2.4%)]	Loss: 0.127634
Train Epoch: 2 [257024/8506302 (3.0%)]	Loss: 0.132536
Train Epoch: 2 [308224/8506302 (3.6%)]	Loss: 0.120563
Train Epoch: 2 [359424/8506302 (4.2%)]	Loss: 0.136694
Train Epoch: 2 [410624/8506302 (4.8%)]	Loss: 0.120655
Train Epoch: 2 [461824/8506302 (5.4%)]	Loss: 0.128747
Train Epoch: 2 [513024/8506302 (6.0%)]	Loss: 0.133290
Train Epoch: 2 [564224/8506302 (6.6%)]	Loss: 0.116082
Train Epoch: 2 [615424/8506302 (7.2%)]	Loss: 0.108315
Train Epoch: 2 [666624/8506302 (7.8%)]	Loss: 0.117363
Train Epoch: 2 [717824/8506302 (8.4%)]	Loss: 0.112611
Train Epoch: 2 [769024/8506302 (9.0%)]	Loss: 0.114880
Train Epoch: 2 [820224/8506302 (9.6%)]	Loss: 0.133993
Train Epoch: 2 [871424/8506302 (10.2%)]	Loss: 0.115838
Train Epoch: 2 [922624/8506302 (10.8%)]	Loss: 0.124226
Train Epoch: 2 [973824/8506302 (11.4%)]	Loss: 0.111673
Train Epoch: 2 [1025024/8506302 (12.1%)]	Loss: 0.121301
Train Epoch: 2 [1076224/8506302 (12.7%)]	Loss: 0.119719
Train Epoch: 2 [1127424/8506302 (13.3%)]	Loss: 0.120780
Train Epoch: 2 [1178624/8506302 (13.9%)]	Loss: 0.116296
Train Epoch: 2 [1229824/8506302 (14.5%)]	Loss: 0.124330
Train Epoch: 2 [1281024/8506302 (15.1%)]	Loss: 0.132426
Train Epoch: 2 [1332224/8506302 (15.7%)]	Loss: 0.120500
Train Epoch: 2 [1383424/8506302 (16.3%)]	Loss: 0.114928
Train Epoch: 2 [1434624/8506302 (16.9%)]	Loss: 0.131648
Train Epoch: 2 [1485824/8506302 (17.5%)]	Loss: 0.125236
Train Epoch: 2 [1537024/8506302 (18.1%)]	Loss: 0.121477
Train Epoch: 2 [1588224/8506302 (18.7%)]	Loss: 0.126807
Train Epoch: 2 [1639424/8506302 (19.3%)]	Loss: 0.128975
Train Epoch: 2 [1690624/8506302 (19.9%)]	Loss: 0.117605
Train Epoch: 2 [1741824/8506302 (20.5%)]	Loss: 0.109938
Train Epoch: 2 [1793024/8506302 (21.1%)]	Loss: 0.118992
Train Epoch: 2 [1844224/8506302 (21.7%)]	Loss: 0.118287
Train Epoch: 2 [1895424/8506302 (22.3%)]	Loss: 0.111548
Train Epoch: 2 [1946624/8506302 (22.9%)]	Loss: 0.117584
Train Epoch: 2 [1997824/8506302 (23.5%)]	Loss: 0.123053
Train Epoch: 2 [2049024/8506302 (24.1%)]	Loss: 0.133298
Train Epoch: 2 [2100224/8506302 (24.7%)]	Loss: 0.142313
Train Epoch: 2 [2151424/8506302 (25.3%)]	Loss: 0.108728
Train Epoch: 2 [2202624/8506302 (25.9%)]	Loss: 0.133394
Train Epoch: 2 [2253824/8506302 (26.5%)]	Loss: 0.125523
Train Epoch: 2 [2305024/8506302 (27.1%)]	Loss: 0.117327
Train Epoch: 2 [2356224/8506302 (27.7%)]	Loss: 0.126380
Train Epoch: 2 [2407424/8506302 (28.3%)]	Loss: 0.126542
Train Epoch: 2 [2458624/8506302 (28.9%)]	Loss: 0.119227
Train Epoch: 2 [2509824/8506302 (29.5%)]	Loss: 0.118517
Train Epoch: 2 [2561024/8506302 (30.1%)]	Loss: 0.115276
Train Epoch: 2 [2612224/8506302 (30.7%)]	Loss: 0.107421
Train Epoch: 2 [2663424/8506302 (31.3%)]	Loss: 0.122544
Train Epoch: 2 [2714624/8506302 (31.9%)]	Loss: 0.114441
Train Epoch: 2 [2765824/8506302 (32.5%)]	Loss: 0.118751
Train Epoch: 2 [2817024/8506302 (33.1%)]	Loss: 0.114164
Train Epoch: 2 [2868224/8506302 (33.7%)]	Loss: 0.131436
Train Epoch: 2 [2919424/8506302 (34.3%)]	Loss: 0.109718
Train Epoch: 2 [2970624/8506302 (34.9%)]	Loss: 0.120639
Train Epoch: 2 [3021824/8506302 (35.5%)]	Loss: 0.110141
Train Epoch: 2 [3073024/8506302 (36.1%)]	Loss: 0.124046
Train Epoch: 2 [3124224/8506302 (36.7%)]	Loss: 0.111192
Train Epoch: 2 [3175424/8506302 (37.3%)]	Loss: 0.121533
Train Epoch: 2 [3226624/8506302 (37.9%)]	Loss: 0.116835
Train Epoch: 2 [3277824/8506302 (38.5%)]	Loss: 0.130855
Train Epoch: 2 [3329024/8506302 (39.1%)]	Loss: 0.124681
Train Epoch: 2 [3380224/8506302 (39.7%)]	Loss: 0.130464
Train Epoch: 2 [3431424/8506302 (40.3%)]	Loss: 0.117900
Train Epoch: 2 [3482624/8506302 (40.9%)]	Loss: 0.119749
Train Epoch: 2 [3533824/8506302 (41.5%)]	Loss: 0.132718
Train Epoch: 2 [3585024/8506302 (42.1%)]	Loss: 0.121417
Train Epoch: 2 [3636224/8506302 (42.7%)]	Loss: 0.113660
Train Epoch: 2 [3687424/8506302 (43.3%)]	Loss: 0.133766
Train Epoch: 2 [3738624/8506302 (44.0%)]	Loss: 0.133422
Train Epoch: 2 [3789824/8506302 (44.6%)]	Loss: 0.094670
Train Epoch: 2 [3841024/8506302 (45.2%)]	Loss: 0.134996
Train Epoch: 2 [3892224/8506302 (45.8%)]	Loss: 0.126612
Train Epoch: 2 [3943424/8506302 (46.4%)]	Loss: 0.128960
Train Epoch: 2 [3994624/8506302 (47.0%)]	Loss: 0.110579
Train Epoch: 2 [4045824/8506302 (47.6%)]	Loss: 0.122832
Train Epoch: 2 [4097024/8506302 (48.2%)]	Loss: 0.130421
Train Epoch: 2 [4148224/8506302 (48.8%)]	Loss: 0.107195
Train Epoch: 2 [4199424/8506302 (49.4%)]	Loss: 0.117559
Train Epoch: 2 [4250624/8506302 (50.0%)]	Loss: 0.105056
Train Epoch: 2 [4301824/8506302 (50.6%)]	Loss: 0.127168
Train Epoch: 2 [4353024/8506302 (51.2%)]	Loss: 0.122184
Train Epoch: 2 [4404224/8506302 (51.8%)]	Loss: 0.113374
Train Epoch: 2 [4455424/8506302 (52.4%)]	Loss: 0.116451
Train Epoch: 2 [4506624/8506302 (53.0%)]	Loss: 0.129991
Train Epoch: 2 [4557824/8506302 (53.6%)]	Loss: 0.121430
Train Epoch: 2 [4609024/8506302 (54.2%)]	Loss: 0.104399
Train Epoch: 2 [4660224/8506302 (54.8%)]	Loss: 0.119711
Train Epoch: 2 [4711424/8506302 (55.4%)]	Loss: 0.133585
Train Epoch: 2 [4762624/8506302 (56.0%)]	Loss: 0.121075
Train Epoch: 2 [4813824/8506302 (56.6%)]	Loss: 0.113781
Train Epoch: 2 [4865024/8506302 (57.2%)]	Loss: 0.119588
Train Epoch: 2 [4916224/8506302 (57.8%)]	Loss: 0.120544
Train Epoch: 2 [4967424/8506302 (58.4%)]	Loss: 0.123742
Train Epoch: 2 [5018624/8506302 (59.0%)]	Loss: 0.127427
Train Epoch: 2 [5069824/8506302 (59.6%)]	Loss: 0.123680
Train Epoch: 2 [5121024/8506302 (60.2%)]	Loss: 0.119095
Train Epoch: 2 [5172224/8506302 (60.8%)]	Loss: 0.123679
Train Epoch: 2 [5223424/8506302 (61.4%)]	Loss: 0.121288
Train Epoch: 2 [5274624/8506302 (62.0%)]	Loss: 0.122423
Train Epoch: 2 [5325824/8506302 (62.6%)]	Loss: 0.111636
Train Epoch: 2 [5377024/8506302 (63.2%)]	Loss: 0.107124
Train Epoch: 2 [5428224/8506302 (63.8%)]	Loss: 0.114002
Train Epoch: 2 [5479424/8506302 (64.4%)]	Loss: 0.106087
Train Epoch: 2 [5530624/8506302 (65.0%)]	Loss: 0.116379
Train Epoch: 2 [5581824/8506302 (65.6%)]	Loss: 0.111064
Train Epoch: 2 [5633024/8506302 (66.2%)]	Loss: 0.127909
Train Epoch: 2 [5684224/8506302 (66.8%)]	Loss: 0.106225
Train Epoch: 2 [5735424/8506302 (67.4%)]	Loss: 0.139087
Train Epoch: 2 [5786624/8506302 (68.0%)]	Loss: 0.129196
Train Epoch: 2 [5837824/8506302 (68.6%)]	Loss: 0.122003
Train Epoch: 2 [5889024/8506302 (69.2%)]	Loss: 0.132512
Train Epoch: 2 [5940224/8506302 (69.8%)]	Loss: 0.120156
Train Epoch: 2 [5991424/8506302 (70.4%)]	Loss: 0.107924
Train Epoch: 2 [6042624/8506302 (71.0%)]	Loss: 0.114877
Train Epoch: 2 [6093824/8506302 (71.6%)]	Loss: 0.121714
Train Epoch: 2 [6145024/8506302 (72.2%)]	Loss: 0.112295
Train Epoch: 2 [6196224/8506302 (72.8%)]	Loss: 0.126690
Train Epoch: 2 [6247424/8506302 (73.4%)]	Loss: 0.107544
Train Epoch: 2 [6298624/8506302 (74.0%)]	Loss: 0.124171
Train Epoch: 2 [6349824/8506302 (74.6%)]	Loss: 0.122769
Train Epoch: 2 [6401024/8506302 (75.3%)]	Loss: 0.121782
Train Epoch: 2 [6452224/8506302 (75.9%)]	Loss: 0.127029
Train Epoch: 2 [6503424/8506302 (76.5%)]	Loss: 0.124300
Train Epoch: 2 [6554624/8506302 (77.1%)]	Loss: 0.127372
Train Epoch: 2 [6605824/8506302 (77.7%)]	Loss: 0.117575
Train Epoch: 2 [6657024/8506302 (78.3%)]	Loss: 0.111314
Train Epoch: 2 [6708224/8506302 (78.9%)]	Loss: 0.109716
Train Epoch: 2 [6759424/8506302 (79.5%)]	Loss: 0.101039
Train Epoch: 2 [6810624/8506302 (80.1%)]	Loss: 0.120765
Train Epoch: 2 [6861824/8506302 (80.7%)]	Loss: 0.109493
Train Epoch: 2 [6913024/8506302 (81.3%)]	Loss: 0.121113
Train Epoch: 2 [6964224/8506302 (81.9%)]	Loss: 0.106781
Train Epoch: 2 [7015424/8506302 (82.5%)]	Loss: 0.111004
Train Epoch: 2 [7066624/8506302 (83.1%)]	Loss: 0.130430
Train Epoch: 2 [7117824/8506302 (83.7%)]	Loss: 0.105948
Train Epoch: 2 [7169024/8506302 (84.3%)]	Loss: 0.130158
Train Epoch: 2 [7220224/8506302 (84.9%)]	Loss: 0.130676
Train Epoch: 2 [7271424/8506302 (85.5%)]	Loss: 0.120437
Train Epoch: 2 [7322624/8506302 (86.1%)]	Loss: 0.123859
Train Epoch: 2 [7373824/8506302 (86.7%)]	Loss: 0.123684
Train Epoch: 2 [7425024/8506302 (87.3%)]	Loss: 0.126387
Train Epoch: 2 [7476224/8506302 (87.9%)]	Loss: 0.127678
Train Epoch: 2 [7527424/8506302 (88.5%)]	Loss: 0.116251
Train Epoch: 2 [7578624/8506302 (89.1%)]	Loss: 0.127367
Train Epoch: 2 [7629824/8506302 (89.7%)]	Loss: 0.123096
Train Epoch: 2 [7681024/8506302 (90.3%)]	Loss: 0.115797
Train Epoch: 2 [7732224/8506302 (90.9%)]	Loss: 0.104477
Train Epoch: 2 [7783424/8506302 (91.5%)]	Loss: 0.108539
Train Epoch: 2 [7834624/8506302 (92.1%)]	Loss: 0.133085
Train Epoch: 2 [7885824/8506302 (92.7%)]	Loss: 0.123406
Train Epoch: 2 [7937024/8506302 (93.3%)]	Loss: 0.125844
Train Epoch: 2 [7988224/8506302 (93.9%)]	Loss: 0.111876
Train Epoch: 2 [8039424/8506302 (94.5%)]	Loss: 0.113159
Train Epoch: 2 [8090624/8506302 (95.1%)]	Loss: 0.112366
Train Epoch: 2 [8141824/8506302 (95.7%)]	Loss: 0.118506
Train Epoch: 2 [8193024/8506302 (96.3%)]	Loss: 0.118557
Train Epoch: 2 [8244224/8506302 (96.9%)]	Loss: 0.125762
Train Epoch: 2 [8295424/8506302 (97.5%)]	Loss: 0.130480
Train Epoch: 2 [8346624/8506302 (98.1%)]	Loss: 0.122219
Train Epoch: 2 [8397824/8506302 (98.7%)]	Loss: 0.112798
Train Epoch: 2 [8449024/8506302 (99.3%)]	Loss: 0.122201
Train Epoch: 2 [8500224/8506302 (99.9%)]	Loss: 0.113530

 ---------------------------------------------------------------------- 


ACC in fold#2 was 0.888


Confusion Matrix in fold#2: 
           nonRipple   Ripple
nonRipple     642141   155107
Ripple         83063  1246264


Classification Report in fold#2: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.885        0.889     0.888        0.887         0.888
recall            0.805        0.938     0.888        0.871         0.888
f1-score          0.844        0.913     0.888        0.878         0.887
sample size  797248.000  1329327.000     0.888  2126575.000   2126575.000


PR_AUC in fold#2 was 0.975


ROC_AUC in fold#2 was 0.961

Time (id:3): tot 11:09:33, prev 03:42:53 [hh:mm:ss]: 
i_fold=2 ends.



 ---------------------------------------------------------------------- 

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8506302 (0.0%)]	Loss: 0.368608
Train Epoch: 1 [52224/8506302 (0.6%)]	Loss: 0.172132
Train Epoch: 1 [103424/8506302 (1.2%)]	Loss: 0.130133
Train Epoch: 1 [154624/8506302 (1.8%)]	Loss: 0.126781
Train Epoch: 1 [205824/8506302 (2.4%)]	Loss: 0.139107
Train Epoch: 1 [257024/8506302 (3.0%)]	Loss: 0.137509
Train Epoch: 1 [308224/8506302 (3.6%)]	Loss: 0.128459
Train Epoch: 1 [359424/8506302 (4.2%)]	Loss: 0.128951
Train Epoch: 1 [410624/8506302 (4.8%)]	Loss: 0.137404
Train Epoch: 1 [461824/8506302 (5.4%)]	Loss: 0.122812
Train Epoch: 1 [513024/8506302 (6.0%)]	Loss: 0.136104
Train Epoch: 1 [564224/8506302 (6.6%)]	Loss: 0.136068
Train Epoch: 1 [615424/8506302 (7.2%)]	Loss: 0.121099
Train Epoch: 1 [666624/8506302 (7.8%)]	Loss: 0.135615
Train Epoch: 1 [717824/8506302 (8.4%)]	Loss: 0.127820
Train Epoch: 1 [769024/8506302 (9.0%)]	Loss: 0.123432
Train Epoch: 1 [820224/8506302 (9.6%)]	Loss: 0.139610
Train Epoch: 1 [871424/8506302 (10.2%)]	Loss: 0.127586
Train Epoch: 1 [922624/8506302 (10.8%)]	Loss: 0.125315
Train Epoch: 1 [973824/8506302 (11.4%)]	Loss: 0.130894
Train Epoch: 1 [1025024/8506302 (12.1%)]	Loss: 0.136979
Train Epoch: 1 [1076224/8506302 (12.7%)]	Loss: 0.137167
Train Epoch: 1 [1127424/8506302 (13.3%)]	Loss: 0.123697
Train Epoch: 1 [1178624/8506302 (13.9%)]	Loss: 0.136082
Train Epoch: 1 [1229824/8506302 (14.5%)]	Loss: 0.126636
Train Epoch: 1 [1281024/8506302 (15.1%)]	Loss: 0.123431
Train Epoch: 1 [1332224/8506302 (15.7%)]	Loss: 0.133832
Train Epoch: 1 [1383424/8506302 (16.3%)]	Loss: 0.110653
Train Epoch: 1 [1434624/8506302 (16.9%)]	Loss: 0.139482
Train Epoch: 1 [1485824/8506302 (17.5%)]	Loss: 0.122113
Train Epoch: 1 [1537024/8506302 (18.1%)]	Loss: 0.128951
Train Epoch: 1 [1588224/8506302 (18.7%)]	Loss: 0.115386
Train Epoch: 1 [1639424/8506302 (19.3%)]	Loss: 0.127227
Train Epoch: 1 [1690624/8506302 (19.9%)]	Loss: 0.113045
Train Epoch: 1 [1741824/8506302 (20.5%)]	Loss: 0.122892
Train Epoch: 1 [1793024/8506302 (21.1%)]	Loss: 0.117089
Train Epoch: 1 [1844224/8506302 (21.7%)]	Loss: 0.111055
Train Epoch: 1 [1895424/8506302 (22.3%)]	Loss: 0.128684
Train Epoch: 1 [1946624/8506302 (22.9%)]	Loss: 0.122628
Train Epoch: 1 [1997824/8506302 (23.5%)]	Loss: 0.118215
Train Epoch: 1 [2049024/8506302 (24.1%)]	Loss: 0.144946
Train Epoch: 1 [2100224/8506302 (24.7%)]	Loss: 0.130041
Train Epoch: 1 [2151424/8506302 (25.3%)]	Loss: 0.114371
Train Epoch: 1 [2202624/8506302 (25.9%)]	Loss: 0.136424
Train Epoch: 1 [2253824/8506302 (26.5%)]	Loss: 0.116704
Train Epoch: 1 [2305024/8506302 (27.1%)]	Loss: 0.119928
Train Epoch: 1 [2356224/8506302 (27.7%)]	Loss: 0.129936
Train Epoch: 1 [2407424/8506302 (28.3%)]	Loss: 0.118263
Train Epoch: 1 [2458624/8506302 (28.9%)]	Loss: 0.137504
Train Epoch: 1 [2509824/8506302 (29.5%)]	Loss: 0.115390
Train Epoch: 1 [2561024/8506302 (30.1%)]	Loss: 0.129134
Train Epoch: 1 [2612224/8506302 (30.7%)]	Loss: 0.125117
Train Epoch: 1 [2663424/8506302 (31.3%)]	Loss: 0.105736
Train Epoch: 1 [2714624/8506302 (31.9%)]	Loss: 0.131733
Train Epoch: 1 [2765824/8506302 (32.5%)]	Loss: 0.146838
Train Epoch: 1 [2817024/8506302 (33.1%)]	Loss: 0.114509
Train Epoch: 1 [2868224/8506302 (33.7%)]	Loss: 0.117627
Train Epoch: 1 [2919424/8506302 (34.3%)]	Loss: 0.124251
Train Epoch: 1 [2970624/8506302 (34.9%)]	Loss: 0.127313
Train Epoch: 1 [3021824/8506302 (35.5%)]	Loss: 0.136584
Train Epoch: 1 [3073024/8506302 (36.1%)]	Loss: 0.124051
Train Epoch: 1 [3124224/8506302 (36.7%)]	Loss: 0.131261
Train Epoch: 1 [3175424/8506302 (37.3%)]	Loss: 0.117672
Train Epoch: 1 [3226624/8506302 (37.9%)]	Loss: 0.119371
Train Epoch: 1 [3277824/8506302 (38.5%)]	Loss: 0.116073
Train Epoch: 1 [3329024/8506302 (39.1%)]	Loss: 0.116596
Train Epoch: 1 [3380224/8506302 (39.7%)]	Loss: 0.146279
Train Epoch: 1 [3431424/8506302 (40.3%)]	Loss: 0.113747
Train Epoch: 1 [3482624/8506302 (40.9%)]	Loss: 0.145391
Train Epoch: 1 [3533824/8506302 (41.5%)]	Loss: 0.129119
Train Epoch: 1 [3585024/8506302 (42.1%)]	Loss: 0.111505
Train Epoch: 1 [3636224/8506302 (42.7%)]	Loss: 0.120988
Train Epoch: 1 [3687424/8506302 (43.3%)]	Loss: 0.124207
Train Epoch: 1 [3738624/8506302 (44.0%)]	Loss: 0.119063
Train Epoch: 1 [3789824/8506302 (44.6%)]	Loss: 0.129547
Train Epoch: 1 [3841024/8506302 (45.2%)]	Loss: 0.113153
Train Epoch: 1 [3892224/8506302 (45.8%)]	Loss: 0.124471
Train Epoch: 1 [3943424/8506302 (46.4%)]	Loss: 0.114148
Train Epoch: 1 [3994624/8506302 (47.0%)]	Loss: 0.129508
Train Epoch: 1 [4045824/8506302 (47.6%)]	Loss: 0.132223
Train Epoch: 1 [4097024/8506302 (48.2%)]	Loss: 0.135504
Train Epoch: 1 [4148224/8506302 (48.8%)]	Loss: 0.121016
Train Epoch: 1 [4199424/8506302 (49.4%)]	Loss: 0.120002
Train Epoch: 1 [4250624/8506302 (50.0%)]	Loss: 0.124414
Train Epoch: 1 [4301824/8506302 (50.6%)]	Loss: 0.117978
Train Epoch: 1 [4353024/8506302 (51.2%)]	Loss: 0.132623
Train Epoch: 1 [4404224/8506302 (51.8%)]	Loss: 0.121246
Train Epoch: 1 [4455424/8506302 (52.4%)]	Loss: 0.130448
Train Epoch: 1 [4506624/8506302 (53.0%)]	Loss: 0.136468
Train Epoch: 1 [4557824/8506302 (53.6%)]	Loss: 0.125766
Train Epoch: 1 [4609024/8506302 (54.2%)]	Loss: 0.116191
Train Epoch: 1 [4660224/8506302 (54.8%)]	Loss: 0.111409
Train Epoch: 1 [4711424/8506302 (55.4%)]	Loss: 0.118603
Train Epoch: 1 [4762624/8506302 (56.0%)]	Loss: 0.120317
Train Epoch: 1 [4813824/8506302 (56.6%)]	Loss: 0.122087
Train Epoch: 1 [4865024/8506302 (57.2%)]	Loss: 0.123364
Train Epoch: 1 [4916224/8506302 (57.8%)]	Loss: 0.127409
Train Epoch: 1 [4967424/8506302 (58.4%)]	Loss: 0.122765
Train Epoch: 1 [5018624/8506302 (59.0%)]	Loss: 0.118240
Train Epoch: 1 [5069824/8506302 (59.6%)]	Loss: 0.116266
Train Epoch: 1 [5121024/8506302 (60.2%)]	Loss: 0.110543
Train Epoch: 1 [5172224/8506302 (60.8%)]	Loss: 0.115117
Train Epoch: 1 [5223424/8506302 (61.4%)]	Loss: 0.107400
Train Epoch: 1 [5274624/8506302 (62.0%)]	Loss: 0.116904
Train Epoch: 1 [5325824/8506302 (62.6%)]	Loss: 0.142176
Train Epoch: 1 [5377024/8506302 (63.2%)]	Loss: 0.131187
Train Epoch: 1 [5428224/8506302 (63.8%)]	Loss: 0.125551
Train Epoch: 1 [5479424/8506302 (64.4%)]	Loss: 0.115890
Train Epoch: 1 [5530624/8506302 (65.0%)]	Loss: 0.118717
Train Epoch: 1 [5581824/8506302 (65.6%)]	Loss: 0.125644
Train Epoch: 1 [5633024/8506302 (66.2%)]	Loss: 0.109184
Train Epoch: 1 [5684224/8506302 (66.8%)]	Loss: 0.114476
Train Epoch: 1 [5735424/8506302 (67.4%)]	Loss: 0.124002
Train Epoch: 1 [5786624/8506302 (68.0%)]	Loss: 0.117023
Train Epoch: 1 [5837824/8506302 (68.6%)]	Loss: 0.117102
Train Epoch: 1 [5889024/8506302 (69.2%)]	Loss: 0.135560
Train Epoch: 1 [5940224/8506302 (69.8%)]	Loss: 0.125337
Train Epoch: 1 [5991424/8506302 (70.4%)]	Loss: 0.127843
Train Epoch: 1 [6042624/8506302 (71.0%)]	Loss: 0.124649
Train Epoch: 1 [6093824/8506302 (71.6%)]	Loss: 0.120798
Train Epoch: 1 [6145024/8506302 (72.2%)]	Loss: 0.116071
Train Epoch: 1 [6196224/8506302 (72.8%)]	Loss: 0.110145
Train Epoch: 1 [6247424/8506302 (73.4%)]	Loss: 0.138505
Train Epoch: 1 [6298624/8506302 (74.0%)]	Loss: 0.120153
Train Epoch: 1 [6349824/8506302 (74.6%)]	Loss: 0.130027
Train Epoch: 1 [6401024/8506302 (75.3%)]	Loss: 0.119551
Train Epoch: 1 [6452224/8506302 (75.9%)]	Loss: 0.140581
Train Epoch: 1 [6503424/8506302 (76.5%)]	Loss: 0.112646
Train Epoch: 1 [6554624/8506302 (77.1%)]	Loss: 0.128875
Train Epoch: 1 [6605824/8506302 (77.7%)]	Loss: 0.114380
Train Epoch: 1 [6657024/8506302 (78.3%)]	Loss: 0.106635
Train Epoch: 1 [6708224/8506302 (78.9%)]	Loss: 0.114662
Train Epoch: 1 [6759424/8506302 (79.5%)]	Loss: 0.125328
Train Epoch: 1 [6810624/8506302 (80.1%)]	Loss: 0.111729
Train Epoch: 1 [6861824/8506302 (80.7%)]	Loss: 0.127751
Train Epoch: 1 [6913024/8506302 (81.3%)]	Loss: 0.115356
Train Epoch: 1 [6964224/8506302 (81.9%)]	Loss: 0.112620
Train Epoch: 1 [7015424/8506302 (82.5%)]	Loss: 0.121190
Train Epoch: 1 [7066624/8506302 (83.1%)]	Loss: 0.119893
Train Epoch: 1 [7117824/8506302 (83.7%)]	Loss: 0.115403
Train Epoch: 1 [7169024/8506302 (84.3%)]	Loss: 0.129166
Train Epoch: 1 [7220224/8506302 (84.9%)]	Loss: 0.112258
Train Epoch: 1 [7271424/8506302 (85.5%)]	Loss: 0.120811
Train Epoch: 1 [7322624/8506302 (86.1%)]	Loss: 0.110339
Train Epoch: 1 [7373824/8506302 (86.7%)]	Loss: 0.132136
Train Epoch: 1 [7425024/8506302 (87.3%)]	Loss: 0.120400
Train Epoch: 1 [7476224/8506302 (87.9%)]	Loss: 0.142898
Train Epoch: 1 [7527424/8506302 (88.5%)]	Loss: 0.115873
Train Epoch: 1 [7578624/8506302 (89.1%)]	Loss: 0.120912
Train Epoch: 1 [7629824/8506302 (89.7%)]	Loss: 0.118210
Train Epoch: 1 [7681024/8506302 (90.3%)]	Loss: 0.113124
Train Epoch: 1 [7732224/8506302 (90.9%)]	Loss: 0.114142
Train Epoch: 1 [7783424/8506302 (91.5%)]	Loss: 0.122099
Train Epoch: 1 [7834624/8506302 (92.1%)]	Loss: 0.118929
Train Epoch: 1 [7885824/8506302 (92.7%)]	Loss: 0.121088
Train Epoch: 1 [7937024/8506302 (93.3%)]	Loss: 0.123187
Train Epoch: 1 [7988224/8506302 (93.9%)]	Loss: 0.116094
Train Epoch: 1 [8039424/8506302 (94.5%)]	Loss: 0.120224
Train Epoch: 1 [8090624/8506302 (95.1%)]	Loss: 0.137895
Train Epoch: 1 [8141824/8506302 (95.7%)]	Loss: 0.123464
Train Epoch: 1 [8193024/8506302 (96.3%)]	Loss: 0.135006
Train Epoch: 1 [8244224/8506302 (96.9%)]	Loss: 0.115588
Train Epoch: 1 [8295424/8506302 (97.5%)]	Loss: 0.118324
Train Epoch: 1 [8346624/8506302 (98.1%)]	Loss: 0.110476
Train Epoch: 1 [8397824/8506302 (98.7%)]	Loss: 0.118020
Train Epoch: 1 [8449024/8506302 (99.3%)]	Loss: 0.121427
Train Epoch: 1 [8500224/8506302 (99.9%)]	Loss: 0.127210
Train Epoch: 2 [1024/8506302 (0.0%)]	Loss: 0.106753
Train Epoch: 2 [52224/8506302 (0.6%)]	Loss: 0.114037
Train Epoch: 2 [103424/8506302 (1.2%)]	Loss: 0.114359
Train Epoch: 2 [154624/8506302 (1.8%)]	Loss: 0.128221
Train Epoch: 2 [205824/8506302 (2.4%)]	Loss: 0.115880
Train Epoch: 2 [257024/8506302 (3.0%)]	Loss: 0.116759
Train Epoch: 2 [308224/8506302 (3.6%)]	Loss: 0.140623
Train Epoch: 2 [359424/8506302 (4.2%)]	Loss: 0.130555
Train Epoch: 2 [410624/8506302 (4.8%)]	Loss: 0.117730
Train Epoch: 2 [461824/8506302 (5.4%)]	Loss: 0.106856
Train Epoch: 2 [513024/8506302 (6.0%)]	Loss: 0.127763
Train Epoch: 2 [564224/8506302 (6.6%)]	Loss: 0.130128
Train Epoch: 2 [615424/8506302 (7.2%)]	Loss: 0.107661
Train Epoch: 2 [666624/8506302 (7.8%)]	Loss: 0.116904
Train Epoch: 2 [717824/8506302 (8.4%)]	Loss: 0.136815
Train Epoch: 2 [769024/8506302 (9.0%)]	Loss: 0.115017
Train Epoch: 2 [820224/8506302 (9.6%)]	Loss: 0.122506
Train Epoch: 2 [871424/8506302 (10.2%)]	Loss: 0.109165
Train Epoch: 2 [922624/8506302 (10.8%)]	Loss: 0.125295
Train Epoch: 2 [973824/8506302 (11.4%)]	Loss: 0.111303
Train Epoch: 2 [1025024/8506302 (12.1%)]	Loss: 0.115516
Train Epoch: 2 [1076224/8506302 (12.7%)]	Loss: 0.108979
Train Epoch: 2 [1127424/8506302 (13.3%)]	Loss: 0.108658
Train Epoch: 2 [1178624/8506302 (13.9%)]	Loss: 0.122185
Train Epoch: 2 [1229824/8506302 (14.5%)]	Loss: 0.115087
Train Epoch: 2 [1281024/8506302 (15.1%)]	Loss: 0.133969
Train Epoch: 2 [1332224/8506302 (15.7%)]	Loss: 0.115153
Train Epoch: 2 [1383424/8506302 (16.3%)]	Loss: 0.113841
Train Epoch: 2 [1434624/8506302 (16.9%)]	Loss: 0.111975
Train Epoch: 2 [1485824/8506302 (17.5%)]	Loss: 0.108350
Train Epoch: 2 [1537024/8506302 (18.1%)]	Loss: 0.125609
Train Epoch: 2 [1588224/8506302 (18.7%)]	Loss: 0.133454
Train Epoch: 2 [1639424/8506302 (19.3%)]	Loss: 0.124618
Train Epoch: 2 [1690624/8506302 (19.9%)]	Loss: 0.125110
Train Epoch: 2 [1741824/8506302 (20.5%)]	Loss: 0.121735
Train Epoch: 2 [1793024/8506302 (21.1%)]	Loss: 0.121781
Train Epoch: 2 [1844224/8506302 (21.7%)]	Loss: 0.110007
Train Epoch: 2 [1895424/8506302 (22.3%)]	Loss: 0.127700
Train Epoch: 2 [1946624/8506302 (22.9%)]	Loss: 0.108729
Train Epoch: 2 [1997824/8506302 (23.5%)]	Loss: 0.112999
Train Epoch: 2 [2049024/8506302 (24.1%)]	Loss: 0.114512
Train Epoch: 2 [2100224/8506302 (24.7%)]	Loss: 0.108699
Train Epoch: 2 [2151424/8506302 (25.3%)]	Loss: 0.114596
Train Epoch: 2 [2202624/8506302 (25.9%)]	Loss: 0.120591
Train Epoch: 2 [2253824/8506302 (26.5%)]	Loss: 0.112282
Train Epoch: 2 [2305024/8506302 (27.1%)]	Loss: 0.121091
Train Epoch: 2 [2356224/8506302 (27.7%)]	Loss: 0.118176
Train Epoch: 2 [2407424/8506302 (28.3%)]	Loss: 0.110132
Train Epoch: 2 [2458624/8506302 (28.9%)]	Loss: 0.114250
Train Epoch: 2 [2509824/8506302 (29.5%)]	Loss: 0.110882
Train Epoch: 2 [2561024/8506302 (30.1%)]	Loss: 0.113129
Train Epoch: 2 [2612224/8506302 (30.7%)]	Loss: 0.120512
Train Epoch: 2 [2663424/8506302 (31.3%)]	Loss: 0.109578
Train Epoch: 2 [2714624/8506302 (31.9%)]	Loss: 0.129874
Train Epoch: 2 [2765824/8506302 (32.5%)]	Loss: 0.138770
Train Epoch: 2 [2817024/8506302 (33.1%)]	Loss: 0.107734
Train Epoch: 2 [2868224/8506302 (33.7%)]	Loss: 0.113118
Train Epoch: 2 [2919424/8506302 (34.3%)]	Loss: 0.113391
Train Epoch: 2 [2970624/8506302 (34.9%)]	Loss: 0.128407
Train Epoch: 2 [3021824/8506302 (35.5%)]	Loss: 0.117994
Train Epoch: 2 [3073024/8506302 (36.1%)]	Loss: 0.125361
Train Epoch: 2 [3124224/8506302 (36.7%)]	Loss: 0.112720
Train Epoch: 2 [3175424/8506302 (37.3%)]	Loss: 0.118785
Train Epoch: 2 [3226624/8506302 (37.9%)]	Loss: 0.131332
Train Epoch: 2 [3277824/8506302 (38.5%)]	Loss: 0.126723
Train Epoch: 2 [3329024/8506302 (39.1%)]	Loss: 0.119741
Train Epoch: 2 [3380224/8506302 (39.7%)]	Loss: 0.128309
Train Epoch: 2 [3431424/8506302 (40.3%)]	Loss: 0.125673
Train Epoch: 2 [3482624/8506302 (40.9%)]	Loss: 0.112760
Train Epoch: 2 [3533824/8506302 (41.5%)]	Loss: 0.117097
Train Epoch: 2 [3585024/8506302 (42.1%)]	Loss: 0.115487
Train Epoch: 2 [3636224/8506302 (42.7%)]	Loss: 0.121000
Train Epoch: 2 [3687424/8506302 (43.3%)]	Loss: 0.114031
Train Epoch: 2 [3738624/8506302 (44.0%)]	Loss: 0.125017
Train Epoch: 2 [3789824/8506302 (44.6%)]	Loss: 0.127159
Train Epoch: 2 [3841024/8506302 (45.2%)]	Loss: 0.132513
Train Epoch: 2 [3892224/8506302 (45.8%)]	Loss: 0.114800
Train Epoch: 2 [3943424/8506302 (46.4%)]	Loss: 0.116508
Train Epoch: 2 [3994624/8506302 (47.0%)]	Loss: 0.104532
Train Epoch: 2 [4045824/8506302 (47.6%)]	Loss: 0.114513
Train Epoch: 2 [4097024/8506302 (48.2%)]	Loss: 0.122022
Train Epoch: 2 [4148224/8506302 (48.8%)]	Loss: 0.124622
Train Epoch: 2 [4199424/8506302 (49.4%)]	Loss: 0.115119
Train Epoch: 2 [4250624/8506302 (50.0%)]	Loss: 0.138514
Train Epoch: 2 [4301824/8506302 (50.6%)]	Loss: 0.111812
Train Epoch: 2 [4353024/8506302 (51.2%)]	Loss: 0.121731
Train Epoch: 2 [4404224/8506302 (51.8%)]	Loss: 0.120643
Train Epoch: 2 [4455424/8506302 (52.4%)]	Loss: 0.121827
Train Epoch: 2 [4506624/8506302 (53.0%)]	Loss: 0.127507
Train Epoch: 2 [4557824/8506302 (53.6%)]	Loss: 0.108528
Train Epoch: 2 [4609024/8506302 (54.2%)]	Loss: 0.137133
Train Epoch: 2 [4660224/8506302 (54.8%)]	Loss: 0.106468
Train Epoch: 2 [4711424/8506302 (55.4%)]	Loss: 0.111662
Train Epoch: 2 [4762624/8506302 (56.0%)]	Loss: 0.114903
Train Epoch: 2 [4813824/8506302 (56.6%)]	Loss: 0.118588
Train Epoch: 2 [4865024/8506302 (57.2%)]	Loss: 0.114377
Train Epoch: 2 [4916224/8506302 (57.8%)]	Loss: 0.117586
Train Epoch: 2 [4967424/8506302 (58.4%)]	Loss: 0.114062
Train Epoch: 2 [5018624/8506302 (59.0%)]	Loss: 0.122795
Train Epoch: 2 [5069824/8506302 (59.6%)]	Loss: 0.102277
Train Epoch: 2 [5121024/8506302 (60.2%)]	Loss: 0.119837
Train Epoch: 2 [5172224/8506302 (60.8%)]	Loss: 0.123959
Train Epoch: 2 [5223424/8506302 (61.4%)]	Loss: 0.112076
Train Epoch: 2 [5274624/8506302 (62.0%)]	Loss: 0.114682
Train Epoch: 2 [5325824/8506302 (62.6%)]	Loss: 0.127087
Train Epoch: 2 [5377024/8506302 (63.2%)]	Loss: 0.127302
Train Epoch: 2 [5428224/8506302 (63.8%)]	Loss: 0.108294
Train Epoch: 2 [5479424/8506302 (64.4%)]	Loss: 0.127634
Train Epoch: 2 [5530624/8506302 (65.0%)]	Loss: 0.122764
Train Epoch: 2 [5581824/8506302 (65.6%)]	Loss: 0.110222
Train Epoch: 2 [5633024/8506302 (66.2%)]	Loss: 0.104895
Train Epoch: 2 [5684224/8506302 (66.8%)]	Loss: 0.099293
Train Epoch: 2 [5735424/8506302 (67.4%)]	Loss: 0.111521
Train Epoch: 2 [5786624/8506302 (68.0%)]	Loss: 0.124704
Train Epoch: 2 [5837824/8506302 (68.6%)]	Loss: 0.116092
Train Epoch: 2 [5889024/8506302 (69.2%)]	Loss: 0.110517
Train Epoch: 2 [5940224/8506302 (69.8%)]	Loss: 0.118153
Train Epoch: 2 [5991424/8506302 (70.4%)]	Loss: 0.125409
Train Epoch: 2 [6042624/8506302 (71.0%)]	Loss: 0.130932
Train Epoch: 2 [6093824/8506302 (71.6%)]	Loss: 0.120144
Train Epoch: 2 [6145024/8506302 (72.2%)]	Loss: 0.120079
Train Epoch: 2 [6196224/8506302 (72.8%)]	Loss: 0.115712
Train Epoch: 2 [6247424/8506302 (73.4%)]	Loss: 0.115346
Train Epoch: 2 [6298624/8506302 (74.0%)]	Loss: 0.123067
Train Epoch: 2 [6349824/8506302 (74.6%)]	Loss: 0.119073
Train Epoch: 2 [6401024/8506302 (75.3%)]	Loss: 0.127470
Train Epoch: 2 [6452224/8506302 (75.9%)]	Loss: 0.105010
Train Epoch: 2 [6503424/8506302 (76.5%)]	Loss: 0.122200
Train Epoch: 2 [6554624/8506302 (77.1%)]	Loss: 0.128265
Train Epoch: 2 [6605824/8506302 (77.7%)]	Loss: 0.116937
Train Epoch: 2 [6657024/8506302 (78.3%)]	Loss: 0.120337
Train Epoch: 2 [6708224/8506302 (78.9%)]	Loss: 0.117680
Train Epoch: 2 [6759424/8506302 (79.5%)]	Loss: 0.130287
Train Epoch: 2 [6810624/8506302 (80.1%)]	Loss: 0.119475
Train Epoch: 2 [6861824/8506302 (80.7%)]	Loss: 0.114928
Train Epoch: 2 [6913024/8506302 (81.3%)]	Loss: 0.115470
Train Epoch: 2 [6964224/8506302 (81.9%)]	Loss: 0.109870
Train Epoch: 2 [7015424/8506302 (82.5%)]	Loss: 0.110106
Train Epoch: 2 [7066624/8506302 (83.1%)]	Loss: 0.124910
Train Epoch: 2 [7117824/8506302 (83.7%)]	Loss: 0.102911
Train Epoch: 2 [7169024/8506302 (84.3%)]	Loss: 0.124431
Train Epoch: 2 [7220224/8506302 (84.9%)]	Loss: 0.128220
Train Epoch: 2 [7271424/8506302 (85.5%)]	Loss: 0.107128
Train Epoch: 2 [7322624/8506302 (86.1%)]	Loss: 0.103701
Train Epoch: 2 [7373824/8506302 (86.7%)]	Loss: 0.101766
Train Epoch: 2 [7425024/8506302 (87.3%)]	Loss: 0.129435
Train Epoch: 2 [7476224/8506302 (87.9%)]	Loss: 0.111240
Train Epoch: 2 [7527424/8506302 (88.5%)]	Loss: 0.124663
Train Epoch: 2 [7578624/8506302 (89.1%)]	Loss: 0.129601
Train Epoch: 2 [7629824/8506302 (89.7%)]	Loss: 0.121589
Train Epoch: 2 [7681024/8506302 (90.3%)]	Loss: 0.122344
Train Epoch: 2 [7732224/8506302 (90.9%)]	Loss: 0.106358
Train Epoch: 2 [7783424/8506302 (91.5%)]	Loss: 0.108268
Train Epoch: 2 [7834624/8506302 (92.1%)]	Loss: 0.113615
Train Epoch: 2 [7885824/8506302 (92.7%)]	Loss: 0.108899
Train Epoch: 2 [7937024/8506302 (93.3%)]	Loss: 0.108062
Train Epoch: 2 [7988224/8506302 (93.9%)]	Loss: 0.120750
Train Epoch: 2 [8039424/8506302 (94.5%)]	Loss: 0.113043
Train Epoch: 2 [8090624/8506302 (95.1%)]	Loss: 0.114548
Train Epoch: 2 [8141824/8506302 (95.7%)]	Loss: 0.104470
Train Epoch: 2 [8193024/8506302 (96.3%)]	Loss: 0.125626
Train Epoch: 2 [8244224/8506302 (96.9%)]	Loss: 0.137812
Train Epoch: 2 [8295424/8506302 (97.5%)]	Loss: 0.108687
Train Epoch: 2 [8346624/8506302 (98.1%)]	Loss: 0.118705
Train Epoch: 2 [8397824/8506302 (98.7%)]	Loss: 0.134144
Train Epoch: 2 [8449024/8506302 (99.3%)]	Loss: 0.124608
Train Epoch: 2 [8500224/8506302 (99.9%)]	Loss: 0.125199

 ---------------------------------------------------------------------- 


ACC in fold#3 was 0.887


Confusion Matrix in fold#3: 
           nonRipple   Ripple
nonRipple     642005   155243
Ripple         86003  1243324


Classification Report in fold#3: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.882        0.889     0.887        0.885         0.886
recall            0.805        0.935     0.887        0.870         0.887
f1-score          0.842        0.912     0.887        0.877         0.885
sample size  797248.000  1329327.000     0.887  2126575.000   2126575.000


PR_AUC in fold#3 was 0.964


ROC_AUC in fold#3 was 0.953

Time (id:4): tot 14:53:34, prev 03:44:00 [hh:mm:ss]: 
i_fold=3 ends.



 ---------------------------------------------------------------------- 

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8506302 (0.0%)]	Loss: 0.370139
Train Epoch: 1 [52224/8506302 (0.6%)]	Loss: 0.186231
Train Epoch: 1 [103424/8506302 (1.2%)]	Loss: 0.139205
Train Epoch: 1 [154624/8506302 (1.8%)]	Loss: 0.143935
Train Epoch: 1 [205824/8506302 (2.4%)]	Loss: 0.134202
Train Epoch: 1 [257024/8506302 (3.0%)]	Loss: 0.134768
Train Epoch: 1 [308224/8506302 (3.6%)]	Loss: 0.139543
Train Epoch: 1 [359424/8506302 (4.2%)]	Loss: 0.136491
Train Epoch: 1 [410624/8506302 (4.8%)]	Loss: 0.133854
Train Epoch: 1 [461824/8506302 (5.4%)]	Loss: 0.124478
Train Epoch: 1 [513024/8506302 (6.0%)]	Loss: 0.132222
Train Epoch: 1 [564224/8506302 (6.6%)]	Loss: 0.132733
Train Epoch: 1 [615424/8506302 (7.2%)]	Loss: 0.124617
Train Epoch: 1 [666624/8506302 (7.8%)]	Loss: 0.135068
Train Epoch: 1 [717824/8506302 (8.4%)]	Loss: 0.130508
Train Epoch: 1 [769024/8506302 (9.0%)]	Loss: 0.140912
Train Epoch: 1 [820224/8506302 (9.6%)]	Loss: 0.121124
Train Epoch: 1 [871424/8506302 (10.2%)]	Loss: 0.132395
Train Epoch: 1 [922624/8506302 (10.8%)]	Loss: 0.139414
Train Epoch: 1 [973824/8506302 (11.4%)]	Loss: 0.138587
Train Epoch: 1 [1025024/8506302 (12.1%)]	Loss: 0.137929
Train Epoch: 1 [1076224/8506302 (12.7%)]	Loss: 0.140842
Train Epoch: 1 [1127424/8506302 (13.3%)]	Loss: 0.145109
Train Epoch: 1 [1178624/8506302 (13.9%)]	Loss: 0.131955
Train Epoch: 1 [1229824/8506302 (14.5%)]	Loss: 0.123808
Train Epoch: 1 [1281024/8506302 (15.1%)]	Loss: 0.131381
Train Epoch: 1 [1332224/8506302 (15.7%)]	Loss: 0.142800
Train Epoch: 1 [1383424/8506302 (16.3%)]	Loss: 0.127632
Train Epoch: 1 [1434624/8506302 (16.9%)]	Loss: 0.123624
Train Epoch: 1 [1485824/8506302 (17.5%)]	Loss: 0.111459
Train Epoch: 1 [1537024/8506302 (18.1%)]	Loss: 0.129795
Train Epoch: 1 [1588224/8506302 (18.7%)]	Loss: 0.130756
Train Epoch: 1 [1639424/8506302 (19.3%)]	Loss: 0.131160
Train Epoch: 1 [1690624/8506302 (19.9%)]	Loss: 0.111104
Train Epoch: 1 [1741824/8506302 (20.5%)]	Loss: 0.123612
Train Epoch: 1 [1793024/8506302 (21.1%)]	Loss: 0.131901
Train Epoch: 1 [1844224/8506302 (21.7%)]	Loss: 0.146749
Train Epoch: 1 [1895424/8506302 (22.3%)]	Loss: 0.124874
Train Epoch: 1 [1946624/8506302 (22.9%)]	Loss: 0.118735
Train Epoch: 1 [1997824/8506302 (23.5%)]	Loss: 0.124752
Train Epoch: 1 [2049024/8506302 (24.1%)]	Loss: 0.116309
Train Epoch: 1 [2100224/8506302 (24.7%)]	Loss: 0.127906
Train Epoch: 1 [2151424/8506302 (25.3%)]	Loss: 0.119374
Train Epoch: 1 [2202624/8506302 (25.9%)]	Loss: 0.127813
Train Epoch: 1 [2253824/8506302 (26.5%)]	Loss: 0.125389
Train Epoch: 1 [2305024/8506302 (27.1%)]	Loss: 0.119380
Train Epoch: 1 [2356224/8506302 (27.7%)]	Loss: 0.128093
Train Epoch: 1 [2407424/8506302 (28.3%)]	Loss: 0.148157
Train Epoch: 1 [2458624/8506302 (28.9%)]	Loss: 0.134158
Train Epoch: 1 [2509824/8506302 (29.5%)]	Loss: 0.124030
Train Epoch: 1 [2561024/8506302 (30.1%)]	Loss: 0.137694
Train Epoch: 1 [2612224/8506302 (30.7%)]	Loss: 0.120610
Train Epoch: 1 [2663424/8506302 (31.3%)]	Loss: 0.125280
Train Epoch: 1 [2714624/8506302 (31.9%)]	Loss: 0.133050
Train Epoch: 1 [2765824/8506302 (32.5%)]	Loss: 0.118515
Train Epoch: 1 [2817024/8506302 (33.1%)]	Loss: 0.121644
Train Epoch: 1 [2868224/8506302 (33.7%)]	Loss: 0.118861
Train Epoch: 1 [2919424/8506302 (34.3%)]	Loss: 0.114836
Train Epoch: 1 [2970624/8506302 (34.9%)]	Loss: 0.126022
Train Epoch: 1 [3021824/8506302 (35.5%)]	Loss: 0.119690
Train Epoch: 1 [3073024/8506302 (36.1%)]	Loss: 0.135920
Train Epoch: 1 [3124224/8506302 (36.7%)]	Loss: 0.129792
Train Epoch: 1 [3175424/8506302 (37.3%)]	Loss: 0.145776
Train Epoch: 1 [3226624/8506302 (37.9%)]	Loss: 0.118219
Train Epoch: 1 [3277824/8506302 (38.5%)]	Loss: 0.119600
Train Epoch: 1 [3329024/8506302 (39.1%)]	Loss: 0.121676
Train Epoch: 1 [3380224/8506302 (39.7%)]	Loss: 0.130252
Train Epoch: 1 [3431424/8506302 (40.3%)]	Loss: 0.144224
Train Epoch: 1 [3482624/8506302 (40.9%)]	Loss: 0.117272
Train Epoch: 1 [3533824/8506302 (41.5%)]	Loss: 0.121252
Train Epoch: 1 [3585024/8506302 (42.1%)]	Loss: 0.125885
Train Epoch: 1 [3636224/8506302 (42.7%)]	Loss: 0.137415
Train Epoch: 1 [3687424/8506302 (43.3%)]	Loss: 0.119317
Train Epoch: 1 [3738624/8506302 (44.0%)]	Loss: 0.132220
Train Epoch: 1 [3789824/8506302 (44.6%)]	Loss: 0.126332
Train Epoch: 1 [3841024/8506302 (45.2%)]	Loss: 0.129074
Train Epoch: 1 [3892224/8506302 (45.8%)]	Loss: 0.132162
Train Epoch: 1 [3943424/8506302 (46.4%)]	Loss: 0.118254
Train Epoch: 1 [3994624/8506302 (47.0%)]	Loss: 0.142910
Train Epoch: 1 [4045824/8506302 (47.6%)]	Loss: 0.114555
Train Epoch: 1 [4097024/8506302 (48.2%)]	Loss: 0.120141
Train Epoch: 1 [4148224/8506302 (48.8%)]	Loss: 0.137427
Train Epoch: 1 [4199424/8506302 (49.4%)]	Loss: 0.128993
Train Epoch: 1 [4250624/8506302 (50.0%)]	Loss: 0.129841
Train Epoch: 1 [4301824/8506302 (50.6%)]	Loss: 0.114737
Train Epoch: 1 [4353024/8506302 (51.2%)]	Loss: 0.123149
Train Epoch: 1 [4404224/8506302 (51.8%)]	Loss: 0.120700
Train Epoch: 1 [4455424/8506302 (52.4%)]	Loss: 0.127572
Train Epoch: 1 [4506624/8506302 (53.0%)]	Loss: 0.124614
Train Epoch: 1 [4557824/8506302 (53.6%)]	Loss: 0.134337
Train Epoch: 1 [4609024/8506302 (54.2%)]	Loss: 0.126818
Train Epoch: 1 [4660224/8506302 (54.8%)]	Loss: 0.139484
Train Epoch: 1 [4711424/8506302 (55.4%)]	Loss: 0.125001
Train Epoch: 1 [4762624/8506302 (56.0%)]	Loss: 0.129280
Train Epoch: 1 [4813824/8506302 (56.6%)]	Loss: 0.117089
Train Epoch: 1 [4865024/8506302 (57.2%)]	Loss: 0.115317
Train Epoch: 1 [4916224/8506302 (57.8%)]	Loss: 0.117859
Train Epoch: 1 [4967424/8506302 (58.4%)]	Loss: 0.114146
Train Epoch: 1 [5018624/8506302 (59.0%)]	Loss: 0.124658
Train Epoch: 1 [5069824/8506302 (59.6%)]	Loss: 0.137253
Train Epoch: 1 [5121024/8506302 (60.2%)]	Loss: 0.132384
Train Epoch: 1 [5172224/8506302 (60.8%)]	Loss: 0.134581
Train Epoch: 1 [5223424/8506302 (61.4%)]	Loss: 0.108927
Train Epoch: 1 [5274624/8506302 (62.0%)]	Loss: 0.129067
Train Epoch: 1 [5325824/8506302 (62.6%)]	Loss: 0.128181
Train Epoch: 1 [5377024/8506302 (63.2%)]	Loss: 0.118819
Train Epoch: 1 [5428224/8506302 (63.8%)]	Loss: 0.113649
Train Epoch: 1 [5479424/8506302 (64.4%)]	Loss: 0.129980
Train Epoch: 1 [5530624/8506302 (65.0%)]	Loss: 0.131835
Train Epoch: 1 [5581824/8506302 (65.6%)]	Loss: 0.125759
Train Epoch: 1 [5633024/8506302 (66.2%)]	Loss: 0.110639
Train Epoch: 1 [5684224/8506302 (66.8%)]	Loss: 0.108927
Train Epoch: 1 [5735424/8506302 (67.4%)]	Loss: 0.119116
Train Epoch: 1 [5786624/8506302 (68.0%)]	Loss: 0.119428
Train Epoch: 1 [5837824/8506302 (68.6%)]	Loss: 0.135185
Train Epoch: 1 [5889024/8506302 (69.2%)]	Loss: 0.128763
Train Epoch: 1 [5940224/8506302 (69.8%)]	Loss: 0.122295
Train Epoch: 1 [5991424/8506302 (70.4%)]	Loss: 0.129652
Train Epoch: 1 [6042624/8506302 (71.0%)]	Loss: 0.125612
Train Epoch: 1 [6093824/8506302 (71.6%)]	Loss: 0.116057
Train Epoch: 1 [6145024/8506302 (72.2%)]	Loss: 0.139467
Train Epoch: 1 [6196224/8506302 (72.8%)]	Loss: 0.110467
Train Epoch: 1 [6247424/8506302 (73.4%)]	Loss: 0.120439
Train Epoch: 1 [6298624/8506302 (74.0%)]	Loss: 0.124590
Train Epoch: 1 [6349824/8506302 (74.6%)]	Loss: 0.121877
Train Epoch: 1 [6401024/8506302 (75.3%)]	Loss: 0.129042
Train Epoch: 1 [6452224/8506302 (75.9%)]	Loss: 0.125433
Train Epoch: 1 [6503424/8506302 (76.5%)]	Loss: 0.123918
Train Epoch: 1 [6554624/8506302 (77.1%)]	Loss: 0.129413
Train Epoch: 1 [6605824/8506302 (77.7%)]	Loss: 0.117966
Train Epoch: 1 [6657024/8506302 (78.3%)]	Loss: 0.133847
Train Epoch: 1 [6708224/8506302 (78.9%)]	Loss: 0.122475
Train Epoch: 1 [6759424/8506302 (79.5%)]	Loss: 0.121269
Train Epoch: 1 [6810624/8506302 (80.1%)]	Loss: 0.120243
Train Epoch: 1 [6861824/8506302 (80.7%)]	Loss: 0.113751
Train Epoch: 1 [6913024/8506302 (81.3%)]	Loss: 0.129629
Train Epoch: 1 [6964224/8506302 (81.9%)]	Loss: 0.131898
Train Epoch: 1 [7015424/8506302 (82.5%)]	Loss: 0.128779
Train Epoch: 1 [7066624/8506302 (83.1%)]	Loss: 0.118407
Train Epoch: 1 [7117824/8506302 (83.7%)]	Loss: 0.129506
Train Epoch: 1 [7169024/8506302 (84.3%)]	Loss: 0.135046
Train Epoch: 1 [7220224/8506302 (84.9%)]	Loss: 0.118332
Train Epoch: 1 [7271424/8506302 (85.5%)]	Loss: 0.114342
Train Epoch: 1 [7322624/8506302 (86.1%)]	Loss: 0.121330
Train Epoch: 1 [7373824/8506302 (86.7%)]	Loss: 0.120421
Train Epoch: 1 [7425024/8506302 (87.3%)]	Loss: 0.107464
Train Epoch: 1 [7476224/8506302 (87.9%)]	Loss: 0.128158
Train Epoch: 1 [7527424/8506302 (88.5%)]	Loss: 0.120535
Train Epoch: 1 [7578624/8506302 (89.1%)]	Loss: 0.119430
Train Epoch: 1 [7629824/8506302 (89.7%)]	Loss: 0.115501
Train Epoch: 1 [7681024/8506302 (90.3%)]	Loss: 0.131954
Train Epoch: 1 [7732224/8506302 (90.9%)]	Loss: 0.115814
Train Epoch: 1 [7783424/8506302 (91.5%)]	Loss: 0.117845
Train Epoch: 1 [7834624/8506302 (92.1%)]	Loss: 0.119173
Train Epoch: 1 [7885824/8506302 (92.7%)]	Loss: 0.118206
Train Epoch: 1 [7937024/8506302 (93.3%)]	Loss: 0.123891
Train Epoch: 1 [7988224/8506302 (93.9%)]	Loss: 0.123571
Train Epoch: 1 [8039424/8506302 (94.5%)]	Loss: 0.111643
Train Epoch: 1 [8090624/8506302 (95.1%)]	Loss: 0.123333
Train Epoch: 1 [8141824/8506302 (95.7%)]	Loss: 0.132038
Train Epoch: 1 [8193024/8506302 (96.3%)]	Loss: 0.118622
Train Epoch: 1 [8244224/8506302 (96.9%)]	Loss: 0.135144
Train Epoch: 1 [8295424/8506302 (97.5%)]	Loss: 0.138000
Train Epoch: 1 [8346624/8506302 (98.1%)]	Loss: 0.129312
Train Epoch: 1 [8397824/8506302 (98.7%)]	Loss: 0.117645
Train Epoch: 1 [8449024/8506302 (99.3%)]	Loss: 0.138133
Train Epoch: 1 [8500224/8506302 (99.9%)]	Loss: 0.126224
Train Epoch: 2 [1024/8506302 (0.0%)]	Loss: 0.105106
Train Epoch: 2 [52224/8506302 (0.6%)]	Loss: 0.124564
Train Epoch: 2 [103424/8506302 (1.2%)]	Loss: 0.119250
Train Epoch: 2 [154624/8506302 (1.8%)]	Loss: 0.129987
Train Epoch: 2 [205824/8506302 (2.4%)]	Loss: 0.128503
Train Epoch: 2 [257024/8506302 (3.0%)]	Loss: 0.116548
Train Epoch: 2 [308224/8506302 (3.6%)]	Loss: 0.119480
Train Epoch: 2 [359424/8506302 (4.2%)]	Loss: 0.131697
Train Epoch: 2 [410624/8506302 (4.8%)]	Loss: 0.105762
Train Epoch: 2 [461824/8506302 (5.4%)]	Loss: 0.109779
Train Epoch: 2 [513024/8506302 (6.0%)]	Loss: 0.114783
Train Epoch: 2 [564224/8506302 (6.6%)]	Loss: 0.129663
Train Epoch: 2 [615424/8506302 (7.2%)]	Loss: 0.127856
Train Epoch: 2 [666624/8506302 (7.8%)]	Loss: 0.116640
Train Epoch: 2 [717824/8506302 (8.4%)]	Loss: 0.106136
Train Epoch: 2 [769024/8506302 (9.0%)]	Loss: 0.114003
Train Epoch: 2 [820224/8506302 (9.6%)]	Loss: 0.120038
Train Epoch: 2 [871424/8506302 (10.2%)]	Loss: 0.130937
Train Epoch: 2 [922624/8506302 (10.8%)]	Loss: 0.129410
Train Epoch: 2 [973824/8506302 (11.4%)]	Loss: 0.133041
Train Epoch: 2 [1025024/8506302 (12.1%)]	Loss: 0.123876
Train Epoch: 2 [1076224/8506302 (12.7%)]	Loss: 0.105814
Train Epoch: 2 [1127424/8506302 (13.3%)]	Loss: 0.117652
Train Epoch: 2 [1178624/8506302 (13.9%)]	Loss: 0.119726
Train Epoch: 2 [1229824/8506302 (14.5%)]	Loss: 0.129808
Train Epoch: 2 [1281024/8506302 (15.1%)]	Loss: 0.145932
Train Epoch: 2 [1332224/8506302 (15.7%)]	Loss: 0.130358
Train Epoch: 2 [1383424/8506302 (16.3%)]	Loss: 0.123070
Train Epoch: 2 [1434624/8506302 (16.9%)]	Loss: 0.125807
Train Epoch: 2 [1485824/8506302 (17.5%)]	Loss: 0.118295
Train Epoch: 2 [1537024/8506302 (18.1%)]	Loss: 0.118425
Train Epoch: 2 [1588224/8506302 (18.7%)]	Loss: 0.121191
Train Epoch: 2 [1639424/8506302 (19.3%)]	Loss: 0.121818
Train Epoch: 2 [1690624/8506302 (19.9%)]	Loss: 0.126598
Train Epoch: 2 [1741824/8506302 (20.5%)]	Loss: 0.131353
Train Epoch: 2 [1793024/8506302 (21.1%)]	Loss: 0.120625
Train Epoch: 2 [1844224/8506302 (21.7%)]	Loss: 0.129617
Train Epoch: 2 [1895424/8506302 (22.3%)]	Loss: 0.125786
Train Epoch: 2 [1946624/8506302 (22.9%)]	Loss: 0.120355
Train Epoch: 2 [1997824/8506302 (23.5%)]	Loss: 0.120394
Train Epoch: 2 [2049024/8506302 (24.1%)]	Loss: 0.117943
Train Epoch: 2 [2100224/8506302 (24.7%)]	Loss: 0.131792
Train Epoch: 2 [2151424/8506302 (25.3%)]	Loss: 0.122117
Train Epoch: 2 [2202624/8506302 (25.9%)]	Loss: 0.129988
Train Epoch: 2 [2253824/8506302 (26.5%)]	Loss: 0.116124
Train Epoch: 2 [2305024/8506302 (27.1%)]	Loss: 0.113033
Train Epoch: 2 [2356224/8506302 (27.7%)]	Loss: 0.119315
Train Epoch: 2 [2407424/8506302 (28.3%)]	Loss: 0.121456
Train Epoch: 2 [2458624/8506302 (28.9%)]	Loss: 0.138773
Train Epoch: 2 [2509824/8506302 (29.5%)]	Loss: 0.125967
Train Epoch: 2 [2561024/8506302 (30.1%)]	Loss: 0.116395
Train Epoch: 2 [2612224/8506302 (30.7%)]	Loss: 0.128214
Train Epoch: 2 [2663424/8506302 (31.3%)]	Loss: 0.114162
Train Epoch: 2 [2714624/8506302 (31.9%)]	Loss: 0.108638
Train Epoch: 2 [2765824/8506302 (32.5%)]	Loss: 0.110695
Train Epoch: 2 [2817024/8506302 (33.1%)]	Loss: 0.109915
Train Epoch: 2 [2868224/8506302 (33.7%)]	Loss: 0.130834
Train Epoch: 2 [2919424/8506302 (34.3%)]	Loss: 0.113710
Train Epoch: 2 [2970624/8506302 (34.9%)]	Loss: 0.119488
Train Epoch: 2 [3021824/8506302 (35.5%)]	Loss: 0.120928
Train Epoch: 2 [3073024/8506302 (36.1%)]	Loss: 0.116236
Train Epoch: 2 [3124224/8506302 (36.7%)]	Loss: 0.119002
Train Epoch: 2 [3175424/8506302 (37.3%)]	Loss: 0.125237
Train Epoch: 2 [3226624/8506302 (37.9%)]	Loss: 0.130394
Train Epoch: 2 [3277824/8506302 (38.5%)]	Loss: 0.130434
Train Epoch: 2 [3329024/8506302 (39.1%)]	Loss: 0.121712
Train Epoch: 2 [3380224/8506302 (39.7%)]	Loss: 0.135477
Train Epoch: 2 [3431424/8506302 (40.3%)]	Loss: 0.121716
Train Epoch: 2 [3482624/8506302 (40.9%)]	Loss: 0.119834
Train Epoch: 2 [3533824/8506302 (41.5%)]	Loss: 0.137448
Train Epoch: 2 [3585024/8506302 (42.1%)]	Loss: 0.114623
Train Epoch: 2 [3636224/8506302 (42.7%)]	Loss: 0.119204
Train Epoch: 2 [3687424/8506302 (43.3%)]	Loss: 0.120157
Train Epoch: 2 [3738624/8506302 (44.0%)]	Loss: 0.119885
Train Epoch: 2 [3789824/8506302 (44.6%)]	Loss: 0.129981
Train Epoch: 2 [3841024/8506302 (45.2%)]	Loss: 0.124076
Train Epoch: 2 [3892224/8506302 (45.8%)]	Loss: 0.124748
Train Epoch: 2 [3943424/8506302 (46.4%)]	Loss: 0.111040
Train Epoch: 2 [3994624/8506302 (47.0%)]	Loss: 0.123157
Train Epoch: 2 [4045824/8506302 (47.6%)]	Loss: 0.122740
Train Epoch: 2 [4097024/8506302 (48.2%)]	Loss: 0.115398
Train Epoch: 2 [4148224/8506302 (48.8%)]	Loss: 0.121917
Train Epoch: 2 [4199424/8506302 (49.4%)]	Loss: 0.120239
Train Epoch: 2 [4250624/8506302 (50.0%)]	Loss: 0.110670
Train Epoch: 2 [4301824/8506302 (50.6%)]	Loss: 0.132634
Train Epoch: 2 [4353024/8506302 (51.2%)]	Loss: 0.108527
Train Epoch: 2 [4404224/8506302 (51.8%)]	Loss: 0.129638
Train Epoch: 2 [4455424/8506302 (52.4%)]	Loss: 0.137202
Train Epoch: 2 [4506624/8506302 (53.0%)]	Loss: 0.115879
Train Epoch: 2 [4557824/8506302 (53.6%)]	Loss: 0.117009
Train Epoch: 2 [4609024/8506302 (54.2%)]	Loss: 0.137848
Train Epoch: 2 [4660224/8506302 (54.8%)]	Loss: 0.124923
Train Epoch: 2 [4711424/8506302 (55.4%)]	Loss: 0.126277
Train Epoch: 2 [4762624/8506302 (56.0%)]	Loss: 0.136286
Train Epoch: 2 [4813824/8506302 (56.6%)]	Loss: 0.124413
Train Epoch: 2 [4865024/8506302 (57.2%)]	Loss: 0.132741
Train Epoch: 2 [4916224/8506302 (57.8%)]	Loss: 0.132393
Train Epoch: 2 [4967424/8506302 (58.4%)]	Loss: 0.114965
Train Epoch: 2 [5018624/8506302 (59.0%)]	Loss: 0.128183
Train Epoch: 2 [5069824/8506302 (59.6%)]	Loss: 0.118408
Train Epoch: 2 [5121024/8506302 (60.2%)]	Loss: 0.117223
Train Epoch: 2 [5172224/8506302 (60.8%)]	Loss: 0.117462
Train Epoch: 2 [5223424/8506302 (61.4%)]	Loss: 0.111530
Train Epoch: 2 [5274624/8506302 (62.0%)]	Loss: 0.108120
Train Epoch: 2 [5325824/8506302 (62.6%)]	Loss: 0.130346
Train Epoch: 2 [5377024/8506302 (63.2%)]	Loss: 0.122348
Train Epoch: 2 [5428224/8506302 (63.8%)]	Loss: 0.112098
Train Epoch: 2 [5479424/8506302 (64.4%)]	Loss: 0.121054
Train Epoch: 2 [5530624/8506302 (65.0%)]	Loss: 0.109659
Train Epoch: 2 [5581824/8506302 (65.6%)]	Loss: 0.120885
Train Epoch: 2 [5633024/8506302 (66.2%)]	Loss: 0.130296
Train Epoch: 2 [5684224/8506302 (66.8%)]	Loss: 0.117402
Train Epoch: 2 [5735424/8506302 (67.4%)]	Loss: 0.121488
Train Epoch: 2 [5786624/8506302 (68.0%)]	Loss: 0.118621
Train Epoch: 2 [5837824/8506302 (68.6%)]	Loss: 0.125485
Train Epoch: 2 [5889024/8506302 (69.2%)]	Loss: 0.128519
Train Epoch: 2 [5940224/8506302 (69.8%)]	Loss: 0.119802
Train Epoch: 2 [5991424/8506302 (70.4%)]	Loss: 0.100153
Train Epoch: 2 [6042624/8506302 (71.0%)]	Loss: 0.117311
Train Epoch: 2 [6093824/8506302 (71.6%)]	Loss: 0.119638
Train Epoch: 2 [6145024/8506302 (72.2%)]	Loss: 0.116718
Train Epoch: 2 [6196224/8506302 (72.8%)]	Loss: 0.113159
Train Epoch: 2 [6247424/8506302 (73.4%)]	Loss: 0.106922
Train Epoch: 2 [6298624/8506302 (74.0%)]	Loss: 0.128604
Train Epoch: 2 [6349824/8506302 (74.6%)]	Loss: 0.125210
Train Epoch: 2 [6401024/8506302 (75.3%)]	Loss: 0.105940
Train Epoch: 2 [6452224/8506302 (75.9%)]	Loss: 0.134409
Train Epoch: 2 [6503424/8506302 (76.5%)]	Loss: 0.107347
Train Epoch: 2 [6554624/8506302 (77.1%)]	Loss: 0.111160
Train Epoch: 2 [6605824/8506302 (77.7%)]	Loss: 0.112426
Train Epoch: 2 [6657024/8506302 (78.3%)]	Loss: 0.115545
Train Epoch: 2 [6708224/8506302 (78.9%)]	Loss: 0.134832
Train Epoch: 2 [6759424/8506302 (79.5%)]	Loss: 0.113748
Train Epoch: 2 [6810624/8506302 (80.1%)]	Loss: 0.116827
Train Epoch: 2 [6861824/8506302 (80.7%)]	Loss: 0.118806
Train Epoch: 2 [6913024/8506302 (81.3%)]	Loss: 0.135635
Train Epoch: 2 [6964224/8506302 (81.9%)]	Loss: 0.119550
Train Epoch: 2 [7015424/8506302 (82.5%)]	Loss: 0.118989
Train Epoch: 2 [7066624/8506302 (83.1%)]	Loss: 0.124264
Train Epoch: 2 [7117824/8506302 (83.7%)]	Loss: 0.121419
Train Epoch: 2 [7169024/8506302 (84.3%)]	Loss: 0.121422
Train Epoch: 2 [7220224/8506302 (84.9%)]	Loss: 0.125545
Train Epoch: 2 [7271424/8506302 (85.5%)]	Loss: 0.135593
Train Epoch: 2 [7322624/8506302 (86.1%)]	Loss: 0.117210
Train Epoch: 2 [7373824/8506302 (86.7%)]	Loss: 0.106898
Train Epoch: 2 [7425024/8506302 (87.3%)]	Loss: 0.111162
Train Epoch: 2 [7476224/8506302 (87.9%)]	Loss: 0.125666
Train Epoch: 2 [7527424/8506302 (88.5%)]	Loss: 0.123820
Train Epoch: 2 [7578624/8506302 (89.1%)]	Loss: 0.124841
Train Epoch: 2 [7629824/8506302 (89.7%)]	Loss: 0.121872
Train Epoch: 2 [7681024/8506302 (90.3%)]	Loss: 0.118861
Train Epoch: 2 [7732224/8506302 (90.9%)]	Loss: 0.130502
Train Epoch: 2 [7783424/8506302 (91.5%)]	Loss: 0.124807
Train Epoch: 2 [7834624/8506302 (92.1%)]	Loss: 0.122419
Train Epoch: 2 [7885824/8506302 (92.7%)]	Loss: 0.135980
Train Epoch: 2 [7937024/8506302 (93.3%)]	Loss: 0.130375
Train Epoch: 2 [7988224/8506302 (93.9%)]	Loss: 0.124456
Train Epoch: 2 [8039424/8506302 (94.5%)]	Loss: 0.122104
Train Epoch: 2 [8090624/8506302 (95.1%)]	Loss: 0.114986
Train Epoch: 2 [8141824/8506302 (95.7%)]	Loss: 0.122208
Train Epoch: 2 [8193024/8506302 (96.3%)]	Loss: 0.120354
Train Epoch: 2 [8244224/8506302 (96.9%)]	Loss: 0.125069
Train Epoch: 2 [8295424/8506302 (97.5%)]	Loss: 0.123110
Train Epoch: 2 [8346624/8506302 (98.1%)]	Loss: 0.126622
Train Epoch: 2 [8397824/8506302 (98.7%)]	Loss: 0.131594
Train Epoch: 2 [8449024/8506302 (99.3%)]	Loss: 0.129751
Train Epoch: 2 [8500224/8506302 (99.9%)]	Loss: 0.118568

 ---------------------------------------------------------------------- 


ACC in fold#4 was 0.905


Confusion Matrix in fold#4: 
           nonRipple   Ripple
nonRipple     643206   154042
Ripple         47690  1281637


Classification Report in fold#4: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.931        0.893     0.905        0.912         0.907
recall            0.807        0.964     0.905        0.885         0.905
f1-score          0.864        0.927     0.905        0.896         0.904
sample size  797248.000  1329327.000     0.905  2126575.000   2126575.000


PR_AUC in fold#4 was 0.972


ROC_AUC in fold#4 was 0.965

Time (id:5): tot 18:34:57, prev 03:41:22 [hh:mm:ss]: 
i_fold=4 ends.



 ---------------------------------------------------------------------- 


Label Errors Rate:
0.032


 --- 5-fold CV overall metrics --- 


Confusion Matrix (Test; sum; num. folds=5)
           nonRipple   Ripple
nonRipple    3316682   669559
Ripple        477748  6168888


Classification Report (Test; mean; num. folds=5)
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.876        0.903     0.892        0.889         0.893
recall            0.832        0.928     0.892        0.880         0.892
f1-score          0.853        0.915     0.892        0.884         0.891
sample size  797248.200  1329327.200     0.892  2126575.400   2126575.400


Classification Report (Test; std; num. folds=5)
             nonRipple  Ripple  accuracy  macro avg  weighted avg
precision        0.033   0.016     0.008      0.012         0.008
recall           0.033   0.024     0.008      0.009         0.008
f1-score         0.010   0.007     0.008      0.008         0.008
sample size      0.400   0.400     0.008      0.490         0.490


PRE-REC AUC Score: 0.969 +/- 0.004 (mean +/- std.; n=5)


ROC AUC Score: 0.958 +/- 0.005 (mean +/- std.; n=5)


Saved to: ./data/okada/cleanlab_results/D04-/are_errors.npy


Saved to: ./data/okada/cleanlab_results/D04-/cleaned_labels.npy


Saved to: ./data/okada/cleanlab_results/D04-/pred_probas_ripples.npy

(Moved to: /tmp/2021-0515-1650-D04--conf_mats.csv)
Saved to: ./data/okada/cleanlab_results/D04-/conf_mats.csv
Saved to: ./data/okada/cleanlab_results/D04-/conf_mat_overall_sum.png
(Moved to: /tmp/2021-0515-1650-D04--clf_reports.csv)
Saved to: ./data/okada/cleanlab_results/D04-/clf_reports.csv
(Moved to: /tmp/2021-0515-1650-D04--roc-auc.csv)
Saved to: ./data/okada/cleanlab_results/D04-/roc-auc.csv

Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-1_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-2_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-3_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-4_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-1_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-2_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-3_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-4_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-1_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-2_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-3_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-4_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-1_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-2_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-3_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-4_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-1_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-2_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-3_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-4_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-1_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-2_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-3_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-4_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-1_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-2_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-3_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-4_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-1_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-2_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-3_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt7-4_fp16.pkl


Saved to: ./data/okada/05/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/05/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/05/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/05/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/05/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/05/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/05/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/05/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/05/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/05/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/05/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/05/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/05/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/05/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/05/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/05/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/05/day5/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-1_fp16.pkl


Saved to: ./data/okada/05/day5/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-2_fp16.pkl


Saved to: ./data/okada/05/day5/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-3_fp16.pkl


Saved to: ./data/okada/05/day5/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt2-4_fp16.pkl


Saved to: ./data/okada/05/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/05/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/05/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/05/day1/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/05/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/05/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/05/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/05/day2/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/05/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/05/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/05/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/05/day3/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/05/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/05/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/05/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/05/day4/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl


Saved to: ./data/okada/05/day5/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-1_fp16.pkl


Saved to: ./data/okada/05/day5/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-2_fp16.pkl


Saved to: ./data/okada/05/day5/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-3_fp16.pkl


Saved to: ./data/okada/05/day5/split/ripples_1kHz_pkl/CNN_labeled/D04-/tt6-4_fp16.pkl

