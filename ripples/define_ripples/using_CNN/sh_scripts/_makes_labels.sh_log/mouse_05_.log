
Random seeds have been fixed as 42


Random seeds have been fixed as 42

Indice of mice to load: ['01', '02', '03', '04']
144
Time (id:0): tot 00:00:00, prev 00:00:00 [hh:mm:ss]: Reporter has been initialized.

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8742050 (0.0%)]	Loss: 0.363007
Train Epoch: 1 [52224/8742050 (0.6%)]	Loss: 0.164482
Train Epoch: 1 [103424/8742050 (1.2%)]	Loss: 0.132665
Train Epoch: 1 [154624/8742050 (1.8%)]	Loss: 0.142982
Train Epoch: 1 [205824/8742050 (2.4%)]	Loss: 0.129647
Train Epoch: 1 [257024/8742050 (2.9%)]	Loss: 0.132943
Train Epoch: 1 [308224/8742050 (3.5%)]	Loss: 0.122335
Train Epoch: 1 [359424/8742050 (4.1%)]	Loss: 0.120826
Train Epoch: 1 [410624/8742050 (4.7%)]	Loss: 0.131455
Train Epoch: 1 [461824/8742050 (5.3%)]	Loss: 0.139270
Train Epoch: 1 [513024/8742050 (5.9%)]	Loss: 0.117640
Train Epoch: 1 [564224/8742050 (6.5%)]	Loss: 0.127379
Train Epoch: 1 [615424/8742050 (7.0%)]	Loss: 0.118906
Train Epoch: 1 [666624/8742050 (7.6%)]	Loss: 0.120505
Train Epoch: 1 [717824/8742050 (8.2%)]	Loss: 0.136247
Train Epoch: 1 [769024/8742050 (8.8%)]	Loss: 0.129043
Train Epoch: 1 [820224/8742050 (9.4%)]	Loss: 0.126806
Train Epoch: 1 [871424/8742050 (10.0%)]	Loss: 0.115910
Train Epoch: 1 [922624/8742050 (10.6%)]	Loss: 0.115364
Train Epoch: 1 [973824/8742050 (11.1%)]	Loss: 0.134651
Train Epoch: 1 [1025024/8742050 (11.7%)]	Loss: 0.113200
Train Epoch: 1 [1076224/8742050 (12.3%)]	Loss: 0.123686
Train Epoch: 1 [1127424/8742050 (12.9%)]	Loss: 0.123432
Train Epoch: 1 [1178624/8742050 (13.5%)]	Loss: 0.132131
Train Epoch: 1 [1229824/8742050 (14.1%)]	Loss: 0.112240
Train Epoch: 1 [1281024/8742050 (14.7%)]	Loss: 0.121970
Train Epoch: 1 [1332224/8742050 (15.2%)]	Loss: 0.130079
Train Epoch: 1 [1383424/8742050 (15.8%)]	Loss: 0.125028
Train Epoch: 1 [1434624/8742050 (16.4%)]	Loss: 0.117034
Train Epoch: 1 [1485824/8742050 (17.0%)]	Loss: 0.115473
Train Epoch: 1 [1537024/8742050 (17.6%)]	Loss: 0.119382
Train Epoch: 1 [1588224/8742050 (18.2%)]	Loss: 0.114994
Train Epoch: 1 [1639424/8742050 (18.8%)]	Loss: 0.125761
Train Epoch: 1 [1690624/8742050 (19.3%)]	Loss: 0.116963
Train Epoch: 1 [1741824/8742050 (19.9%)]	Loss: 0.117463
Train Epoch: 1 [1793024/8742050 (20.5%)]	Loss: 0.112421
Train Epoch: 1 [1844224/8742050 (21.1%)]	Loss: 0.116792
Train Epoch: 1 [1895424/8742050 (21.7%)]	Loss: 0.117708
Train Epoch: 1 [1946624/8742050 (22.3%)]	Loss: 0.118136
Train Epoch: 1 [1997824/8742050 (22.9%)]	Loss: 0.099749
Train Epoch: 1 [2049024/8742050 (23.4%)]	Loss: 0.113886
Train Epoch: 1 [2100224/8742050 (24.0%)]	Loss: 0.109857
Train Epoch: 1 [2151424/8742050 (24.6%)]	Loss: 0.132171
Train Epoch: 1 [2202624/8742050 (25.2%)]	Loss: 0.109298
Train Epoch: 1 [2253824/8742050 (25.8%)]	Loss: 0.122072
Train Epoch: 1 [2305024/8742050 (26.4%)]	Loss: 0.116850
Train Epoch: 1 [2356224/8742050 (27.0%)]	Loss: 0.113599
Train Epoch: 1 [2407424/8742050 (27.5%)]	Loss: 0.117573
Train Epoch: 1 [2458624/8742050 (28.1%)]	Loss: 0.136284
Train Epoch: 1 [2509824/8742050 (28.7%)]	Loss: 0.119537
Train Epoch: 1 [2561024/8742050 (29.3%)]	Loss: 0.117293
Train Epoch: 1 [2612224/8742050 (29.9%)]	Loss: 0.134194
Train Epoch: 1 [2663424/8742050 (30.5%)]	Loss: 0.116677
Train Epoch: 1 [2714624/8742050 (31.1%)]	Loss: 0.138067
Train Epoch: 1 [2765824/8742050 (31.6%)]	Loss: 0.127855
Train Epoch: 1 [2817024/8742050 (32.2%)]	Loss: 0.124214
Train Epoch: 1 [2868224/8742050 (32.8%)]	Loss: 0.113821
Train Epoch: 1 [2919424/8742050 (33.4%)]	Loss: 0.121913
Train Epoch: 1 [2970624/8742050 (34.0%)]	Loss: 0.107560
Train Epoch: 1 [3021824/8742050 (34.6%)]	Loss: 0.123473
Train Epoch: 1 [3073024/8742050 (35.2%)]	Loss: 0.113362
Train Epoch: 1 [3124224/8742050 (35.7%)]	Loss: 0.111825
Train Epoch: 1 [3175424/8742050 (36.3%)]	Loss: 0.134842
Train Epoch: 1 [3226624/8742050 (36.9%)]	Loss: 0.116772
Train Epoch: 1 [3277824/8742050 (37.5%)]	Loss: 0.109078
Train Epoch: 1 [3329024/8742050 (38.1%)]	Loss: 0.119051
Train Epoch: 1 [3380224/8742050 (38.7%)]	Loss: 0.114804
Train Epoch: 1 [3431424/8742050 (39.3%)]	Loss: 0.125155
Train Epoch: 1 [3482624/8742050 (39.8%)]	Loss: 0.110837
Train Epoch: 1 [3533824/8742050 (40.4%)]	Loss: 0.111950
Train Epoch: 1 [3585024/8742050 (41.0%)]	Loss: 0.117019
Train Epoch: 1 [3636224/8742050 (41.6%)]	Loss: 0.107537
Train Epoch: 1 [3687424/8742050 (42.2%)]	Loss: 0.110243
Train Epoch: 1 [3738624/8742050 (42.8%)]	Loss: 0.133257
Train Epoch: 1 [3789824/8742050 (43.4%)]	Loss: 0.111069
Train Epoch: 1 [3841024/8742050 (43.9%)]	Loss: 0.121845
Train Epoch: 1 [3892224/8742050 (44.5%)]	Loss: 0.118699
Train Epoch: 1 [3943424/8742050 (45.1%)]	Loss: 0.101579
Train Epoch: 1 [3994624/8742050 (45.7%)]	Loss: 0.117204
Train Epoch: 1 [4045824/8742050 (46.3%)]	Loss: 0.119030
Train Epoch: 1 [4097024/8742050 (46.9%)]	Loss: 0.132286
Train Epoch: 1 [4148224/8742050 (47.5%)]	Loss: 0.110646
Train Epoch: 1 [4199424/8742050 (48.0%)]	Loss: 0.106588
Train Epoch: 1 [4250624/8742050 (48.6%)]	Loss: 0.105911
Train Epoch: 1 [4301824/8742050 (49.2%)]	Loss: 0.108163
Train Epoch: 1 [4353024/8742050 (49.8%)]	Loss: 0.113981
Train Epoch: 1 [4404224/8742050 (50.4%)]	Loss: 0.104680
Train Epoch: 1 [4455424/8742050 (51.0%)]	Loss: 0.115305
Train Epoch: 1 [4506624/8742050 (51.6%)]	Loss: 0.117171
Train Epoch: 1 [4557824/8742050 (52.1%)]	Loss: 0.096994
Train Epoch: 1 [4609024/8742050 (52.7%)]	Loss: 0.119521
Train Epoch: 1 [4660224/8742050 (53.3%)]	Loss: 0.109750
Train Epoch: 1 [4711424/8742050 (53.9%)]	Loss: 0.136950
Train Epoch: 1 [4762624/8742050 (54.5%)]	Loss: 0.106959
Train Epoch: 1 [4813824/8742050 (55.1%)]	Loss: 0.106388
Train Epoch: 1 [4865024/8742050 (55.7%)]	Loss: 0.103110
Train Epoch: 1 [4916224/8742050 (56.2%)]	Loss: 0.113695
Train Epoch: 1 [4967424/8742050 (56.8%)]	Loss: 0.124451
Train Epoch: 1 [5018624/8742050 (57.4%)]	Loss: 0.099712
Train Epoch: 1 [5069824/8742050 (58.0%)]	Loss: 0.113302
Train Epoch: 1 [5121024/8742050 (58.6%)]	Loss: 0.123723
Train Epoch: 1 [5172224/8742050 (59.2%)]	Loss: 0.116035
Train Epoch: 1 [5223424/8742050 (59.8%)]	Loss: 0.096146
Train Epoch: 1 [5274624/8742050 (60.3%)]	Loss: 0.118660
Train Epoch: 1 [5325824/8742050 (60.9%)]	Loss: 0.133180
Train Epoch: 1 [5377024/8742050 (61.5%)]	Loss: 0.118911
Train Epoch: 1 [5428224/8742050 (62.1%)]	Loss: 0.124499
Train Epoch: 1 [5479424/8742050 (62.7%)]	Loss: 0.137345
Train Epoch: 1 [5530624/8742050 (63.3%)]	Loss: 0.125970
Train Epoch: 1 [5581824/8742050 (63.9%)]	Loss: 0.110361
Train Epoch: 1 [5633024/8742050 (64.4%)]	Loss: 0.120875
Train Epoch: 1 [5684224/8742050 (65.0%)]	Loss: 0.104244
Train Epoch: 1 [5735424/8742050 (65.6%)]	Loss: 0.116183
Train Epoch: 1 [5786624/8742050 (66.2%)]	Loss: 0.126702
Train Epoch: 1 [5837824/8742050 (66.8%)]	Loss: 0.102898
Train Epoch: 1 [5889024/8742050 (67.4%)]	Loss: 0.112303
Train Epoch: 1 [5940224/8742050 (68.0%)]	Loss: 0.113537
Train Epoch: 1 [5991424/8742050 (68.5%)]	Loss: 0.127890
Train Epoch: 1 [6042624/8742050 (69.1%)]	Loss: 0.119567
Train Epoch: 1 [6093824/8742050 (69.7%)]	Loss: 0.097959
Train Epoch: 1 [6145024/8742050 (70.3%)]	Loss: 0.120376
Train Epoch: 1 [6196224/8742050 (70.9%)]	Loss: 0.110839
Train Epoch: 1 [6247424/8742050 (71.5%)]	Loss: 0.111289
Train Epoch: 1 [6298624/8742050 (72.0%)]	Loss: 0.123998
Train Epoch: 1 [6349824/8742050 (72.6%)]	Loss: 0.110433
Train Epoch: 1 [6401024/8742050 (73.2%)]	Loss: 0.121582
Train Epoch: 1 [6452224/8742050 (73.8%)]	Loss: 0.103916
Train Epoch: 1 [6503424/8742050 (74.4%)]	Loss: 0.111897
Train Epoch: 1 [6554624/8742050 (75.0%)]	Loss: 0.118732
Train Epoch: 1 [6605824/8742050 (75.6%)]	Loss: 0.109850
Train Epoch: 1 [6657024/8742050 (76.1%)]	Loss: 0.098882
Train Epoch: 1 [6708224/8742050 (76.7%)]	Loss: 0.110525
Train Epoch: 1 [6759424/8742050 (77.3%)]	Loss: 0.117899
Train Epoch: 1 [6810624/8742050 (77.9%)]	Loss: 0.106013
Train Epoch: 1 [6861824/8742050 (78.5%)]	Loss: 0.121758
Train Epoch: 1 [6913024/8742050 (79.1%)]	Loss: 0.118955
Train Epoch: 1 [6964224/8742050 (79.7%)]	Loss: 0.110558
Train Epoch: 1 [7015424/8742050 (80.2%)]	Loss: 0.107431
Train Epoch: 1 [7066624/8742050 (80.8%)]	Loss: 0.117531
Train Epoch: 1 [7117824/8742050 (81.4%)]	Loss: 0.109276
Train Epoch: 1 [7169024/8742050 (82.0%)]	Loss: 0.120578
Train Epoch: 1 [7220224/8742050 (82.6%)]	Loss: 0.113594
Train Epoch: 1 [7271424/8742050 (83.2%)]	Loss: 0.109005
Train Epoch: 1 [7322624/8742050 (83.8%)]	Loss: 0.120466
Train Epoch: 1 [7373824/8742050 (84.3%)]	Loss: 0.117045
Train Epoch: 1 [7425024/8742050 (84.9%)]	Loss: 0.101453
Train Epoch: 1 [7476224/8742050 (85.5%)]	Loss: 0.105933
Train Epoch: 1 [7527424/8742050 (86.1%)]	Loss: 0.118850
Train Epoch: 1 [7578624/8742050 (86.7%)]	Loss: 0.101505
Train Epoch: 1 [7629824/8742050 (87.3%)]	Loss: 0.112311
Train Epoch: 1 [7681024/8742050 (87.9%)]	Loss: 0.123613
Train Epoch: 1 [7732224/8742050 (88.4%)]	Loss: 0.117874
Train Epoch: 1 [7783424/8742050 (89.0%)]	Loss: 0.104963
Train Epoch: 1 [7834624/8742050 (89.6%)]	Loss: 0.110174
Train Epoch: 1 [7885824/8742050 (90.2%)]	Loss: 0.107928
Train Epoch: 1 [7937024/8742050 (90.8%)]	Loss: 0.101621
Train Epoch: 1 [7988224/8742050 (91.4%)]	Loss: 0.103887
Train Epoch: 1 [8039424/8742050 (92.0%)]	Loss: 0.121939
Train Epoch: 1 [8090624/8742050 (92.5%)]	Loss: 0.113601
Train Epoch: 1 [8141824/8742050 (93.1%)]	Loss: 0.122034
Train Epoch: 1 [8193024/8742050 (93.7%)]	Loss: 0.115914
Train Epoch: 1 [8244224/8742050 (94.3%)]	Loss: 0.110539
Train Epoch: 1 [8295424/8742050 (94.9%)]	Loss: 0.116163
Train Epoch: 1 [8346624/8742050 (95.5%)]	Loss: 0.120764
Train Epoch: 1 [8397824/8742050 (96.1%)]	Loss: 0.106875
Train Epoch: 1 [8449024/8742050 (96.6%)]	Loss: 0.105358
Train Epoch: 1 [8500224/8742050 (97.2%)]	Loss: 0.098815
Train Epoch: 1 [8551424/8742050 (97.8%)]	Loss: 0.113201
Train Epoch: 1 [8602624/8742050 (98.4%)]	Loss: 0.123634
Train Epoch: 1 [8653824/8742050 (99.0%)]	Loss: 0.112993
Train Epoch: 1 [8705024/8742050 (99.6%)]	Loss: 0.112300
Train Epoch: 2 [1024/8742050 (0.0%)]	Loss: 0.104337
Train Epoch: 2 [52224/8742050 (0.6%)]	Loss: 0.107778
Train Epoch: 2 [103424/8742050 (1.2%)]	Loss: 0.108021
Train Epoch: 2 [154624/8742050 (1.8%)]	Loss: 0.105890
Train Epoch: 2 [205824/8742050 (2.4%)]	Loss: 0.107319
Train Epoch: 2 [257024/8742050 (2.9%)]	Loss: 0.117089
Train Epoch: 2 [308224/8742050 (3.5%)]	Loss: 0.100579
Train Epoch: 2 [359424/8742050 (4.1%)]	Loss: 0.099624
Train Epoch: 2 [410624/8742050 (4.7%)]	Loss: 0.113798
Train Epoch: 2 [461824/8742050 (5.3%)]	Loss: 0.111338
Train Epoch: 2 [513024/8742050 (5.9%)]	Loss: 0.108507
Train Epoch: 2 [564224/8742050 (6.5%)]	Loss: 0.107357
Train Epoch: 2 [615424/8742050 (7.0%)]	Loss: 0.110123
Train Epoch: 2 [666624/8742050 (7.6%)]	Loss: 0.120174
Train Epoch: 2 [717824/8742050 (8.2%)]	Loss: 0.107747
Train Epoch: 2 [769024/8742050 (8.8%)]	Loss: 0.116266
Train Epoch: 2 [820224/8742050 (9.4%)]	Loss: 0.107130
Train Epoch: 2 [871424/8742050 (10.0%)]	Loss: 0.112993
Train Epoch: 2 [922624/8742050 (10.6%)]	Loss: 0.110276
Train Epoch: 2 [973824/8742050 (11.1%)]	Loss: 0.116068
Train Epoch: 2 [1025024/8742050 (11.7%)]	Loss: 0.121000
Train Epoch: 2 [1076224/8742050 (12.3%)]	Loss: 0.126168
Train Epoch: 2 [1127424/8742050 (12.9%)]	Loss: 0.097119
Train Epoch: 2 [1178624/8742050 (13.5%)]	Loss: 0.111279
Train Epoch: 2 [1229824/8742050 (14.1%)]	Loss: 0.102873
Train Epoch: 2 [1281024/8742050 (14.7%)]	Loss: 0.104774
Train Epoch: 2 [1332224/8742050 (15.2%)]	Loss: 0.115606
Train Epoch: 2 [1383424/8742050 (15.8%)]	Loss: 0.112107
Train Epoch: 2 [1434624/8742050 (16.4%)]	Loss: 0.109165
Train Epoch: 2 [1485824/8742050 (17.0%)]	Loss: 0.111643
Train Epoch: 2 [1537024/8742050 (17.6%)]	Loss: 0.107088
Train Epoch: 2 [1588224/8742050 (18.2%)]	Loss: 0.116928
Train Epoch: 2 [1639424/8742050 (18.8%)]	Loss: 0.113743
Train Epoch: 2 [1690624/8742050 (19.3%)]	Loss: 0.127606
Train Epoch: 2 [1741824/8742050 (19.9%)]	Loss: 0.116227
Train Epoch: 2 [1793024/8742050 (20.5%)]	Loss: 0.111655
Train Epoch: 2 [1844224/8742050 (21.1%)]	Loss: 0.108951
Train Epoch: 2 [1895424/8742050 (21.7%)]	Loss: 0.116128
Train Epoch: 2 [1946624/8742050 (22.3%)]	Loss: 0.108782
Train Epoch: 2 [1997824/8742050 (22.9%)]	Loss: 0.104758
Train Epoch: 2 [2049024/8742050 (23.4%)]	Loss: 0.125584
Train Epoch: 2 [2100224/8742050 (24.0%)]	Loss: 0.114674
Train Epoch: 2 [2151424/8742050 (24.6%)]	Loss: 0.120418
Train Epoch: 2 [2202624/8742050 (25.2%)]	Loss: 0.108053
Train Epoch: 2 [2253824/8742050 (25.8%)]	Loss: 0.113303
Train Epoch: 2 [2305024/8742050 (26.4%)]	Loss: 0.118778
Train Epoch: 2 [2356224/8742050 (27.0%)]	Loss: 0.114223
Train Epoch: 2 [2407424/8742050 (27.5%)]	Loss: 0.098208
Train Epoch: 2 [2458624/8742050 (28.1%)]	Loss: 0.109547
Train Epoch: 2 [2509824/8742050 (28.7%)]	Loss: 0.111644
Train Epoch: 2 [2561024/8742050 (29.3%)]	Loss: 0.106151
Train Epoch: 2 [2612224/8742050 (29.9%)]	Loss: 0.116397
Train Epoch: 2 [2663424/8742050 (30.5%)]	Loss: 0.105756
Train Epoch: 2 [2714624/8742050 (31.1%)]	Loss: 0.103061
Train Epoch: 2 [2765824/8742050 (31.6%)]	Loss: 0.114773
Train Epoch: 2 [2817024/8742050 (32.2%)]	Loss: 0.109340
Train Epoch: 2 [2868224/8742050 (32.8%)]	Loss: 0.106366
Train Epoch: 2 [2919424/8742050 (33.4%)]	Loss: 0.118918
Train Epoch: 2 [2970624/8742050 (34.0%)]	Loss: 0.112340
Train Epoch: 2 [3021824/8742050 (34.6%)]	Loss: 0.117747
Train Epoch: 2 [3073024/8742050 (35.2%)]	Loss: 0.096633
Train Epoch: 2 [3124224/8742050 (35.7%)]	Loss: 0.110245
Train Epoch: 2 [3175424/8742050 (36.3%)]	Loss: 0.111153
Train Epoch: 2 [3226624/8742050 (36.9%)]	Loss: 0.107638
Train Epoch: 2 [3277824/8742050 (37.5%)]	Loss: 0.109839
Train Epoch: 2 [3329024/8742050 (38.1%)]	Loss: 0.112023
Train Epoch: 2 [3380224/8742050 (38.7%)]	Loss: 0.116521
Train Epoch: 2 [3431424/8742050 (39.3%)]	Loss: 0.098660
Train Epoch: 2 [3482624/8742050 (39.8%)]	Loss: 0.101294
Train Epoch: 2 [3533824/8742050 (40.4%)]	Loss: 0.112777
Train Epoch: 2 [3585024/8742050 (41.0%)]	Loss: 0.119454
Train Epoch: 2 [3636224/8742050 (41.6%)]	Loss: 0.113831
Train Epoch: 2 [3687424/8742050 (42.2%)]	Loss: 0.107426
Train Epoch: 2 [3738624/8742050 (42.8%)]	Loss: 0.108994
Train Epoch: 2 [3789824/8742050 (43.4%)]	Loss: 0.105144
Train Epoch: 2 [3841024/8742050 (43.9%)]	Loss: 0.104586
Train Epoch: 2 [3892224/8742050 (44.5%)]	Loss: 0.099981
Train Epoch: 2 [3943424/8742050 (45.1%)]	Loss: 0.106569
Train Epoch: 2 [3994624/8742050 (45.7%)]	Loss: 0.109227
Train Epoch: 2 [4045824/8742050 (46.3%)]	Loss: 0.115998
Train Epoch: 2 [4097024/8742050 (46.9%)]	Loss: 0.101114
Train Epoch: 2 [4148224/8742050 (47.5%)]	Loss: 0.108758
Train Epoch: 2 [4199424/8742050 (48.0%)]	Loss: 0.086850
Train Epoch: 2 [4250624/8742050 (48.6%)]	Loss: 0.124586
Train Epoch: 2 [4301824/8742050 (49.2%)]	Loss: 0.104053
Train Epoch: 2 [4353024/8742050 (49.8%)]	Loss: 0.105852
Train Epoch: 2 [4404224/8742050 (50.4%)]	Loss: 0.111679
Train Epoch: 2 [4455424/8742050 (51.0%)]	Loss: 0.113712
Train Epoch: 2 [4506624/8742050 (51.6%)]	Loss: 0.102840
Train Epoch: 2 [4557824/8742050 (52.1%)]	Loss: 0.114229
Train Epoch: 2 [4609024/8742050 (52.7%)]	Loss: 0.099890
Train Epoch: 2 [4660224/8742050 (53.3%)]	Loss: 0.112597
Train Epoch: 2 [4711424/8742050 (53.9%)]	Loss: 0.107512
Train Epoch: 2 [4762624/8742050 (54.5%)]	Loss: 0.106052
Train Epoch: 2 [4813824/8742050 (55.1%)]	Loss: 0.108483
Train Epoch: 2 [4865024/8742050 (55.7%)]	Loss: 0.112035
Train Epoch: 2 [4916224/8742050 (56.2%)]	Loss: 0.112801
Train Epoch: 2 [4967424/8742050 (56.8%)]	Loss: 0.121626
Train Epoch: 2 [5018624/8742050 (57.4%)]	Loss: 0.100933
Train Epoch: 2 [5069824/8742050 (58.0%)]	Loss: 0.107363
Train Epoch: 2 [5121024/8742050 (58.6%)]	Loss: 0.113924
Train Epoch: 2 [5172224/8742050 (59.2%)]	Loss: 0.112654
Train Epoch: 2 [5223424/8742050 (59.8%)]	Loss: 0.092841
Train Epoch: 2 [5274624/8742050 (60.3%)]	Loss: 0.104716
Train Epoch: 2 [5325824/8742050 (60.9%)]	Loss: 0.107769
Train Epoch: 2 [5377024/8742050 (61.5%)]	Loss: 0.106719
Train Epoch: 2 [5428224/8742050 (62.1%)]	Loss: 0.111115
Train Epoch: 2 [5479424/8742050 (62.7%)]	Loss: 0.099592
Train Epoch: 2 [5530624/8742050 (63.3%)]	Loss: 0.114646
Train Epoch: 2 [5581824/8742050 (63.9%)]	Loss: 0.103201
Train Epoch: 2 [5633024/8742050 (64.4%)]	Loss: 0.103689
Train Epoch: 2 [5684224/8742050 (65.0%)]	Loss: 0.113313
Train Epoch: 2 [5735424/8742050 (65.6%)]	Loss: 0.120031
Train Epoch: 2 [5786624/8742050 (66.2%)]	Loss: 0.104430
Train Epoch: 2 [5837824/8742050 (66.8%)]	Loss: 0.106818
Train Epoch: 2 [5889024/8742050 (67.4%)]	Loss: 0.105406
Train Epoch: 2 [5940224/8742050 (68.0%)]	Loss: 0.106989
Train Epoch: 2 [5991424/8742050 (68.5%)]	Loss: 0.110677
Train Epoch: 2 [6042624/8742050 (69.1%)]	Loss: 0.121684
Train Epoch: 2 [6093824/8742050 (69.7%)]	Loss: 0.106873
Train Epoch: 2 [6145024/8742050 (70.3%)]	Loss: 0.119211
Train Epoch: 2 [6196224/8742050 (70.9%)]	Loss: 0.112110
Train Epoch: 2 [6247424/8742050 (71.5%)]	Loss: 0.110590
Train Epoch: 2 [6298624/8742050 (72.0%)]	Loss: 0.111367
Train Epoch: 2 [6349824/8742050 (72.6%)]	Loss: 0.114147
Train Epoch: 2 [6401024/8742050 (73.2%)]	Loss: 0.104270
Train Epoch: 2 [6452224/8742050 (73.8%)]	Loss: 0.111164
Train Epoch: 2 [6503424/8742050 (74.4%)]	Loss: 0.117911
Train Epoch: 2 [6554624/8742050 (75.0%)]	Loss: 0.115052
Train Epoch: 2 [6605824/8742050 (75.6%)]	Loss: 0.115607
Train Epoch: 2 [6657024/8742050 (76.1%)]	Loss: 0.129465
Train Epoch: 2 [6708224/8742050 (76.7%)]	Loss: 0.116716
Train Epoch: 2 [6759424/8742050 (77.3%)]	Loss: 0.116905
Train Epoch: 2 [6810624/8742050 (77.9%)]	Loss: 0.117103
Train Epoch: 2 [6861824/8742050 (78.5%)]	Loss: 0.113005
Train Epoch: 2 [6913024/8742050 (79.1%)]	Loss: 0.107169
Train Epoch: 2 [6964224/8742050 (79.7%)]	Loss: 0.107699
Train Epoch: 2 [7015424/8742050 (80.2%)]	Loss: 0.111122
Train Epoch: 2 [7066624/8742050 (80.8%)]	Loss: 0.111040
Train Epoch: 2 [7117824/8742050 (81.4%)]	Loss: 0.112103
Train Epoch: 2 [7169024/8742050 (82.0%)]	Loss: 0.108915
Train Epoch: 2 [7220224/8742050 (82.6%)]	Loss: 0.108902
Train Epoch: 2 [7271424/8742050 (83.2%)]	Loss: 0.121626
Train Epoch: 2 [7322624/8742050 (83.8%)]	Loss: 0.115888
Train Epoch: 2 [7373824/8742050 (84.3%)]	Loss: 0.103389
Train Epoch: 2 [7425024/8742050 (84.9%)]	Loss: 0.109432
Train Epoch: 2 [7476224/8742050 (85.5%)]	Loss: 0.108771
Train Epoch: 2 [7527424/8742050 (86.1%)]	Loss: 0.113511
Train Epoch: 2 [7578624/8742050 (86.7%)]	Loss: 0.106302
Train Epoch: 2 [7629824/8742050 (87.3%)]	Loss: 0.127489
Train Epoch: 2 [7681024/8742050 (87.9%)]	Loss: 0.100339
Train Epoch: 2 [7732224/8742050 (88.4%)]	Loss: 0.107551
Train Epoch: 2 [7783424/8742050 (89.0%)]	Loss: 0.101539
Train Epoch: 2 [7834624/8742050 (89.6%)]	Loss: 0.115435
Train Epoch: 2 [7885824/8742050 (90.2%)]	Loss: 0.095994
Train Epoch: 2 [7937024/8742050 (90.8%)]	Loss: 0.103616
Train Epoch: 2 [7988224/8742050 (91.4%)]	Loss: 0.099736
Train Epoch: 2 [8039424/8742050 (92.0%)]	Loss: 0.117515
Train Epoch: 2 [8090624/8742050 (92.5%)]	Loss: 0.114990
Train Epoch: 2 [8141824/8742050 (93.1%)]	Loss: 0.124041
Train Epoch: 2 [8193024/8742050 (93.7%)]	Loss: 0.101495
Train Epoch: 2 [8244224/8742050 (94.3%)]	Loss: 0.089485
Train Epoch: 2 [8295424/8742050 (94.9%)]	Loss: 0.103658
Train Epoch: 2 [8346624/8742050 (95.5%)]	Loss: 0.110450
Train Epoch: 2 [8397824/8742050 (96.1%)]	Loss: 0.104706
Train Epoch: 2 [8449024/8742050 (96.6%)]	Loss: 0.106887
Train Epoch: 2 [8500224/8742050 (97.2%)]	Loss: 0.118701
Train Epoch: 2 [8551424/8742050 (97.8%)]	Loss: 0.110821
Train Epoch: 2 [8602624/8742050 (98.4%)]	Loss: 0.126538
Train Epoch: 2 [8653824/8742050 (99.0%)]	Loss: 0.106313
Train Epoch: 2 [8705024/8742050 (99.6%)]	Loss: 0.103465

 ---------------------------------------------------------------------- 


ACC in fold#0 was 0.907


Confusion Matrix in fold#0: 
           nonRipple   Ripple
nonRipple     466528   186051
Ripple         16942  1515992


Classification Report in fold#0: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.965        0.891     0.907        0.928         0.913
recall            0.715        0.989     0.907        0.852         0.907
f1-score          0.821        0.937     0.907        0.879         0.903
sample size  652579.000  1532934.000     0.907  2185513.000   2185513.000


PR_AUC in fold#0 was 0.979


ROC_AUC in fold#0 was 0.963

Time (id:1): tot 03:49:09, prev 03:49:09 [hh:mm:ss]: 
i_fold=0 ends.



 ---------------------------------------------------------------------- 

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8742050 (0.0%)]	Loss: 0.352086
Train Epoch: 1 [52224/8742050 (0.6%)]	Loss: 0.159800
Train Epoch: 1 [103424/8742050 (1.2%)]	Loss: 0.119843
Train Epoch: 1 [154624/8742050 (1.8%)]	Loss: 0.125315
Train Epoch: 1 [205824/8742050 (2.4%)]	Loss: 0.131018
Train Epoch: 1 [257024/8742050 (2.9%)]	Loss: 0.128869
Train Epoch: 1 [308224/8742050 (3.5%)]	Loss: 0.131607
Train Epoch: 1 [359424/8742050 (4.1%)]	Loss: 0.111169
Train Epoch: 1 [410624/8742050 (4.7%)]	Loss: 0.133275
Train Epoch: 1 [461824/8742050 (5.3%)]	Loss: 0.126905
Train Epoch: 1 [513024/8742050 (5.9%)]	Loss: 0.108274
Train Epoch: 1 [564224/8742050 (6.5%)]	Loss: 0.125816
Train Epoch: 1 [615424/8742050 (7.0%)]	Loss: 0.120948
Train Epoch: 1 [666624/8742050 (7.6%)]	Loss: 0.141021
Train Epoch: 1 [717824/8742050 (8.2%)]	Loss: 0.124201
Train Epoch: 1 [769024/8742050 (8.8%)]	Loss: 0.112425
Train Epoch: 1 [820224/8742050 (9.4%)]	Loss: 0.124250
Train Epoch: 1 [871424/8742050 (10.0%)]	Loss: 0.108234
Train Epoch: 1 [922624/8742050 (10.6%)]	Loss: 0.109647
Train Epoch: 1 [973824/8742050 (11.1%)]	Loss: 0.139901
Train Epoch: 1 [1025024/8742050 (11.7%)]	Loss: 0.117802
Train Epoch: 1 [1076224/8742050 (12.3%)]	Loss: 0.122886
Train Epoch: 1 [1127424/8742050 (12.9%)]	Loss: 0.122070
Train Epoch: 1 [1178624/8742050 (13.5%)]	Loss: 0.125782
Train Epoch: 1 [1229824/8742050 (14.1%)]	Loss: 0.123214
Train Epoch: 1 [1281024/8742050 (14.7%)]	Loss: 0.106203
Train Epoch: 1 [1332224/8742050 (15.2%)]	Loss: 0.113750
Train Epoch: 1 [1383424/8742050 (15.8%)]	Loss: 0.113171
Train Epoch: 1 [1434624/8742050 (16.4%)]	Loss: 0.119176
Train Epoch: 1 [1485824/8742050 (17.0%)]	Loss: 0.115138
Train Epoch: 1 [1537024/8742050 (17.6%)]	Loss: 0.122065
Train Epoch: 1 [1588224/8742050 (18.2%)]	Loss: 0.101812
Train Epoch: 1 [1639424/8742050 (18.8%)]	Loss: 0.116711
Train Epoch: 1 [1690624/8742050 (19.3%)]	Loss: 0.109028
Train Epoch: 1 [1741824/8742050 (19.9%)]	Loss: 0.118202
Train Epoch: 1 [1793024/8742050 (20.5%)]	Loss: 0.114010
Train Epoch: 1 [1844224/8742050 (21.1%)]	Loss: 0.113549
Train Epoch: 1 [1895424/8742050 (21.7%)]	Loss: 0.111777
Train Epoch: 1 [1946624/8742050 (22.3%)]	Loss: 0.107365
Train Epoch: 1 [1997824/8742050 (22.9%)]	Loss: 0.105941
Train Epoch: 1 [2049024/8742050 (23.4%)]	Loss: 0.105550
Train Epoch: 1 [2100224/8742050 (24.0%)]	Loss: 0.120759
Train Epoch: 1 [2151424/8742050 (24.6%)]	Loss: 0.120704
Train Epoch: 1 [2202624/8742050 (25.2%)]	Loss: 0.112759
Train Epoch: 1 [2253824/8742050 (25.8%)]	Loss: 0.120688
Train Epoch: 1 [2305024/8742050 (26.4%)]	Loss: 0.115829
Train Epoch: 1 [2356224/8742050 (27.0%)]	Loss: 0.119336
Train Epoch: 1 [2407424/8742050 (27.5%)]	Loss: 0.125177
Train Epoch: 1 [2458624/8742050 (28.1%)]	Loss: 0.118571
Train Epoch: 1 [2509824/8742050 (28.7%)]	Loss: 0.129619
Train Epoch: 1 [2561024/8742050 (29.3%)]	Loss: 0.107356
Train Epoch: 1 [2612224/8742050 (29.9%)]	Loss: 0.129736
Train Epoch: 1 [2663424/8742050 (30.5%)]	Loss: 0.125912
Train Epoch: 1 [2714624/8742050 (31.1%)]	Loss: 0.118286
Train Epoch: 1 [2765824/8742050 (31.6%)]	Loss: 0.108111
Train Epoch: 1 [2817024/8742050 (32.2%)]	Loss: 0.119365
Train Epoch: 1 [2868224/8742050 (32.8%)]	Loss: 0.116388
Train Epoch: 1 [2919424/8742050 (33.4%)]	Loss: 0.121073
Train Epoch: 1 [2970624/8742050 (34.0%)]	Loss: 0.107870
Train Epoch: 1 [3021824/8742050 (34.6%)]	Loss: 0.106670
Train Epoch: 1 [3073024/8742050 (35.2%)]	Loss: 0.114000
Train Epoch: 1 [3124224/8742050 (35.7%)]	Loss: 0.118977
Train Epoch: 1 [3175424/8742050 (36.3%)]	Loss: 0.110380
Train Epoch: 1 [3226624/8742050 (36.9%)]	Loss: 0.109247
Train Epoch: 1 [3277824/8742050 (37.5%)]	Loss: 0.114059
Train Epoch: 1 [3329024/8742050 (38.1%)]	Loss: 0.115245
Train Epoch: 1 [3380224/8742050 (38.7%)]	Loss: 0.117529
Train Epoch: 1 [3431424/8742050 (39.3%)]	Loss: 0.123556
Train Epoch: 1 [3482624/8742050 (39.8%)]	Loss: 0.129798
Train Epoch: 1 [3533824/8742050 (40.4%)]	Loss: 0.135560
Train Epoch: 1 [3585024/8742050 (41.0%)]	Loss: 0.123505
Train Epoch: 1 [3636224/8742050 (41.6%)]	Loss: 0.110114
Train Epoch: 1 [3687424/8742050 (42.2%)]	Loss: 0.123947
Train Epoch: 1 [3738624/8742050 (42.8%)]	Loss: 0.112920
Train Epoch: 1 [3789824/8742050 (43.4%)]	Loss: 0.124256
Train Epoch: 1 [3841024/8742050 (43.9%)]	Loss: 0.114411
Train Epoch: 1 [3892224/8742050 (44.5%)]	Loss: 0.105220
Train Epoch: 1 [3943424/8742050 (45.1%)]	Loss: 0.100833
Train Epoch: 1 [3994624/8742050 (45.7%)]	Loss: 0.125382
Train Epoch: 1 [4045824/8742050 (46.3%)]	Loss: 0.108541
Train Epoch: 1 [4097024/8742050 (46.9%)]	Loss: 0.112568
Train Epoch: 1 [4148224/8742050 (47.5%)]	Loss: 0.129235
Train Epoch: 1 [4199424/8742050 (48.0%)]	Loss: 0.114456
Train Epoch: 1 [4250624/8742050 (48.6%)]	Loss: 0.106652
Train Epoch: 1 [4301824/8742050 (49.2%)]	Loss: 0.115363
Train Epoch: 1 [4353024/8742050 (49.8%)]	Loss: 0.115171
Train Epoch: 1 [4404224/8742050 (50.4%)]	Loss: 0.127913
Train Epoch: 1 [4455424/8742050 (51.0%)]	Loss: 0.124944
Train Epoch: 1 [4506624/8742050 (51.6%)]	Loss: 0.117665
Train Epoch: 1 [4557824/8742050 (52.1%)]	Loss: 0.116361
Train Epoch: 1 [4609024/8742050 (52.7%)]	Loss: 0.117338
Train Epoch: 1 [4660224/8742050 (53.3%)]	Loss: 0.103295
Train Epoch: 1 [4711424/8742050 (53.9%)]	Loss: 0.123478
Train Epoch: 1 [4762624/8742050 (54.5%)]	Loss: 0.127626
Train Epoch: 1 [4813824/8742050 (55.1%)]	Loss: 0.106733
Train Epoch: 1 [4865024/8742050 (55.7%)]	Loss: 0.101650
Train Epoch: 1 [4916224/8742050 (56.2%)]	Loss: 0.125715
Train Epoch: 1 [4967424/8742050 (56.8%)]	Loss: 0.115495
Train Epoch: 1 [5018624/8742050 (57.4%)]	Loss: 0.115441
Train Epoch: 1 [5069824/8742050 (58.0%)]	Loss: 0.103860
Train Epoch: 1 [5121024/8742050 (58.6%)]	Loss: 0.111840
Train Epoch: 1 [5172224/8742050 (59.2%)]	Loss: 0.100278
Train Epoch: 1 [5223424/8742050 (59.8%)]	Loss: 0.120545
Train Epoch: 1 [5274624/8742050 (60.3%)]	Loss: 0.098693
Train Epoch: 1 [5325824/8742050 (60.9%)]	Loss: 0.109994
Train Epoch: 1 [5377024/8742050 (61.5%)]	Loss: 0.114411
Train Epoch: 1 [5428224/8742050 (62.1%)]	Loss: 0.105242
Train Epoch: 1 [5479424/8742050 (62.7%)]	Loss: 0.104334
Train Epoch: 1 [5530624/8742050 (63.3%)]	Loss: 0.108645
Train Epoch: 1 [5581824/8742050 (63.9%)]	Loss: 0.108508
Train Epoch: 1 [5633024/8742050 (64.4%)]	Loss: 0.111141
Train Epoch: 1 [5684224/8742050 (65.0%)]	Loss: 0.112938
Train Epoch: 1 [5735424/8742050 (65.6%)]	Loss: 0.111978
Train Epoch: 1 [5786624/8742050 (66.2%)]	Loss: 0.116618
Train Epoch: 1 [5837824/8742050 (66.8%)]	Loss: 0.107871
Train Epoch: 1 [5889024/8742050 (67.4%)]	Loss: 0.117034
Train Epoch: 1 [5940224/8742050 (68.0%)]	Loss: 0.113960
Train Epoch: 1 [5991424/8742050 (68.5%)]	Loss: 0.107483
Train Epoch: 1 [6042624/8742050 (69.1%)]	Loss: 0.112407
Train Epoch: 1 [6093824/8742050 (69.7%)]	Loss: 0.127479
Train Epoch: 1 [6145024/8742050 (70.3%)]	Loss: 0.115341
Train Epoch: 1 [6196224/8742050 (70.9%)]	Loss: 0.109494
Train Epoch: 1 [6247424/8742050 (71.5%)]	Loss: 0.122170
Train Epoch: 1 [6298624/8742050 (72.0%)]	Loss: 0.111425
Train Epoch: 1 [6349824/8742050 (72.6%)]	Loss: 0.093465
Train Epoch: 1 [6401024/8742050 (73.2%)]	Loss: 0.097757
Train Epoch: 1 [6452224/8742050 (73.8%)]	Loss: 0.104756
Train Epoch: 1 [6503424/8742050 (74.4%)]	Loss: 0.103749
Train Epoch: 1 [6554624/8742050 (75.0%)]	Loss: 0.125007
Train Epoch: 1 [6605824/8742050 (75.6%)]	Loss: 0.106436
Train Epoch: 1 [6657024/8742050 (76.1%)]	Loss: 0.103048
Train Epoch: 1 [6708224/8742050 (76.7%)]	Loss: 0.113107
Train Epoch: 1 [6759424/8742050 (77.3%)]	Loss: 0.102823
Train Epoch: 1 [6810624/8742050 (77.9%)]	Loss: 0.113925
Train Epoch: 1 [6861824/8742050 (78.5%)]	Loss: 0.101700
Train Epoch: 1 [6913024/8742050 (79.1%)]	Loss: 0.117122
Train Epoch: 1 [6964224/8742050 (79.7%)]	Loss: 0.115029
Train Epoch: 1 [7015424/8742050 (80.2%)]	Loss: 0.123671
Train Epoch: 1 [7066624/8742050 (80.8%)]	Loss: 0.095817
Train Epoch: 1 [7117824/8742050 (81.4%)]	Loss: 0.122235
Train Epoch: 1 [7169024/8742050 (82.0%)]	Loss: 0.116297
Train Epoch: 1 [7220224/8742050 (82.6%)]	Loss: 0.122295
Train Epoch: 1 [7271424/8742050 (83.2%)]	Loss: 0.115258
Train Epoch: 1 [7322624/8742050 (83.8%)]	Loss: 0.116436
Train Epoch: 1 [7373824/8742050 (84.3%)]	Loss: 0.111811
Train Epoch: 1 [7425024/8742050 (84.9%)]	Loss: 0.116706
Train Epoch: 1 [7476224/8742050 (85.5%)]	Loss: 0.131623
Train Epoch: 1 [7527424/8742050 (86.1%)]	Loss: 0.109470
Train Epoch: 1 [7578624/8742050 (86.7%)]	Loss: 0.109952
Train Epoch: 1 [7629824/8742050 (87.3%)]	Loss: 0.099091
Train Epoch: 1 [7681024/8742050 (87.9%)]	Loss: 0.102290
Train Epoch: 1 [7732224/8742050 (88.4%)]	Loss: 0.110097
Train Epoch: 1 [7783424/8742050 (89.0%)]	Loss: 0.096269
Train Epoch: 1 [7834624/8742050 (89.6%)]	Loss: 0.115738
Train Epoch: 1 [7885824/8742050 (90.2%)]	Loss: 0.123874
Train Epoch: 1 [7937024/8742050 (90.8%)]	Loss: 0.102835
Train Epoch: 1 [7988224/8742050 (91.4%)]	Loss: 0.105764
Train Epoch: 1 [8039424/8742050 (92.0%)]	Loss: 0.111451
Train Epoch: 1 [8090624/8742050 (92.5%)]	Loss: 0.108344
Train Epoch: 1 [8141824/8742050 (93.1%)]	Loss: 0.111607
Train Epoch: 1 [8193024/8742050 (93.7%)]	Loss: 0.118045
Train Epoch: 1 [8244224/8742050 (94.3%)]	Loss: 0.107704
Train Epoch: 1 [8295424/8742050 (94.9%)]	Loss: 0.104282
Train Epoch: 1 [8346624/8742050 (95.5%)]	Loss: 0.121789
Train Epoch: 1 [8397824/8742050 (96.1%)]	Loss: 0.106276
Train Epoch: 1 [8449024/8742050 (96.6%)]	Loss: 0.109406
Train Epoch: 1 [8500224/8742050 (97.2%)]	Loss: 0.096102
Train Epoch: 1 [8551424/8742050 (97.8%)]	Loss: 0.112624
Train Epoch: 1 [8602624/8742050 (98.4%)]	Loss: 0.109936
Train Epoch: 1 [8653824/8742050 (99.0%)]	Loss: 0.106807
Train Epoch: 1 [8705024/8742050 (99.6%)]	Loss: 0.113121
Train Epoch: 2 [1024/8742050 (0.0%)]	Loss: 0.109156
Train Epoch: 2 [52224/8742050 (0.6%)]	Loss: 0.111513
Train Epoch: 2 [103424/8742050 (1.2%)]	Loss: 0.114694
Train Epoch: 2 [154624/8742050 (1.8%)]	Loss: 0.115929
Train Epoch: 2 [205824/8742050 (2.4%)]	Loss: 0.126041
Train Epoch: 2 [257024/8742050 (2.9%)]	Loss: 0.120443
Train Epoch: 2 [308224/8742050 (3.5%)]	Loss: 0.112723
Train Epoch: 2 [359424/8742050 (4.1%)]	Loss: 0.120676
Train Epoch: 2 [410624/8742050 (4.7%)]	Loss: 0.110865
Train Epoch: 2 [461824/8742050 (5.3%)]	Loss: 0.099745
Train Epoch: 2 [513024/8742050 (5.9%)]	Loss: 0.095633
Train Epoch: 2 [564224/8742050 (6.5%)]	Loss: 0.117170
Train Epoch: 2 [615424/8742050 (7.0%)]	Loss: 0.119142
Train Epoch: 2 [666624/8742050 (7.6%)]	Loss: 0.112674
Train Epoch: 2 [717824/8742050 (8.2%)]	Loss: 0.096876
Train Epoch: 2 [769024/8742050 (8.8%)]	Loss: 0.107939
Train Epoch: 2 [820224/8742050 (9.4%)]	Loss: 0.118597
Train Epoch: 2 [871424/8742050 (10.0%)]	Loss: 0.111750
Train Epoch: 2 [922624/8742050 (10.6%)]	Loss: 0.089212
Train Epoch: 2 [973824/8742050 (11.1%)]	Loss: 0.106384
Train Epoch: 2 [1025024/8742050 (11.7%)]	Loss: 0.107846
Train Epoch: 2 [1076224/8742050 (12.3%)]	Loss: 0.116204
Train Epoch: 2 [1127424/8742050 (12.9%)]	Loss: 0.109222
Train Epoch: 2 [1178624/8742050 (13.5%)]	Loss: 0.107842
Train Epoch: 2 [1229824/8742050 (14.1%)]	Loss: 0.112504
Train Epoch: 2 [1281024/8742050 (14.7%)]	Loss: 0.108545
Train Epoch: 2 [1332224/8742050 (15.2%)]	Loss: 0.115628
Train Epoch: 2 [1383424/8742050 (15.8%)]	Loss: 0.102931
Train Epoch: 2 [1434624/8742050 (16.4%)]	Loss: 0.125409
Train Epoch: 2 [1485824/8742050 (17.0%)]	Loss: 0.116780
Train Epoch: 2 [1537024/8742050 (17.6%)]	Loss: 0.111251
Train Epoch: 2 [1588224/8742050 (18.2%)]	Loss: 0.110346
Train Epoch: 2 [1639424/8742050 (18.8%)]	Loss: 0.115733
Train Epoch: 2 [1690624/8742050 (19.3%)]	Loss: 0.097310
Train Epoch: 2 [1741824/8742050 (19.9%)]	Loss: 0.100298
Train Epoch: 2 [1793024/8742050 (20.5%)]	Loss: 0.103529
Train Epoch: 2 [1844224/8742050 (21.1%)]	Loss: 0.104443
Train Epoch: 2 [1895424/8742050 (21.7%)]	Loss: 0.105404
Train Epoch: 2 [1946624/8742050 (22.3%)]	Loss: 0.113764
Train Epoch: 2 [1997824/8742050 (22.9%)]	Loss: 0.104834
Train Epoch: 2 [2049024/8742050 (23.4%)]	Loss: 0.108247
Train Epoch: 2 [2100224/8742050 (24.0%)]	Loss: 0.098993
Train Epoch: 2 [2151424/8742050 (24.6%)]	Loss: 0.119456
Train Epoch: 2 [2202624/8742050 (25.2%)]	Loss: 0.117023
Train Epoch: 2 [2253824/8742050 (25.8%)]	Loss: 0.111820
Train Epoch: 2 [2305024/8742050 (26.4%)]	Loss: 0.113043
Train Epoch: 2 [2356224/8742050 (27.0%)]	Loss: 0.100281
Train Epoch: 2 [2407424/8742050 (27.5%)]	Loss: 0.100625
Train Epoch: 2 [2458624/8742050 (28.1%)]	Loss: 0.116671
Train Epoch: 2 [2509824/8742050 (28.7%)]	Loss: 0.109194
Train Epoch: 2 [2561024/8742050 (29.3%)]	Loss: 0.117231
Train Epoch: 2 [2612224/8742050 (29.9%)]	Loss: 0.121721
Train Epoch: 2 [2663424/8742050 (30.5%)]	Loss: 0.102350
Train Epoch: 2 [2714624/8742050 (31.1%)]	Loss: 0.110372
Train Epoch: 2 [2765824/8742050 (31.6%)]	Loss: 0.114721
Train Epoch: 2 [2817024/8742050 (32.2%)]	Loss: 0.101012
Train Epoch: 2 [2868224/8742050 (32.8%)]	Loss: 0.109993
Train Epoch: 2 [2919424/8742050 (33.4%)]	Loss: 0.116969
Train Epoch: 2 [2970624/8742050 (34.0%)]	Loss: 0.094627
Train Epoch: 2 [3021824/8742050 (34.6%)]	Loss: 0.118252
Train Epoch: 2 [3073024/8742050 (35.2%)]	Loss: 0.114379
Train Epoch: 2 [3124224/8742050 (35.7%)]	Loss: 0.096112
Train Epoch: 2 [3175424/8742050 (36.3%)]	Loss: 0.110114
Train Epoch: 2 [3226624/8742050 (36.9%)]	Loss: 0.106689
Train Epoch: 2 [3277824/8742050 (37.5%)]	Loss: 0.109663
Train Epoch: 2 [3329024/8742050 (38.1%)]	Loss: 0.104212
Train Epoch: 2 [3380224/8742050 (38.7%)]	Loss: 0.116770
Train Epoch: 2 [3431424/8742050 (39.3%)]	Loss: 0.111752
Train Epoch: 2 [3482624/8742050 (39.8%)]	Loss: 0.100358
Train Epoch: 2 [3533824/8742050 (40.4%)]	Loss: 0.109598
Train Epoch: 2 [3585024/8742050 (41.0%)]	Loss: 0.100847
Train Epoch: 2 [3636224/8742050 (41.6%)]	Loss: 0.119328
Train Epoch: 2 [3687424/8742050 (42.2%)]	Loss: 0.108009
Train Epoch: 2 [3738624/8742050 (42.8%)]	Loss: 0.103798
Train Epoch: 2 [3789824/8742050 (43.4%)]	Loss: 0.100585
Train Epoch: 2 [3841024/8742050 (43.9%)]	Loss: 0.107345
Train Epoch: 2 [3892224/8742050 (44.5%)]	Loss: 0.105532
Train Epoch: 2 [3943424/8742050 (45.1%)]	Loss: 0.116993
Train Epoch: 2 [3994624/8742050 (45.7%)]	Loss: 0.120369
Train Epoch: 2 [4045824/8742050 (46.3%)]	Loss: 0.112978
Train Epoch: 2 [4097024/8742050 (46.9%)]	Loss: 0.106027
Train Epoch: 2 [4148224/8742050 (47.5%)]	Loss: 0.108980
Train Epoch: 2 [4199424/8742050 (48.0%)]	Loss: 0.096135
Train Epoch: 2 [4250624/8742050 (48.6%)]	Loss: 0.098685
Train Epoch: 2 [4301824/8742050 (49.2%)]	Loss: 0.116314
Train Epoch: 2 [4353024/8742050 (49.8%)]	Loss: 0.137280
Train Epoch: 2 [4404224/8742050 (50.4%)]	Loss: 0.107191
Train Epoch: 2 [4455424/8742050 (51.0%)]	Loss: 0.112946
Train Epoch: 2 [4506624/8742050 (51.6%)]	Loss: 0.106105
Train Epoch: 2 [4557824/8742050 (52.1%)]	Loss: 0.108042
Train Epoch: 2 [4609024/8742050 (52.7%)]	Loss: 0.110399
Train Epoch: 2 [4660224/8742050 (53.3%)]	Loss: 0.112546
Train Epoch: 2 [4711424/8742050 (53.9%)]	Loss: 0.094490
Train Epoch: 2 [4762624/8742050 (54.5%)]	Loss: 0.101771
Train Epoch: 2 [4813824/8742050 (55.1%)]	Loss: 0.115456
Train Epoch: 2 [4865024/8742050 (55.7%)]	Loss: 0.110148
Train Epoch: 2 [4916224/8742050 (56.2%)]	Loss: 0.103261
Train Epoch: 2 [4967424/8742050 (56.8%)]	Loss: 0.103872
Train Epoch: 2 [5018624/8742050 (57.4%)]	Loss: 0.095298
Train Epoch: 2 [5069824/8742050 (58.0%)]	Loss: 0.111831
Train Epoch: 2 [5121024/8742050 (58.6%)]	Loss: 0.111978
Train Epoch: 2 [5172224/8742050 (59.2%)]	Loss: 0.129529
Train Epoch: 2 [5223424/8742050 (59.8%)]	Loss: 0.110631
Train Epoch: 2 [5274624/8742050 (60.3%)]	Loss: 0.109336
Train Epoch: 2 [5325824/8742050 (60.9%)]	Loss: 0.105458
Train Epoch: 2 [5377024/8742050 (61.5%)]	Loss: 0.105674
Train Epoch: 2 [5428224/8742050 (62.1%)]	Loss: 0.118406
Train Epoch: 2 [5479424/8742050 (62.7%)]	Loss: 0.106192
Train Epoch: 2 [5530624/8742050 (63.3%)]	Loss: 0.114070
Train Epoch: 2 [5581824/8742050 (63.9%)]	Loss: 0.129046
Train Epoch: 2 [5633024/8742050 (64.4%)]	Loss: 0.101965
Train Epoch: 2 [5684224/8742050 (65.0%)]	Loss: 0.124895
Train Epoch: 2 [5735424/8742050 (65.6%)]	Loss: 0.101095
Train Epoch: 2 [5786624/8742050 (66.2%)]	Loss: 0.108247
Train Epoch: 2 [5837824/8742050 (66.8%)]	Loss: 0.103841
Train Epoch: 2 [5889024/8742050 (67.4%)]	Loss: 0.105885
Train Epoch: 2 [5940224/8742050 (68.0%)]	Loss: 0.109041
Train Epoch: 2 [5991424/8742050 (68.5%)]	Loss: 0.128827
Train Epoch: 2 [6042624/8742050 (69.1%)]	Loss: 0.126311
Train Epoch: 2 [6093824/8742050 (69.7%)]	Loss: 0.115206
Train Epoch: 2 [6145024/8742050 (70.3%)]	Loss: 0.113692
Train Epoch: 2 [6196224/8742050 (70.9%)]	Loss: 0.112922
Train Epoch: 2 [6247424/8742050 (71.5%)]	Loss: 0.100770
Train Epoch: 2 [6298624/8742050 (72.0%)]	Loss: 0.110997
Train Epoch: 2 [6349824/8742050 (72.6%)]	Loss: 0.127371
Train Epoch: 2 [6401024/8742050 (73.2%)]	Loss: 0.100370
Train Epoch: 2 [6452224/8742050 (73.8%)]	Loss: 0.108547
Train Epoch: 2 [6503424/8742050 (74.4%)]	Loss: 0.102368
Train Epoch: 2 [6554624/8742050 (75.0%)]	Loss: 0.114827
Train Epoch: 2 [6605824/8742050 (75.6%)]	Loss: 0.123093
Train Epoch: 2 [6657024/8742050 (76.1%)]	Loss: 0.107968
Train Epoch: 2 [6708224/8742050 (76.7%)]	Loss: 0.112894
Train Epoch: 2 [6759424/8742050 (77.3%)]	Loss: 0.098370
Train Epoch: 2 [6810624/8742050 (77.9%)]	Loss: 0.115620
Train Epoch: 2 [6861824/8742050 (78.5%)]	Loss: 0.110503
Train Epoch: 2 [6913024/8742050 (79.1%)]	Loss: 0.104382
Train Epoch: 2 [6964224/8742050 (79.7%)]	Loss: 0.115068
Train Epoch: 2 [7015424/8742050 (80.2%)]	Loss: 0.102636
Train Epoch: 2 [7066624/8742050 (80.8%)]	Loss: 0.115461
Train Epoch: 2 [7117824/8742050 (81.4%)]	Loss: 0.088566
Train Epoch: 2 [7169024/8742050 (82.0%)]	Loss: 0.103693
Train Epoch: 2 [7220224/8742050 (82.6%)]	Loss: 0.099326
Train Epoch: 2 [7271424/8742050 (83.2%)]	Loss: 0.113644
Train Epoch: 2 [7322624/8742050 (83.8%)]	Loss: 0.109654
Train Epoch: 2 [7373824/8742050 (84.3%)]	Loss: 0.122519
Train Epoch: 2 [7425024/8742050 (84.9%)]	Loss: 0.120291
Train Epoch: 2 [7476224/8742050 (85.5%)]	Loss: 0.111115
Train Epoch: 2 [7527424/8742050 (86.1%)]	Loss: 0.098257
Train Epoch: 2 [7578624/8742050 (86.7%)]	Loss: 0.104729
Train Epoch: 2 [7629824/8742050 (87.3%)]	Loss: 0.109857
Train Epoch: 2 [7681024/8742050 (87.9%)]	Loss: 0.108625
Train Epoch: 2 [7732224/8742050 (88.4%)]	Loss: 0.106325
Train Epoch: 2 [7783424/8742050 (89.0%)]	Loss: 0.123646
Train Epoch: 2 [7834624/8742050 (89.6%)]	Loss: 0.087363
Train Epoch: 2 [7885824/8742050 (90.2%)]	Loss: 0.099505
Train Epoch: 2 [7937024/8742050 (90.8%)]	Loss: 0.124817
Train Epoch: 2 [7988224/8742050 (91.4%)]	Loss: 0.104073
Train Epoch: 2 [8039424/8742050 (92.0%)]	Loss: 0.121394
Train Epoch: 2 [8090624/8742050 (92.5%)]	Loss: 0.111405
Train Epoch: 2 [8141824/8742050 (93.1%)]	Loss: 0.124001
Train Epoch: 2 [8193024/8742050 (93.7%)]	Loss: 0.101043
Train Epoch: 2 [8244224/8742050 (94.3%)]	Loss: 0.110364
Train Epoch: 2 [8295424/8742050 (94.9%)]	Loss: 0.112423
Train Epoch: 2 [8346624/8742050 (95.5%)]	Loss: 0.111787
Train Epoch: 2 [8397824/8742050 (96.1%)]	Loss: 0.110868
Train Epoch: 2 [8449024/8742050 (96.6%)]	Loss: 0.119620
Train Epoch: 2 [8500224/8742050 (97.2%)]	Loss: 0.110382
Train Epoch: 2 [8551424/8742050 (97.8%)]	Loss: 0.122423
Train Epoch: 2 [8602624/8742050 (98.4%)]	Loss: 0.104074
Train Epoch: 2 [8653824/8742050 (99.0%)]	Loss: 0.109096
Train Epoch: 2 [8705024/8742050 (99.6%)]	Loss: 0.111941

 ---------------------------------------------------------------------- 


ACC in fold#1 was 0.904


Confusion Matrix in fold#1: 
           nonRipple   Ripple
nonRipple     473229   179350
Ripple         31364  1501570


Classification Report in fold#1: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.938        0.893     0.904        0.916         0.907
recall            0.725        0.980     0.904        0.852         0.904
f1-score          0.818        0.934     0.904        0.876         0.900
sample size  652579.000  1532934.000     0.904  2185513.000   2185513.000


PR_AUC in fold#1 was 0.975


ROC_AUC in fold#1 was 0.955

Time (id:2): tot 07:39:09, prev 03:50:00 [hh:mm:ss]: 
i_fold=1 ends.



 ---------------------------------------------------------------------- 

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8742050 (0.0%)]	Loss: 0.359211
Train Epoch: 1 [52224/8742050 (0.6%)]	Loss: 0.159784
Train Epoch: 1 [103424/8742050 (1.2%)]	Loss: 0.123450
Train Epoch: 1 [154624/8742050 (1.8%)]	Loss: 0.116792
Train Epoch: 1 [205824/8742050 (2.4%)]	Loss: 0.106833
Train Epoch: 1 [257024/8742050 (2.9%)]	Loss: 0.114260
Train Epoch: 1 [308224/8742050 (3.5%)]	Loss: 0.111912
Train Epoch: 1 [359424/8742050 (4.1%)]	Loss: 0.115612
Train Epoch: 1 [410624/8742050 (4.7%)]	Loss: 0.124075
Train Epoch: 1 [461824/8742050 (5.3%)]	Loss: 0.112208
Train Epoch: 1 [513024/8742050 (5.9%)]	Loss: 0.117248
Train Epoch: 1 [564224/8742050 (6.5%)]	Loss: 0.124079
Train Epoch: 1 [615424/8742050 (7.0%)]	Loss: 0.108396
Train Epoch: 1 [666624/8742050 (7.6%)]	Loss: 0.110068
Train Epoch: 1 [717824/8742050 (8.2%)]	Loss: 0.106314
Train Epoch: 1 [769024/8742050 (8.8%)]	Loss: 0.105795
Train Epoch: 1 [820224/8742050 (9.4%)]	Loss: 0.122757
Train Epoch: 1 [871424/8742050 (10.0%)]	Loss: 0.123574
Train Epoch: 1 [922624/8742050 (10.6%)]	Loss: 0.117274
Train Epoch: 1 [973824/8742050 (11.1%)]	Loss: 0.129183
Train Epoch: 1 [1025024/8742050 (11.7%)]	Loss: 0.127512
Train Epoch: 1 [1076224/8742050 (12.3%)]	Loss: 0.105779
Train Epoch: 1 [1127424/8742050 (12.9%)]	Loss: 0.122199
Train Epoch: 1 [1178624/8742050 (13.5%)]	Loss: 0.115974
Train Epoch: 1 [1229824/8742050 (14.1%)]	Loss: 0.109267
Train Epoch: 1 [1281024/8742050 (14.7%)]	Loss: 0.102270
Train Epoch: 1 [1332224/8742050 (15.2%)]	Loss: 0.121009
Train Epoch: 1 [1383424/8742050 (15.8%)]	Loss: 0.116722
Train Epoch: 1 [1434624/8742050 (16.4%)]	Loss: 0.119245
Train Epoch: 1 [1485824/8742050 (17.0%)]	Loss: 0.121240
Train Epoch: 1 [1537024/8742050 (17.6%)]	Loss: 0.109640
Train Epoch: 1 [1588224/8742050 (18.2%)]	Loss: 0.117377
Train Epoch: 1 [1639424/8742050 (18.8%)]	Loss: 0.116269
Train Epoch: 1 [1690624/8742050 (19.3%)]	Loss: 0.122972
Train Epoch: 1 [1741824/8742050 (19.9%)]	Loss: 0.119513
Train Epoch: 1 [1793024/8742050 (20.5%)]	Loss: 0.113891
Train Epoch: 1 [1844224/8742050 (21.1%)]	Loss: 0.113148
Train Epoch: 1 [1895424/8742050 (21.7%)]	Loss: 0.116896
Train Epoch: 1 [1946624/8742050 (22.3%)]	Loss: 0.114998
Train Epoch: 1 [1997824/8742050 (22.9%)]	Loss: 0.112994
Train Epoch: 1 [2049024/8742050 (23.4%)]	Loss: 0.111327
Train Epoch: 1 [2100224/8742050 (24.0%)]	Loss: 0.105648
Train Epoch: 1 [2151424/8742050 (24.6%)]	Loss: 0.116259
Train Epoch: 1 [2202624/8742050 (25.2%)]	Loss: 0.119455
Train Epoch: 1 [2253824/8742050 (25.8%)]	Loss: 0.110731
Train Epoch: 1 [2305024/8742050 (26.4%)]	Loss: 0.106032
Train Epoch: 1 [2356224/8742050 (27.0%)]	Loss: 0.112316
Train Epoch: 1 [2407424/8742050 (27.5%)]	Loss: 0.098403
Train Epoch: 1 [2458624/8742050 (28.1%)]	Loss: 0.115380
Train Epoch: 1 [2509824/8742050 (28.7%)]	Loss: 0.119396
Train Epoch: 1 [2561024/8742050 (29.3%)]	Loss: 0.102458
Train Epoch: 1 [2612224/8742050 (29.9%)]	Loss: 0.118275
Train Epoch: 1 [2663424/8742050 (30.5%)]	Loss: 0.106681
Train Epoch: 1 [2714624/8742050 (31.1%)]	Loss: 0.114890
Train Epoch: 1 [2765824/8742050 (31.6%)]	Loss: 0.100408
Train Epoch: 1 [2817024/8742050 (32.2%)]	Loss: 0.115350
Train Epoch: 1 [2868224/8742050 (32.8%)]	Loss: 0.110541
Train Epoch: 1 [2919424/8742050 (33.4%)]	Loss: 0.111013
Train Epoch: 1 [2970624/8742050 (34.0%)]	Loss: 0.101286
Train Epoch: 1 [3021824/8742050 (34.6%)]	Loss: 0.122078
Train Epoch: 1 [3073024/8742050 (35.2%)]	Loss: 0.118244
Train Epoch: 1 [3124224/8742050 (35.7%)]	Loss: 0.112882
Train Epoch: 1 [3175424/8742050 (36.3%)]	Loss: 0.116881
Train Epoch: 1 [3226624/8742050 (36.9%)]	Loss: 0.106929
Train Epoch: 1 [3277824/8742050 (37.5%)]	Loss: 0.103551
Train Epoch: 1 [3329024/8742050 (38.1%)]	Loss: 0.117388
Train Epoch: 1 [3380224/8742050 (38.7%)]	Loss: 0.110392
Train Epoch: 1 [3431424/8742050 (39.3%)]	Loss: 0.117926
Train Epoch: 1 [3482624/8742050 (39.8%)]	Loss: 0.107217
Train Epoch: 1 [3533824/8742050 (40.4%)]	Loss: 0.102562
Train Epoch: 1 [3585024/8742050 (41.0%)]	Loss: 0.118538
Train Epoch: 1 [3636224/8742050 (41.6%)]	Loss: 0.097117
Train Epoch: 1 [3687424/8742050 (42.2%)]	Loss: 0.101977
Train Epoch: 1 [3738624/8742050 (42.8%)]	Loss: 0.121039
Train Epoch: 1 [3789824/8742050 (43.4%)]	Loss: 0.099992
Train Epoch: 1 [3841024/8742050 (43.9%)]	Loss: 0.118822
Train Epoch: 1 [3892224/8742050 (44.5%)]	Loss: 0.107449
Train Epoch: 1 [3943424/8742050 (45.1%)]	Loss: 0.124002
Train Epoch: 1 [3994624/8742050 (45.7%)]	Loss: 0.109660
Train Epoch: 1 [4045824/8742050 (46.3%)]	Loss: 0.116906
Train Epoch: 1 [4097024/8742050 (46.9%)]	Loss: 0.100211
Train Epoch: 1 [4148224/8742050 (47.5%)]	Loss: 0.118866
Train Epoch: 1 [4199424/8742050 (48.0%)]	Loss: 0.115127
Train Epoch: 1 [4250624/8742050 (48.6%)]	Loss: 0.105361
Train Epoch: 1 [4301824/8742050 (49.2%)]	Loss: 0.103732
Train Epoch: 1 [4353024/8742050 (49.8%)]	Loss: 0.104438
Train Epoch: 1 [4404224/8742050 (50.4%)]	Loss: 0.113676
Train Epoch: 1 [4455424/8742050 (51.0%)]	Loss: 0.106787
Train Epoch: 1 [4506624/8742050 (51.6%)]	Loss: 0.121859
Train Epoch: 1 [4557824/8742050 (52.1%)]	Loss: 0.123240
Train Epoch: 1 [4609024/8742050 (52.7%)]	Loss: 0.100910
Train Epoch: 1 [4660224/8742050 (53.3%)]	Loss: 0.106521
Train Epoch: 1 [4711424/8742050 (53.9%)]	Loss: 0.105220
Train Epoch: 1 [4762624/8742050 (54.5%)]	Loss: 0.107360
Train Epoch: 1 [4813824/8742050 (55.1%)]	Loss: 0.107851
Train Epoch: 1 [4865024/8742050 (55.7%)]	Loss: 0.115190
Train Epoch: 1 [4916224/8742050 (56.2%)]	Loss: 0.112769
Train Epoch: 1 [4967424/8742050 (56.8%)]	Loss: 0.110865
Train Epoch: 1 [5018624/8742050 (57.4%)]	Loss: 0.120044
Train Epoch: 1 [5069824/8742050 (58.0%)]	Loss: 0.099855
Train Epoch: 1 [5121024/8742050 (58.6%)]	Loss: 0.117973
Train Epoch: 1 [5172224/8742050 (59.2%)]	Loss: 0.115181
Train Epoch: 1 [5223424/8742050 (59.8%)]	Loss: 0.110733
Train Epoch: 1 [5274624/8742050 (60.3%)]	Loss: 0.097651
Train Epoch: 1 [5325824/8742050 (60.9%)]	Loss: 0.105867
Train Epoch: 1 [5377024/8742050 (61.5%)]	Loss: 0.116769
Train Epoch: 1 [5428224/8742050 (62.1%)]	Loss: 0.107991
Train Epoch: 1 [5479424/8742050 (62.7%)]	Loss: 0.114695
Train Epoch: 1 [5530624/8742050 (63.3%)]	Loss: 0.103144
Train Epoch: 1 [5581824/8742050 (63.9%)]	Loss: 0.094465
Train Epoch: 1 [5633024/8742050 (64.4%)]	Loss: 0.120310
Train Epoch: 1 [5684224/8742050 (65.0%)]	Loss: 0.115812
Train Epoch: 1 [5735424/8742050 (65.6%)]	Loss: 0.096078
Train Epoch: 1 [5786624/8742050 (66.2%)]	Loss: 0.116079
Train Epoch: 1 [5837824/8742050 (66.8%)]	Loss: 0.104470
Train Epoch: 1 [5889024/8742050 (67.4%)]	Loss: 0.120034
Train Epoch: 1 [5940224/8742050 (68.0%)]	Loss: 0.102861
Train Epoch: 1 [5991424/8742050 (68.5%)]	Loss: 0.099144
Train Epoch: 1 [6042624/8742050 (69.1%)]	Loss: 0.110042
Train Epoch: 1 [6093824/8742050 (69.7%)]	Loss: 0.107191
Train Epoch: 1 [6145024/8742050 (70.3%)]	Loss: 0.109319
Train Epoch: 1 [6196224/8742050 (70.9%)]	Loss: 0.093266
Train Epoch: 1 [6247424/8742050 (71.5%)]	Loss: 0.104990
Train Epoch: 1 [6298624/8742050 (72.0%)]	Loss: 0.121571
Train Epoch: 1 [6349824/8742050 (72.6%)]	Loss: 0.091463
Train Epoch: 1 [6401024/8742050 (73.2%)]	Loss: 0.113976
Train Epoch: 1 [6452224/8742050 (73.8%)]	Loss: 0.101836
Train Epoch: 1 [6503424/8742050 (74.4%)]	Loss: 0.118104
Train Epoch: 1 [6554624/8742050 (75.0%)]	Loss: 0.123368
Train Epoch: 1 [6605824/8742050 (75.6%)]	Loss: 0.108199
Train Epoch: 1 [6657024/8742050 (76.1%)]	Loss: 0.127810
Train Epoch: 1 [6708224/8742050 (76.7%)]	Loss: 0.111178
Train Epoch: 1 [6759424/8742050 (77.3%)]	Loss: 0.108986
Train Epoch: 1 [6810624/8742050 (77.9%)]	Loss: 0.126476
Train Epoch: 1 [6861824/8742050 (78.5%)]	Loss: 0.119283
Train Epoch: 1 [6913024/8742050 (79.1%)]	Loss: 0.112941
Train Epoch: 1 [6964224/8742050 (79.7%)]	Loss: 0.113397
Train Epoch: 1 [7015424/8742050 (80.2%)]	Loss: 0.106138
Train Epoch: 1 [7066624/8742050 (80.8%)]	Loss: 0.104302
Train Epoch: 1 [7117824/8742050 (81.4%)]	Loss: 0.122682
Train Epoch: 1 [7169024/8742050 (82.0%)]	Loss: 0.094374
Train Epoch: 1 [7220224/8742050 (82.6%)]	Loss: 0.109378
Train Epoch: 1 [7271424/8742050 (83.2%)]	Loss: 0.109202
Train Epoch: 1 [7322624/8742050 (83.8%)]	Loss: 0.096177
Train Epoch: 1 [7373824/8742050 (84.3%)]	Loss: 0.099833
Train Epoch: 1 [7425024/8742050 (84.9%)]	Loss: 0.105732
Train Epoch: 1 [7476224/8742050 (85.5%)]	Loss: 0.108920
Train Epoch: 1 [7527424/8742050 (86.1%)]	Loss: 0.117324
Train Epoch: 1 [7578624/8742050 (86.7%)]	Loss: 0.111368
Train Epoch: 1 [7629824/8742050 (87.3%)]	Loss: 0.116258
Train Epoch: 1 [7681024/8742050 (87.9%)]	Loss: 0.104256
Train Epoch: 1 [7732224/8742050 (88.4%)]	Loss: 0.090331
Train Epoch: 1 [7783424/8742050 (89.0%)]	Loss: 0.105842
Train Epoch: 1 [7834624/8742050 (89.6%)]	Loss: 0.101454
Train Epoch: 1 [7885824/8742050 (90.2%)]	Loss: 0.112237
Train Epoch: 1 [7937024/8742050 (90.8%)]	Loss: 0.110597
Train Epoch: 1 [7988224/8742050 (91.4%)]	Loss: 0.108249
Train Epoch: 1 [8039424/8742050 (92.0%)]	Loss: 0.113801
Train Epoch: 1 [8090624/8742050 (92.5%)]	Loss: 0.097089
Train Epoch: 1 [8141824/8742050 (93.1%)]	Loss: 0.103590
Train Epoch: 1 [8193024/8742050 (93.7%)]	Loss: 0.110654
Train Epoch: 1 [8244224/8742050 (94.3%)]	Loss: 0.106700
Train Epoch: 1 [8295424/8742050 (94.9%)]	Loss: 0.124126
Train Epoch: 1 [8346624/8742050 (95.5%)]	Loss: 0.110744
Train Epoch: 1 [8397824/8742050 (96.1%)]	Loss: 0.108417
Train Epoch: 1 [8449024/8742050 (96.6%)]	Loss: 0.109980
Train Epoch: 1 [8500224/8742050 (97.2%)]	Loss: 0.118483
Train Epoch: 1 [8551424/8742050 (97.8%)]	Loss: 0.103936
Train Epoch: 1 [8602624/8742050 (98.4%)]	Loss: 0.108521
Train Epoch: 1 [8653824/8742050 (99.0%)]	Loss: 0.111411
Train Epoch: 1 [8705024/8742050 (99.6%)]	Loss: 0.107034
Train Epoch: 2 [1024/8742050 (0.0%)]	Loss: 0.106722
Train Epoch: 2 [52224/8742050 (0.6%)]	Loss: 0.105574
Train Epoch: 2 [103424/8742050 (1.2%)]	Loss: 0.089057
Train Epoch: 2 [154624/8742050 (1.8%)]	Loss: 0.105422
Train Epoch: 2 [205824/8742050 (2.4%)]	Loss: 0.116981
Train Epoch: 2 [257024/8742050 (2.9%)]	Loss: 0.117243
Train Epoch: 2 [308224/8742050 (3.5%)]	Loss: 0.111751
Train Epoch: 2 [359424/8742050 (4.1%)]	Loss: 0.107058
Train Epoch: 2 [410624/8742050 (4.7%)]	Loss: 0.099950
Train Epoch: 2 [461824/8742050 (5.3%)]	Loss: 0.102348
Train Epoch: 2 [513024/8742050 (5.9%)]	Loss: 0.117475
Train Epoch: 2 [564224/8742050 (6.5%)]	Loss: 0.117135
Train Epoch: 2 [615424/8742050 (7.0%)]	Loss: 0.103633
Train Epoch: 2 [666624/8742050 (7.6%)]	Loss: 0.109468
Train Epoch: 2 [717824/8742050 (8.2%)]	Loss: 0.093999
Train Epoch: 2 [769024/8742050 (8.8%)]	Loss: 0.112991
Train Epoch: 2 [820224/8742050 (9.4%)]	Loss: 0.104670
Train Epoch: 2 [871424/8742050 (10.0%)]	Loss: 0.106198
Train Epoch: 2 [922624/8742050 (10.6%)]	Loss: 0.108244
Train Epoch: 2 [973824/8742050 (11.1%)]	Loss: 0.113695
Train Epoch: 2 [1025024/8742050 (11.7%)]	Loss: 0.122803
Train Epoch: 2 [1076224/8742050 (12.3%)]	Loss: 0.109679
Train Epoch: 2 [1127424/8742050 (12.9%)]	Loss: 0.100184
Train Epoch: 2 [1178624/8742050 (13.5%)]	Loss: 0.102154
Train Epoch: 2 [1229824/8742050 (14.1%)]	Loss: 0.115112
Train Epoch: 2 [1281024/8742050 (14.7%)]	Loss: 0.113936
Train Epoch: 2 [1332224/8742050 (15.2%)]	Loss: 0.112769
Train Epoch: 2 [1383424/8742050 (15.8%)]	Loss: 0.098837
Train Epoch: 2 [1434624/8742050 (16.4%)]	Loss: 0.103969
Train Epoch: 2 [1485824/8742050 (17.0%)]	Loss: 0.121482
Train Epoch: 2 [1537024/8742050 (17.6%)]	Loss: 0.101292
Train Epoch: 2 [1588224/8742050 (18.2%)]	Loss: 0.109850
Train Epoch: 2 [1639424/8742050 (18.8%)]	Loss: 0.112875
Train Epoch: 2 [1690624/8742050 (19.3%)]	Loss: 0.095847
Train Epoch: 2 [1741824/8742050 (19.9%)]	Loss: 0.102788
Train Epoch: 2 [1793024/8742050 (20.5%)]	Loss: 0.120551
Train Epoch: 2 [1844224/8742050 (21.1%)]	Loss: 0.124664
Train Epoch: 2 [1895424/8742050 (21.7%)]	Loss: 0.118745
Train Epoch: 2 [1946624/8742050 (22.3%)]	Loss: 0.104359
Train Epoch: 2 [1997824/8742050 (22.9%)]	Loss: 0.104631
Train Epoch: 2 [2049024/8742050 (23.4%)]	Loss: 0.111219
Train Epoch: 2 [2100224/8742050 (24.0%)]	Loss: 0.104874
Train Epoch: 2 [2151424/8742050 (24.6%)]	Loss: 0.104196
Train Epoch: 2 [2202624/8742050 (25.2%)]	Loss: 0.109456
Train Epoch: 2 [2253824/8742050 (25.8%)]	Loss: 0.099253
Train Epoch: 2 [2305024/8742050 (26.4%)]	Loss: 0.109825
Train Epoch: 2 [2356224/8742050 (27.0%)]	Loss: 0.110845
Train Epoch: 2 [2407424/8742050 (27.5%)]	Loss: 0.119351
Train Epoch: 2 [2458624/8742050 (28.1%)]	Loss: 0.104372
Train Epoch: 2 [2509824/8742050 (28.7%)]	Loss: 0.093301
Train Epoch: 2 [2561024/8742050 (29.3%)]	Loss: 0.104254
Train Epoch: 2 [2612224/8742050 (29.9%)]	Loss: 0.095123
Train Epoch: 2 [2663424/8742050 (30.5%)]	Loss: 0.110426
Train Epoch: 2 [2714624/8742050 (31.1%)]	Loss: 0.104509
Train Epoch: 2 [2765824/8742050 (31.6%)]	Loss: 0.115189
Train Epoch: 2 [2817024/8742050 (32.2%)]	Loss: 0.102685
Train Epoch: 2 [2868224/8742050 (32.8%)]	Loss: 0.097073
Train Epoch: 2 [2919424/8742050 (33.4%)]	Loss: 0.112446
Train Epoch: 2 [2970624/8742050 (34.0%)]	Loss: 0.112850
Train Epoch: 2 [3021824/8742050 (34.6%)]	Loss: 0.098159
Train Epoch: 2 [3073024/8742050 (35.2%)]	Loss: 0.101642
Train Epoch: 2 [3124224/8742050 (35.7%)]	Loss: 0.106026
Train Epoch: 2 [3175424/8742050 (36.3%)]	Loss: 0.113017
Train Epoch: 2 [3226624/8742050 (36.9%)]	Loss: 0.101447
Train Epoch: 2 [3277824/8742050 (37.5%)]	Loss: 0.100466
Train Epoch: 2 [3329024/8742050 (38.1%)]	Loss: 0.113708
Train Epoch: 2 [3380224/8742050 (38.7%)]	Loss: 0.098083
Train Epoch: 2 [3431424/8742050 (39.3%)]	Loss: 0.108775
Train Epoch: 2 [3482624/8742050 (39.8%)]	Loss: 0.106101
Train Epoch: 2 [3533824/8742050 (40.4%)]	Loss: 0.101381
Train Epoch: 2 [3585024/8742050 (41.0%)]	Loss: 0.094133
Train Epoch: 2 [3636224/8742050 (41.6%)]	Loss: 0.093675
Train Epoch: 2 [3687424/8742050 (42.2%)]	Loss: 0.096216
Train Epoch: 2 [3738624/8742050 (42.8%)]	Loss: 0.108554
Train Epoch: 2 [3789824/8742050 (43.4%)]	Loss: 0.097507
Train Epoch: 2 [3841024/8742050 (43.9%)]	Loss: 0.105686
Train Epoch: 2 [3892224/8742050 (44.5%)]	Loss: 0.105157
Train Epoch: 2 [3943424/8742050 (45.1%)]	Loss: 0.104875
Train Epoch: 2 [3994624/8742050 (45.7%)]	Loss: 0.113399
Train Epoch: 2 [4045824/8742050 (46.3%)]	Loss: 0.108525
Train Epoch: 2 [4097024/8742050 (46.9%)]	Loss: 0.108631
Train Epoch: 2 [4148224/8742050 (47.5%)]	Loss: 0.112042
Train Epoch: 2 [4199424/8742050 (48.0%)]	Loss: 0.111545
Train Epoch: 2 [4250624/8742050 (48.6%)]	Loss: 0.097680
Train Epoch: 2 [4301824/8742050 (49.2%)]	Loss: 0.109607
Train Epoch: 2 [4353024/8742050 (49.8%)]	Loss: 0.111318
Train Epoch: 2 [4404224/8742050 (50.4%)]	Loss: 0.114360
Train Epoch: 2 [4455424/8742050 (51.0%)]	Loss: 0.120516
Train Epoch: 2 [4506624/8742050 (51.6%)]	Loss: 0.105235
Train Epoch: 2 [4557824/8742050 (52.1%)]	Loss: 0.093370
Train Epoch: 2 [4609024/8742050 (52.7%)]	Loss: 0.116433
Train Epoch: 2 [4660224/8742050 (53.3%)]	Loss: 0.117492
Train Epoch: 2 [4711424/8742050 (53.9%)]	Loss: 0.114117
Train Epoch: 2 [4762624/8742050 (54.5%)]	Loss: 0.103445
Train Epoch: 2 [4813824/8742050 (55.1%)]	Loss: 0.102527
Train Epoch: 2 [4865024/8742050 (55.7%)]	Loss: 0.102636
Train Epoch: 2 [4916224/8742050 (56.2%)]	Loss: 0.105424
Train Epoch: 2 [4967424/8742050 (56.8%)]	Loss: 0.100429
Train Epoch: 2 [5018624/8742050 (57.4%)]	Loss: 0.098924
Train Epoch: 2 [5069824/8742050 (58.0%)]	Loss: 0.095710
Train Epoch: 2 [5121024/8742050 (58.6%)]	Loss: 0.100889
Train Epoch: 2 [5172224/8742050 (59.2%)]	Loss: 0.106401
Train Epoch: 2 [5223424/8742050 (59.8%)]	Loss: 0.099886
Train Epoch: 2 [5274624/8742050 (60.3%)]	Loss: 0.098539
Train Epoch: 2 [5325824/8742050 (60.9%)]	Loss: 0.112276
Train Epoch: 2 [5377024/8742050 (61.5%)]	Loss: 0.109063
Train Epoch: 2 [5428224/8742050 (62.1%)]	Loss: 0.110670
Train Epoch: 2 [5479424/8742050 (62.7%)]	Loss: 0.103127
Train Epoch: 2 [5530624/8742050 (63.3%)]	Loss: 0.119187
Train Epoch: 2 [5581824/8742050 (63.9%)]	Loss: 0.106643
Train Epoch: 2 [5633024/8742050 (64.4%)]	Loss: 0.102071
Train Epoch: 2 [5684224/8742050 (65.0%)]	Loss: 0.106321
Train Epoch: 2 [5735424/8742050 (65.6%)]	Loss: 0.121465
Train Epoch: 2 [5786624/8742050 (66.2%)]	Loss: 0.112650
Train Epoch: 2 [5837824/8742050 (66.8%)]	Loss: 0.097306
Train Epoch: 2 [5889024/8742050 (67.4%)]	Loss: 0.113994
Train Epoch: 2 [5940224/8742050 (68.0%)]	Loss: 0.109420
Train Epoch: 2 [5991424/8742050 (68.5%)]	Loss: 0.094354
Train Epoch: 2 [6042624/8742050 (69.1%)]	Loss: 0.098728
Train Epoch: 2 [6093824/8742050 (69.7%)]	Loss: 0.105832
Train Epoch: 2 [6145024/8742050 (70.3%)]	Loss: 0.125313
Train Epoch: 2 [6196224/8742050 (70.9%)]	Loss: 0.104407
Train Epoch: 2 [6247424/8742050 (71.5%)]	Loss: 0.107907
Train Epoch: 2 [6298624/8742050 (72.0%)]	Loss: 0.089993
Train Epoch: 2 [6349824/8742050 (72.6%)]	Loss: 0.113573
Train Epoch: 2 [6401024/8742050 (73.2%)]	Loss: 0.108710
Train Epoch: 2 [6452224/8742050 (73.8%)]	Loss: 0.112170
Train Epoch: 2 [6503424/8742050 (74.4%)]	Loss: 0.115288
Train Epoch: 2 [6554624/8742050 (75.0%)]	Loss: 0.112405
Train Epoch: 2 [6605824/8742050 (75.6%)]	Loss: 0.092715
Train Epoch: 2 [6657024/8742050 (76.1%)]	Loss: 0.106068
Train Epoch: 2 [6708224/8742050 (76.7%)]	Loss: 0.095568
Train Epoch: 2 [6759424/8742050 (77.3%)]	Loss: 0.108207
Train Epoch: 2 [6810624/8742050 (77.9%)]	Loss: 0.102970
Train Epoch: 2 [6861824/8742050 (78.5%)]	Loss: 0.106008
Train Epoch: 2 [6913024/8742050 (79.1%)]	Loss: 0.113449
Train Epoch: 2 [6964224/8742050 (79.7%)]	Loss: 0.103504
Train Epoch: 2 [7015424/8742050 (80.2%)]	Loss: 0.095605
Train Epoch: 2 [7066624/8742050 (80.8%)]	Loss: 0.107930
Train Epoch: 2 [7117824/8742050 (81.4%)]	Loss: 0.096870
Train Epoch: 2 [7169024/8742050 (82.0%)]	Loss: 0.110249
Train Epoch: 2 [7220224/8742050 (82.6%)]	Loss: 0.100155
Train Epoch: 2 [7271424/8742050 (83.2%)]	Loss: 0.109729
Train Epoch: 2 [7322624/8742050 (83.8%)]	Loss: 0.102547
Train Epoch: 2 [7373824/8742050 (84.3%)]	Loss: 0.101051
Train Epoch: 2 [7425024/8742050 (84.9%)]	Loss: 0.105763
Train Epoch: 2 [7476224/8742050 (85.5%)]	Loss: 0.103327
Train Epoch: 2 [7527424/8742050 (86.1%)]	Loss: 0.097159
Train Epoch: 2 [7578624/8742050 (86.7%)]	Loss: 0.102526
Train Epoch: 2 [7629824/8742050 (87.3%)]	Loss: 0.117873
Train Epoch: 2 [7681024/8742050 (87.9%)]	Loss: 0.099026
Train Epoch: 2 [7732224/8742050 (88.4%)]	Loss: 0.108184
Train Epoch: 2 [7783424/8742050 (89.0%)]	Loss: 0.099748
Train Epoch: 2 [7834624/8742050 (89.6%)]	Loss: 0.097332
Train Epoch: 2 [7885824/8742050 (90.2%)]	Loss: 0.133072
Train Epoch: 2 [7937024/8742050 (90.8%)]	Loss: 0.117091
Train Epoch: 2 [7988224/8742050 (91.4%)]	Loss: 0.120218
Train Epoch: 2 [8039424/8742050 (92.0%)]	Loss: 0.097172
Train Epoch: 2 [8090624/8742050 (92.5%)]	Loss: 0.113423
Train Epoch: 2 [8141824/8742050 (93.1%)]	Loss: 0.108880
Train Epoch: 2 [8193024/8742050 (93.7%)]	Loss: 0.106265
Train Epoch: 2 [8244224/8742050 (94.3%)]	Loss: 0.112006
Train Epoch: 2 [8295424/8742050 (94.9%)]	Loss: 0.088995
Train Epoch: 2 [8346624/8742050 (95.5%)]	Loss: 0.106960
Train Epoch: 2 [8397824/8742050 (96.1%)]	Loss: 0.114212
Train Epoch: 2 [8449024/8742050 (96.6%)]	Loss: 0.124984
Train Epoch: 2 [8500224/8742050 (97.2%)]	Loss: 0.103262
Train Epoch: 2 [8551424/8742050 (97.8%)]	Loss: 0.100217
Train Epoch: 2 [8602624/8742050 (98.4%)]	Loss: 0.103123
Train Epoch: 2 [8653824/8742050 (99.0%)]	Loss: 0.121783
Train Epoch: 2 [8705024/8742050 (99.6%)]	Loss: 0.105604

 ---------------------------------------------------------------------- 


ACC in fold#2 was 0.876


Confusion Matrix in fold#2: 
           nonRipple   Ripple
nonRipple     389578   263001
Ripple          8791  1524143


Classification Report in fold#2: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.978        0.853     0.876        0.915         0.890
recall            0.597        0.994     0.876        0.796         0.876
f1-score          0.741        0.918     0.876        0.830         0.865
sample size  652579.000  1532934.000     0.876  2185513.000   2185513.000


PR_AUC in fold#2 was 0.982


ROC_AUC in fold#2 was 0.965

Time (id:3): tot 11:28:39, prev 03:49:29 [hh:mm:ss]: 
i_fold=2 ends.



 ---------------------------------------------------------------------- 

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8742051 (0.0%)]	Loss: 0.379446
Train Epoch: 1 [52224/8742051 (0.6%)]	Loss: 0.162855
Train Epoch: 1 [103424/8742051 (1.2%)]	Loss: 0.141673
Train Epoch: 1 [154624/8742051 (1.8%)]	Loss: 0.107909
Train Epoch: 1 [205824/8742051 (2.4%)]	Loss: 0.114135
Train Epoch: 1 [257024/8742051 (2.9%)]	Loss: 0.129131
Train Epoch: 1 [308224/8742051 (3.5%)]	Loss: 0.125645
Train Epoch: 1 [359424/8742051 (4.1%)]	Loss: 0.108831
Train Epoch: 1 [410624/8742051 (4.7%)]	Loss: 0.098709
Train Epoch: 1 [461824/8742051 (5.3%)]	Loss: 0.118430
Train Epoch: 1 [513024/8742051 (5.9%)]	Loss: 0.116966
Train Epoch: 1 [564224/8742051 (6.5%)]	Loss: 0.132909
Train Epoch: 1 [615424/8742051 (7.0%)]	Loss: 0.123294
Train Epoch: 1 [666624/8742051 (7.6%)]	Loss: 0.111183
Train Epoch: 1 [717824/8742051 (8.2%)]	Loss: 0.119056
Train Epoch: 1 [769024/8742051 (8.8%)]	Loss: 0.118563
Train Epoch: 1 [820224/8742051 (9.4%)]	Loss: 0.122901
Train Epoch: 1 [871424/8742051 (10.0%)]	Loss: 0.141030
Train Epoch: 1 [922624/8742051 (10.6%)]	Loss: 0.115857
Train Epoch: 1 [973824/8742051 (11.1%)]	Loss: 0.096664
Train Epoch: 1 [1025024/8742051 (11.7%)]	Loss: 0.140167
Train Epoch: 1 [1076224/8742051 (12.3%)]	Loss: 0.114044
Train Epoch: 1 [1127424/8742051 (12.9%)]	Loss: 0.118913
Train Epoch: 1 [1178624/8742051 (13.5%)]	Loss: 0.115316
Train Epoch: 1 [1229824/8742051 (14.1%)]	Loss: 0.122770
Train Epoch: 1 [1281024/8742051 (14.7%)]	Loss: 0.124011
Train Epoch: 1 [1332224/8742051 (15.2%)]	Loss: 0.117535
Train Epoch: 1 [1383424/8742051 (15.8%)]	Loss: 0.108025
Train Epoch: 1 [1434624/8742051 (16.4%)]	Loss: 0.120868
Train Epoch: 1 [1485824/8742051 (17.0%)]	Loss: 0.112399
Train Epoch: 1 [1537024/8742051 (17.6%)]	Loss: 0.109305
Train Epoch: 1 [1588224/8742051 (18.2%)]	Loss: 0.114359
Train Epoch: 1 [1639424/8742051 (18.8%)]	Loss: 0.120786
Train Epoch: 1 [1690624/8742051 (19.3%)]	Loss: 0.112752
Train Epoch: 1 [1741824/8742051 (19.9%)]	Loss: 0.114847
Train Epoch: 1 [1793024/8742051 (20.5%)]	Loss: 0.106000
Train Epoch: 1 [1844224/8742051 (21.1%)]	Loss: 0.115824
Train Epoch: 1 [1895424/8742051 (21.7%)]	Loss: 0.116501
Train Epoch: 1 [1946624/8742051 (22.3%)]	Loss: 0.119692
Train Epoch: 1 [1997824/8742051 (22.9%)]	Loss: 0.116537
Train Epoch: 1 [2049024/8742051 (23.4%)]	Loss: 0.122620
Train Epoch: 1 [2100224/8742051 (24.0%)]	Loss: 0.111576
Train Epoch: 1 [2151424/8742051 (24.6%)]	Loss: 0.118878
Train Epoch: 1 [2202624/8742051 (25.2%)]	Loss: 0.115069
Train Epoch: 1 [2253824/8742051 (25.8%)]	Loss: 0.112660
Train Epoch: 1 [2305024/8742051 (26.4%)]	Loss: 0.124005
Train Epoch: 1 [2356224/8742051 (27.0%)]	Loss: 0.111945
Train Epoch: 1 [2407424/8742051 (27.5%)]	Loss: 0.104780
Train Epoch: 1 [2458624/8742051 (28.1%)]	Loss: 0.112131
Train Epoch: 1 [2509824/8742051 (28.7%)]	Loss: 0.112340
Train Epoch: 1 [2561024/8742051 (29.3%)]	Loss: 0.102739
Train Epoch: 1 [2612224/8742051 (29.9%)]	Loss: 0.110757
Train Epoch: 1 [2663424/8742051 (30.5%)]	Loss: 0.116899
Train Epoch: 1 [2714624/8742051 (31.1%)]	Loss: 0.111965
Train Epoch: 1 [2765824/8742051 (31.6%)]	Loss: 0.121758
Train Epoch: 1 [2817024/8742051 (32.2%)]	Loss: 0.108256
Train Epoch: 1 [2868224/8742051 (32.8%)]	Loss: 0.101135
Train Epoch: 1 [2919424/8742051 (33.4%)]	Loss: 0.121617
Train Epoch: 1 [2970624/8742051 (34.0%)]	Loss: 0.121898
Train Epoch: 1 [3021824/8742051 (34.6%)]	Loss: 0.112882
Train Epoch: 1 [3073024/8742051 (35.2%)]	Loss: 0.095031
Train Epoch: 1 [3124224/8742051 (35.7%)]	Loss: 0.110996
Train Epoch: 1 [3175424/8742051 (36.3%)]	Loss: 0.118561
Train Epoch: 1 [3226624/8742051 (36.9%)]	Loss: 0.106271
Train Epoch: 1 [3277824/8742051 (37.5%)]	Loss: 0.107312
Train Epoch: 1 [3329024/8742051 (38.1%)]	Loss: 0.120483
Train Epoch: 1 [3380224/8742051 (38.7%)]	Loss: 0.099479
Train Epoch: 1 [3431424/8742051 (39.3%)]	Loss: 0.113811
Train Epoch: 1 [3482624/8742051 (39.8%)]	Loss: 0.107864
Train Epoch: 1 [3533824/8742051 (40.4%)]	Loss: 0.105062
Train Epoch: 1 [3585024/8742051 (41.0%)]	Loss: 0.106375
Train Epoch: 1 [3636224/8742051 (41.6%)]	Loss: 0.102701
Train Epoch: 1 [3687424/8742051 (42.2%)]	Loss: 0.110652
Train Epoch: 1 [3738624/8742051 (42.8%)]	Loss: 0.109393
Train Epoch: 1 [3789824/8742051 (43.4%)]	Loss: 0.108963
Train Epoch: 1 [3841024/8742051 (43.9%)]	Loss: 0.115830
Train Epoch: 1 [3892224/8742051 (44.5%)]	Loss: 0.108909
Train Epoch: 1 [3943424/8742051 (45.1%)]	Loss: 0.112826
Train Epoch: 1 [3994624/8742051 (45.7%)]	Loss: 0.097219
Train Epoch: 1 [4045824/8742051 (46.3%)]	Loss: 0.099713
Train Epoch: 1 [4097024/8742051 (46.9%)]	Loss: 0.092169
Train Epoch: 1 [4148224/8742051 (47.5%)]	Loss: 0.117065
Train Epoch: 1 [4199424/8742051 (48.0%)]	Loss: 0.104526
Train Epoch: 1 [4250624/8742051 (48.6%)]	Loss: 0.117919
Train Epoch: 1 [4301824/8742051 (49.2%)]	Loss: 0.100907
Train Epoch: 1 [4353024/8742051 (49.8%)]	Loss: 0.099181
Train Epoch: 1 [4404224/8742051 (50.4%)]	Loss: 0.099668
Train Epoch: 1 [4455424/8742051 (51.0%)]	Loss: 0.113594
Train Epoch: 1 [4506624/8742051 (51.6%)]	Loss: 0.118497
Train Epoch: 1 [4557824/8742051 (52.1%)]	Loss: 0.107213
Train Epoch: 1 [4609024/8742051 (52.7%)]	Loss: 0.117474
Train Epoch: 1 [4660224/8742051 (53.3%)]	Loss: 0.115860
Train Epoch: 1 [4711424/8742051 (53.9%)]	Loss: 0.103543
Train Epoch: 1 [4762624/8742051 (54.5%)]	Loss: 0.117904
Train Epoch: 1 [4813824/8742051 (55.1%)]	Loss: 0.110746
Train Epoch: 1 [4865024/8742051 (55.7%)]	Loss: 0.106461
Train Epoch: 1 [4916224/8742051 (56.2%)]	Loss: 0.100749
Train Epoch: 1 [4967424/8742051 (56.8%)]	Loss: 0.108089
Train Epoch: 1 [5018624/8742051 (57.4%)]	Loss: 0.101706
Train Epoch: 1 [5069824/8742051 (58.0%)]	Loss: 0.116433
Train Epoch: 1 [5121024/8742051 (58.6%)]	Loss: 0.111213
Train Epoch: 1 [5172224/8742051 (59.2%)]	Loss: 0.110218
Train Epoch: 1 [5223424/8742051 (59.8%)]	Loss: 0.108738
Train Epoch: 1 [5274624/8742051 (60.3%)]	Loss: 0.113314
Train Epoch: 1 [5325824/8742051 (60.9%)]	Loss: 0.129524
Train Epoch: 1 [5377024/8742051 (61.5%)]	Loss: 0.086136
Train Epoch: 1 [5428224/8742051 (62.1%)]	Loss: 0.124584
Train Epoch: 1 [5479424/8742051 (62.7%)]	Loss: 0.100797
Train Epoch: 1 [5530624/8742051 (63.3%)]	Loss: 0.112214
Train Epoch: 1 [5581824/8742051 (63.9%)]	Loss: 0.110375
Train Epoch: 1 [5633024/8742051 (64.4%)]	Loss: 0.131736
Train Epoch: 1 [5684224/8742051 (65.0%)]	Loss: 0.099971
Train Epoch: 1 [5735424/8742051 (65.6%)]	Loss: 0.097944
Train Epoch: 1 [5786624/8742051 (66.2%)]	Loss: 0.102019
Train Epoch: 1 [5837824/8742051 (66.8%)]	Loss: 0.100688
Train Epoch: 1 [5889024/8742051 (67.4%)]	Loss: 0.118041
Train Epoch: 1 [5940224/8742051 (68.0%)]	Loss: 0.103806
Train Epoch: 1 [5991424/8742051 (68.5%)]	Loss: 0.100089
Train Epoch: 1 [6042624/8742051 (69.1%)]	Loss: 0.098852
Train Epoch: 1 [6093824/8742051 (69.7%)]	Loss: 0.107745
Train Epoch: 1 [6145024/8742051 (70.3%)]	Loss: 0.111917
Train Epoch: 1 [6196224/8742051 (70.9%)]	Loss: 0.121079
Train Epoch: 1 [6247424/8742051 (71.5%)]	Loss: 0.115147
Train Epoch: 1 [6298624/8742051 (72.0%)]	Loss: 0.121737
Train Epoch: 1 [6349824/8742051 (72.6%)]	Loss: 0.092622
Train Epoch: 1 [6401024/8742051 (73.2%)]	Loss: 0.120615
Train Epoch: 1 [6452224/8742051 (73.8%)]	Loss: 0.124879
Train Epoch: 1 [6503424/8742051 (74.4%)]	Loss: 0.103470
Train Epoch: 1 [6554624/8742051 (75.0%)]	Loss: 0.110400
Train Epoch: 1 [6605824/8742051 (75.6%)]	Loss: 0.103530
Train Epoch: 1 [6657024/8742051 (76.1%)]	Loss: 0.135295
Train Epoch: 1 [6708224/8742051 (76.7%)]	Loss: 0.098628
Train Epoch: 1 [6759424/8742051 (77.3%)]	Loss: 0.104148
Train Epoch: 1 [6810624/8742051 (77.9%)]	Loss: 0.110846
Train Epoch: 1 [6861824/8742051 (78.5%)]	Loss: 0.091918
Train Epoch: 1 [6913024/8742051 (79.1%)]	Loss: 0.111799
Train Epoch: 1 [6964224/8742051 (79.7%)]	Loss: 0.112167
Train Epoch: 1 [7015424/8742051 (80.2%)]	Loss: 0.113198
Train Epoch: 1 [7066624/8742051 (80.8%)]	Loss: 0.106676
Train Epoch: 1 [7117824/8742051 (81.4%)]	Loss: 0.118699
Train Epoch: 1 [7169024/8742051 (82.0%)]	Loss: 0.120274
Train Epoch: 1 [7220224/8742051 (82.6%)]	Loss: 0.112717
Train Epoch: 1 [7271424/8742051 (83.2%)]	Loss: 0.112292
Train Epoch: 1 [7322624/8742051 (83.8%)]	Loss: 0.107877
Train Epoch: 1 [7373824/8742051 (84.3%)]	Loss: 0.093364
Train Epoch: 1 [7425024/8742051 (84.9%)]	Loss: 0.123709
Train Epoch: 1 [7476224/8742051 (85.5%)]	Loss: 0.126702
Train Epoch: 1 [7527424/8742051 (86.1%)]	Loss: 0.107709
Train Epoch: 1 [7578624/8742051 (86.7%)]	Loss: 0.101990
Train Epoch: 1 [7629824/8742051 (87.3%)]	Loss: 0.101725
Train Epoch: 1 [7681024/8742051 (87.9%)]	Loss: 0.104737
Train Epoch: 1 [7732224/8742051 (88.4%)]	Loss: 0.118518
Train Epoch: 1 [7783424/8742051 (89.0%)]	Loss: 0.123327
Train Epoch: 1 [7834624/8742051 (89.6%)]	Loss: 0.107689
Train Epoch: 1 [7885824/8742051 (90.2%)]	Loss: 0.115161
Train Epoch: 1 [7937024/8742051 (90.8%)]	Loss: 0.120194
Train Epoch: 1 [7988224/8742051 (91.4%)]	Loss: 0.106209
Train Epoch: 1 [8039424/8742051 (92.0%)]	Loss: 0.110433
Train Epoch: 1 [8090624/8742051 (92.5%)]	Loss: 0.114792
Train Epoch: 1 [8141824/8742051 (93.1%)]	Loss: 0.106635
Train Epoch: 1 [8193024/8742051 (93.7%)]	Loss: 0.098118
Train Epoch: 1 [8244224/8742051 (94.3%)]	Loss: 0.103740
Train Epoch: 1 [8295424/8742051 (94.9%)]	Loss: 0.097337
Train Epoch: 1 [8346624/8742051 (95.5%)]	Loss: 0.101836
Train Epoch: 1 [8397824/8742051 (96.1%)]	Loss: 0.101778
Train Epoch: 1 [8449024/8742051 (96.6%)]	Loss: 0.119187
Train Epoch: 1 [8500224/8742051 (97.2%)]	Loss: 0.117790
Train Epoch: 1 [8551424/8742051 (97.8%)]	Loss: 0.107814
Train Epoch: 1 [8602624/8742051 (98.4%)]	Loss: 0.095983
Train Epoch: 1 [8653824/8742051 (99.0%)]	Loss: 0.106517
Train Epoch: 1 [8705024/8742051 (99.6%)]	Loss: 0.128489
Train Epoch: 2 [1024/8742051 (0.0%)]	Loss: 0.098089
Train Epoch: 2 [52224/8742051 (0.6%)]	Loss: 0.115668
Train Epoch: 2 [103424/8742051 (1.2%)]	Loss: 0.101047
Train Epoch: 2 [154624/8742051 (1.8%)]	Loss: 0.112712
Train Epoch: 2 [205824/8742051 (2.4%)]	Loss: 0.102630
Train Epoch: 2 [257024/8742051 (2.9%)]	Loss: 0.096210
Train Epoch: 2 [308224/8742051 (3.5%)]	Loss: 0.107191
Train Epoch: 2 [359424/8742051 (4.1%)]	Loss: 0.098898
Train Epoch: 2 [410624/8742051 (4.7%)]	Loss: 0.110584
Train Epoch: 2 [461824/8742051 (5.3%)]	Loss: 0.111267
Train Epoch: 2 [513024/8742051 (5.9%)]	Loss: 0.126485
Train Epoch: 2 [564224/8742051 (6.5%)]	Loss: 0.116085
Train Epoch: 2 [615424/8742051 (7.0%)]	Loss: 0.112749
Train Epoch: 2 [666624/8742051 (7.6%)]	Loss: 0.106717
Train Epoch: 2 [717824/8742051 (8.2%)]	Loss: 0.117390
Train Epoch: 2 [769024/8742051 (8.8%)]	Loss: 0.120096
Train Epoch: 2 [820224/8742051 (9.4%)]	Loss: 0.104097
Train Epoch: 2 [871424/8742051 (10.0%)]	Loss: 0.112462
Train Epoch: 2 [922624/8742051 (10.6%)]	Loss: 0.083480
Train Epoch: 2 [973824/8742051 (11.1%)]	Loss: 0.096660
Train Epoch: 2 [1025024/8742051 (11.7%)]	Loss: 0.105697
Train Epoch: 2 [1076224/8742051 (12.3%)]	Loss: 0.105064
Train Epoch: 2 [1127424/8742051 (12.9%)]	Loss: 0.106831
Train Epoch: 2 [1178624/8742051 (13.5%)]	Loss: 0.101408
Train Epoch: 2 [1229824/8742051 (14.1%)]	Loss: 0.105965
Train Epoch: 2 [1281024/8742051 (14.7%)]	Loss: 0.113075
Train Epoch: 2 [1332224/8742051 (15.2%)]	Loss: 0.111295
Train Epoch: 2 [1383424/8742051 (15.8%)]	Loss: 0.108191
Train Epoch: 2 [1434624/8742051 (16.4%)]	Loss: 0.095478
Train Epoch: 2 [1485824/8742051 (17.0%)]	Loss: 0.115140
Train Epoch: 2 [1537024/8742051 (17.6%)]	Loss: 0.119765
Train Epoch: 2 [1588224/8742051 (18.2%)]	Loss: 0.103416
Train Epoch: 2 [1639424/8742051 (18.8%)]	Loss: 0.100829
Train Epoch: 2 [1690624/8742051 (19.3%)]	Loss: 0.097270
Train Epoch: 2 [1741824/8742051 (19.9%)]	Loss: 0.096031
Train Epoch: 2 [1793024/8742051 (20.5%)]	Loss: 0.109910
Train Epoch: 2 [1844224/8742051 (21.1%)]	Loss: 0.116207
Train Epoch: 2 [1895424/8742051 (21.7%)]	Loss: 0.095159
Train Epoch: 2 [1946624/8742051 (22.3%)]	Loss: 0.112089
Train Epoch: 2 [1997824/8742051 (22.9%)]	Loss: 0.107533
Train Epoch: 2 [2049024/8742051 (23.4%)]	Loss: 0.109590
Train Epoch: 2 [2100224/8742051 (24.0%)]	Loss: 0.109631
Train Epoch: 2 [2151424/8742051 (24.6%)]	Loss: 0.109312
Train Epoch: 2 [2202624/8742051 (25.2%)]	Loss: 0.102677
Train Epoch: 2 [2253824/8742051 (25.8%)]	Loss: 0.102726
Train Epoch: 2 [2305024/8742051 (26.4%)]	Loss: 0.105199
Train Epoch: 2 [2356224/8742051 (27.0%)]	Loss: 0.109113
Train Epoch: 2 [2407424/8742051 (27.5%)]	Loss: 0.109456
Train Epoch: 2 [2458624/8742051 (28.1%)]	Loss: 0.101861
Train Epoch: 2 [2509824/8742051 (28.7%)]	Loss: 0.102158
Train Epoch: 2 [2561024/8742051 (29.3%)]	Loss: 0.102897
Train Epoch: 2 [2612224/8742051 (29.9%)]	Loss: 0.095998
Train Epoch: 2 [2663424/8742051 (30.5%)]	Loss: 0.106310
Train Epoch: 2 [2714624/8742051 (31.1%)]	Loss: 0.107395
Train Epoch: 2 [2765824/8742051 (31.6%)]	Loss: 0.105143
Train Epoch: 2 [2817024/8742051 (32.2%)]	Loss: 0.123716
Train Epoch: 2 [2868224/8742051 (32.8%)]	Loss: 0.112786
Train Epoch: 2 [2919424/8742051 (33.4%)]	Loss: 0.117979
Train Epoch: 2 [2970624/8742051 (34.0%)]	Loss: 0.096550
Train Epoch: 2 [3021824/8742051 (34.6%)]	Loss: 0.108030
Train Epoch: 2 [3073024/8742051 (35.2%)]	Loss: 0.110385
Train Epoch: 2 [3124224/8742051 (35.7%)]	Loss: 0.112392
Train Epoch: 2 [3175424/8742051 (36.3%)]	Loss: 0.098343
Train Epoch: 2 [3226624/8742051 (36.9%)]	Loss: 0.107984
Train Epoch: 2 [3277824/8742051 (37.5%)]	Loss: 0.107360
Train Epoch: 2 [3329024/8742051 (38.1%)]	Loss: 0.122437
Train Epoch: 2 [3380224/8742051 (38.7%)]	Loss: 0.110865
Train Epoch: 2 [3431424/8742051 (39.3%)]	Loss: 0.101256
Train Epoch: 2 [3482624/8742051 (39.8%)]	Loss: 0.095309
Train Epoch: 2 [3533824/8742051 (40.4%)]	Loss: 0.105486
Train Epoch: 2 [3585024/8742051 (41.0%)]	Loss: 0.112420
Train Epoch: 2 [3636224/8742051 (41.6%)]	Loss: 0.099989
Train Epoch: 2 [3687424/8742051 (42.2%)]	Loss: 0.116390
Train Epoch: 2 [3738624/8742051 (42.8%)]	Loss: 0.108991
Train Epoch: 2 [3789824/8742051 (43.4%)]	Loss: 0.129757
Train Epoch: 2 [3841024/8742051 (43.9%)]	Loss: 0.116944
Train Epoch: 2 [3892224/8742051 (44.5%)]	Loss: 0.112235
Train Epoch: 2 [3943424/8742051 (45.1%)]	Loss: 0.102931
Train Epoch: 2 [3994624/8742051 (45.7%)]	Loss: 0.117525
Train Epoch: 2 [4045824/8742051 (46.3%)]	Loss: 0.097832
Train Epoch: 2 [4097024/8742051 (46.9%)]	Loss: 0.095354
Train Epoch: 2 [4148224/8742051 (47.5%)]	Loss: 0.111927
Train Epoch: 2 [4199424/8742051 (48.0%)]	Loss: 0.103526
Train Epoch: 2 [4250624/8742051 (48.6%)]	Loss: 0.108479
Train Epoch: 2 [4301824/8742051 (49.2%)]	Loss: 0.103704
Train Epoch: 2 [4353024/8742051 (49.8%)]	Loss: 0.101202
Train Epoch: 2 [4404224/8742051 (50.4%)]	Loss: 0.102323
Train Epoch: 2 [4455424/8742051 (51.0%)]	Loss: 0.110383
Train Epoch: 2 [4506624/8742051 (51.6%)]	Loss: 0.113711
Train Epoch: 2 [4557824/8742051 (52.1%)]	Loss: 0.120722
Train Epoch: 2 [4609024/8742051 (52.7%)]	Loss: 0.106532
Train Epoch: 2 [4660224/8742051 (53.3%)]	Loss: 0.127891
Train Epoch: 2 [4711424/8742051 (53.9%)]	Loss: 0.104382
Train Epoch: 2 [4762624/8742051 (54.5%)]	Loss: 0.101944
Train Epoch: 2 [4813824/8742051 (55.1%)]	Loss: 0.107037
Train Epoch: 2 [4865024/8742051 (55.7%)]	Loss: 0.097240
Train Epoch: 2 [4916224/8742051 (56.2%)]	Loss: 0.103494
Train Epoch: 2 [4967424/8742051 (56.8%)]	Loss: 0.104537
Train Epoch: 2 [5018624/8742051 (57.4%)]	Loss: 0.095118
Train Epoch: 2 [5069824/8742051 (58.0%)]	Loss: 0.107384
Train Epoch: 2 [5121024/8742051 (58.6%)]	Loss: 0.103878
Train Epoch: 2 [5172224/8742051 (59.2%)]	Loss: 0.114270
Train Epoch: 2 [5223424/8742051 (59.8%)]	Loss: 0.106596
Train Epoch: 2 [5274624/8742051 (60.3%)]	Loss: 0.117960
Train Epoch: 2 [5325824/8742051 (60.9%)]	Loss: 0.100721
Train Epoch: 2 [5377024/8742051 (61.5%)]	Loss: 0.100826
Train Epoch: 2 [5428224/8742051 (62.1%)]	Loss: 0.108511
Train Epoch: 2 [5479424/8742051 (62.7%)]	Loss: 0.090086
Train Epoch: 2 [5530624/8742051 (63.3%)]	Loss: 0.110740
Train Epoch: 2 [5581824/8742051 (63.9%)]	Loss: 0.101658
Train Epoch: 2 [5633024/8742051 (64.4%)]	Loss: 0.108481
Train Epoch: 2 [5684224/8742051 (65.0%)]	Loss: 0.095914
Train Epoch: 2 [5735424/8742051 (65.6%)]	Loss: 0.117426
Train Epoch: 2 [5786624/8742051 (66.2%)]	Loss: 0.105436
Train Epoch: 2 [5837824/8742051 (66.8%)]	Loss: 0.117177
Train Epoch: 2 [5889024/8742051 (67.4%)]	Loss: 0.104986
Train Epoch: 2 [5940224/8742051 (68.0%)]	Loss: 0.106007
Train Epoch: 2 [5991424/8742051 (68.5%)]	Loss: 0.119892
Train Epoch: 2 [6042624/8742051 (69.1%)]	Loss: 0.092416
Train Epoch: 2 [6093824/8742051 (69.7%)]	Loss: 0.094045
Train Epoch: 2 [6145024/8742051 (70.3%)]	Loss: 0.115624
Train Epoch: 2 [6196224/8742051 (70.9%)]	Loss: 0.103425
Train Epoch: 2 [6247424/8742051 (71.5%)]	Loss: 0.104097
Train Epoch: 2 [6298624/8742051 (72.0%)]	Loss: 0.116434
Train Epoch: 2 [6349824/8742051 (72.6%)]	Loss: 0.095370
Train Epoch: 2 [6401024/8742051 (73.2%)]	Loss: 0.112483
Train Epoch: 2 [6452224/8742051 (73.8%)]	Loss: 0.093366
Train Epoch: 2 [6503424/8742051 (74.4%)]	Loss: 0.114783
Train Epoch: 2 [6554624/8742051 (75.0%)]	Loss: 0.114126
Train Epoch: 2 [6605824/8742051 (75.6%)]	Loss: 0.107284
Train Epoch: 2 [6657024/8742051 (76.1%)]	Loss: 0.097737
Train Epoch: 2 [6708224/8742051 (76.7%)]	Loss: 0.119444
Train Epoch: 2 [6759424/8742051 (77.3%)]	Loss: 0.103370
Train Epoch: 2 [6810624/8742051 (77.9%)]	Loss: 0.109616
Train Epoch: 2 [6861824/8742051 (78.5%)]	Loss: 0.114094
Train Epoch: 2 [6913024/8742051 (79.1%)]	Loss: 0.112482
Train Epoch: 2 [6964224/8742051 (79.7%)]	Loss: 0.094730
Train Epoch: 2 [7015424/8742051 (80.2%)]	Loss: 0.106542
Train Epoch: 2 [7066624/8742051 (80.8%)]	Loss: 0.105432
Train Epoch: 2 [7117824/8742051 (81.4%)]	Loss: 0.094620
Train Epoch: 2 [7169024/8742051 (82.0%)]	Loss: 0.112384
Train Epoch: 2 [7220224/8742051 (82.6%)]	Loss: 0.100198
Train Epoch: 2 [7271424/8742051 (83.2%)]	Loss: 0.101764
Train Epoch: 2 [7322624/8742051 (83.8%)]	Loss: 0.111421
Train Epoch: 2 [7373824/8742051 (84.3%)]	Loss: 0.108267
Train Epoch: 2 [7425024/8742051 (84.9%)]	Loss: 0.092473
Train Epoch: 2 [7476224/8742051 (85.5%)]	Loss: 0.109356
Train Epoch: 2 [7527424/8742051 (86.1%)]	Loss: 0.111484
Train Epoch: 2 [7578624/8742051 (86.7%)]	Loss: 0.099849
Train Epoch: 2 [7629824/8742051 (87.3%)]	Loss: 0.103842
Train Epoch: 2 [7681024/8742051 (87.9%)]	Loss: 0.128109
Train Epoch: 2 [7732224/8742051 (88.4%)]	Loss: 0.104423
Train Epoch: 2 [7783424/8742051 (89.0%)]	Loss: 0.103048
Train Epoch: 2 [7834624/8742051 (89.6%)]	Loss: 0.105398
Train Epoch: 2 [7885824/8742051 (90.2%)]	Loss: 0.101056
Train Epoch: 2 [7937024/8742051 (90.8%)]	Loss: 0.115971
Train Epoch: 2 [7988224/8742051 (91.4%)]	Loss: 0.109042
Train Epoch: 2 [8039424/8742051 (92.0%)]	Loss: 0.102805
Train Epoch: 2 [8090624/8742051 (92.5%)]	Loss: 0.117201
Train Epoch: 2 [8141824/8742051 (93.1%)]	Loss: 0.109686
Train Epoch: 2 [8193024/8742051 (93.7%)]	Loss: 0.112375
Train Epoch: 2 [8244224/8742051 (94.3%)]	Loss: 0.099935
Train Epoch: 2 [8295424/8742051 (94.9%)]	Loss: 0.100923
Train Epoch: 2 [8346624/8742051 (95.5%)]	Loss: 0.097788
Train Epoch: 2 [8397824/8742051 (96.1%)]	Loss: 0.118407
Train Epoch: 2 [8449024/8742051 (96.6%)]	Loss: 0.111252
Train Epoch: 2 [8500224/8742051 (97.2%)]	Loss: 0.102099
Train Epoch: 2 [8551424/8742051 (97.8%)]	Loss: 0.096924
Train Epoch: 2 [8602624/8742051 (98.4%)]	Loss: 0.125386
Train Epoch: 2 [8653824/8742051 (99.0%)]	Loss: 0.105165
Train Epoch: 2 [8705024/8742051 (99.6%)]	Loss: 0.099631

 ---------------------------------------------------------------------- 


ACC in fold#3 was 0.895


Confusion Matrix in fold#3: 
           nonRipple   Ripple
nonRipple     500462   152116
Ripple         78336  1454598


Classification Report in fold#3: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.865        0.905     0.895        0.885         0.893
recall            0.767        0.949     0.895        0.858         0.895
f1-score          0.813        0.927     0.895        0.870         0.893
sample size  652578.000  1532934.000     0.895  2185512.000   2185512.000


PR_AUC in fold#3 was 0.975


ROC_AUC in fold#3 was 0.948

Time (id:4): tot 15:15:42, prev 03:47:03 [hh:mm:ss]: 
i_fold=3 ends.



 ---------------------------------------------------------------------- 

Ranger optimizer loaded. 
Gradient Centralization usage = True
GC applied to both conv and fc layers
Train Epoch: 1 [1024/8742051 (0.0%)]	Loss: 0.362756
Train Epoch: 1 [52224/8742051 (0.6%)]	Loss: 0.169604
Train Epoch: 1 [103424/8742051 (1.2%)]	Loss: 0.137387
Train Epoch: 1 [154624/8742051 (1.8%)]	Loss: 0.116532
Train Epoch: 1 [205824/8742051 (2.4%)]	Loss: 0.128658
Train Epoch: 1 [257024/8742051 (2.9%)]	Loss: 0.118346
Train Epoch: 1 [308224/8742051 (3.5%)]	Loss: 0.125599
Train Epoch: 1 [359424/8742051 (4.1%)]	Loss: 0.105487
Train Epoch: 1 [410624/8742051 (4.7%)]	Loss: 0.130580
Train Epoch: 1 [461824/8742051 (5.3%)]	Loss: 0.109802
Train Epoch: 1 [513024/8742051 (5.9%)]	Loss: 0.103875
Train Epoch: 1 [564224/8742051 (6.5%)]	Loss: 0.101956
Train Epoch: 1 [615424/8742051 (7.0%)]	Loss: 0.131093
Train Epoch: 1 [666624/8742051 (7.6%)]	Loss: 0.128547
Train Epoch: 1 [717824/8742051 (8.2%)]	Loss: 0.108031
Train Epoch: 1 [769024/8742051 (8.8%)]	Loss: 0.129453
Train Epoch: 1 [820224/8742051 (9.4%)]	Loss: 0.120018
Train Epoch: 1 [871424/8742051 (10.0%)]	Loss: 0.128587
Train Epoch: 1 [922624/8742051 (10.6%)]	Loss: 0.124195
Train Epoch: 1 [973824/8742051 (11.1%)]	Loss: 0.114683
Train Epoch: 1 [1025024/8742051 (11.7%)]	Loss: 0.121849
Train Epoch: 1 [1076224/8742051 (12.3%)]	Loss: 0.124229
Train Epoch: 1 [1127424/8742051 (12.9%)]	Loss: 0.115262
Train Epoch: 1 [1178624/8742051 (13.5%)]	Loss: 0.122565
Train Epoch: 1 [1229824/8742051 (14.1%)]	Loss: 0.108503
Train Epoch: 1 [1281024/8742051 (14.7%)]	Loss: 0.119989
Train Epoch: 1 [1332224/8742051 (15.2%)]	Loss: 0.103438
Train Epoch: 1 [1383424/8742051 (15.8%)]	Loss: 0.104858
Train Epoch: 1 [1434624/8742051 (16.4%)]	Loss: 0.112154
Train Epoch: 1 [1485824/8742051 (17.0%)]	Loss: 0.107188
Train Epoch: 1 [1537024/8742051 (17.6%)]	Loss: 0.118828
Train Epoch: 1 [1588224/8742051 (18.2%)]	Loss: 0.113929
Train Epoch: 1 [1639424/8742051 (18.8%)]	Loss: 0.120341
Train Epoch: 1 [1690624/8742051 (19.3%)]	Loss: 0.110306
Train Epoch: 1 [1741824/8742051 (19.9%)]	Loss: 0.106014
Train Epoch: 1 [1793024/8742051 (20.5%)]	Loss: 0.110459
Train Epoch: 1 [1844224/8742051 (21.1%)]	Loss: 0.117555
Train Epoch: 1 [1895424/8742051 (21.7%)]	Loss: 0.108784
Train Epoch: 1 [1946624/8742051 (22.3%)]	Loss: 0.123053
Train Epoch: 1 [1997824/8742051 (22.9%)]	Loss: 0.106645
Train Epoch: 1 [2049024/8742051 (23.4%)]	Loss: 0.104765
Train Epoch: 1 [2100224/8742051 (24.0%)]	Loss: 0.111224
Train Epoch: 1 [2151424/8742051 (24.6%)]	Loss: 0.123127
Train Epoch: 1 [2202624/8742051 (25.2%)]	Loss: 0.121289
Train Epoch: 1 [2253824/8742051 (25.8%)]	Loss: 0.115591
Train Epoch: 1 [2305024/8742051 (26.4%)]	Loss: 0.119565
Train Epoch: 1 [2356224/8742051 (27.0%)]	Loss: 0.140811
Train Epoch: 1 [2407424/8742051 (27.5%)]	Loss: 0.122955
Train Epoch: 1 [2458624/8742051 (28.1%)]	Loss: 0.108437
Train Epoch: 1 [2509824/8742051 (28.7%)]	Loss: 0.109874
Train Epoch: 1 [2561024/8742051 (29.3%)]	Loss: 0.131800
Train Epoch: 1 [2612224/8742051 (29.9%)]	Loss: 0.104778
Train Epoch: 1 [2663424/8742051 (30.5%)]	Loss: 0.096854
Train Epoch: 1 [2714624/8742051 (31.1%)]	Loss: 0.119914
Train Epoch: 1 [2765824/8742051 (31.6%)]	Loss: 0.128622
Train Epoch: 1 [2817024/8742051 (32.2%)]	Loss: 0.113588
Train Epoch: 1 [2868224/8742051 (32.8%)]	Loss: 0.100709
Train Epoch: 1 [2919424/8742051 (33.4%)]	Loss: 0.114405
Train Epoch: 1 [2970624/8742051 (34.0%)]	Loss: 0.116479
Train Epoch: 1 [3021824/8742051 (34.6%)]	Loss: 0.104794
Train Epoch: 1 [3073024/8742051 (35.2%)]	Loss: 0.123576
Train Epoch: 1 [3124224/8742051 (35.7%)]	Loss: 0.118547
Train Epoch: 1 [3175424/8742051 (36.3%)]	Loss: 0.099942
Train Epoch: 1 [3226624/8742051 (36.9%)]	Loss: 0.115025
Train Epoch: 1 [3277824/8742051 (37.5%)]	Loss: 0.120734
Train Epoch: 1 [3329024/8742051 (38.1%)]	Loss: 0.117282
Train Epoch: 1 [3380224/8742051 (38.7%)]	Loss: 0.105980
Train Epoch: 1 [3431424/8742051 (39.3%)]	Loss: 0.104024
Train Epoch: 1 [3482624/8742051 (39.8%)]	Loss: 0.106780
Train Epoch: 1 [3533824/8742051 (40.4%)]	Loss: 0.111263
Train Epoch: 1 [3585024/8742051 (41.0%)]	Loss: 0.092779
Train Epoch: 1 [3636224/8742051 (41.6%)]	Loss: 0.115260
Train Epoch: 1 [3687424/8742051 (42.2%)]	Loss: 0.109830
Train Epoch: 1 [3738624/8742051 (42.8%)]	Loss: 0.101821
Train Epoch: 1 [3789824/8742051 (43.4%)]	Loss: 0.113078
Train Epoch: 1 [3841024/8742051 (43.9%)]	Loss: 0.112613
Train Epoch: 1 [3892224/8742051 (44.5%)]	Loss: 0.108956
Train Epoch: 1 [3943424/8742051 (45.1%)]	Loss: 0.108022
Train Epoch: 1 [3994624/8742051 (45.7%)]	Loss: 0.107489
Train Epoch: 1 [4045824/8742051 (46.3%)]	Loss: 0.119868
Train Epoch: 1 [4097024/8742051 (46.9%)]	Loss: 0.135862
Train Epoch: 1 [4148224/8742051 (47.5%)]	Loss: 0.110994
Train Epoch: 1 [4199424/8742051 (48.0%)]	Loss: 0.111422
Train Epoch: 1 [4250624/8742051 (48.6%)]	Loss: 0.112822
Train Epoch: 1 [4301824/8742051 (49.2%)]	Loss: 0.114609
Train Epoch: 1 [4353024/8742051 (49.8%)]	Loss: 0.112366
Train Epoch: 1 [4404224/8742051 (50.4%)]	Loss: 0.117040
Train Epoch: 1 [4455424/8742051 (51.0%)]	Loss: 0.113667
Train Epoch: 1 [4506624/8742051 (51.6%)]	Loss: 0.107187
Train Epoch: 1 [4557824/8742051 (52.1%)]	Loss: 0.120749
Train Epoch: 1 [4609024/8742051 (52.7%)]	Loss: 0.107920
Train Epoch: 1 [4660224/8742051 (53.3%)]	Loss: 0.130846
Train Epoch: 1 [4711424/8742051 (53.9%)]	Loss: 0.113707
Train Epoch: 1 [4762624/8742051 (54.5%)]	Loss: 0.106904
Train Epoch: 1 [4813824/8742051 (55.1%)]	Loss: 0.099033
Train Epoch: 1 [4865024/8742051 (55.7%)]	Loss: 0.104870
Train Epoch: 1 [4916224/8742051 (56.2%)]	Loss: 0.110159
Train Epoch: 1 [4967424/8742051 (56.8%)]	Loss: 0.115931
Train Epoch: 1 [5018624/8742051 (57.4%)]	Loss: 0.103395
Train Epoch: 1 [5069824/8742051 (58.0%)]	Loss: 0.108287
Train Epoch: 1 [5121024/8742051 (58.6%)]	Loss: 0.120893
Train Epoch: 1 [5172224/8742051 (59.2%)]	Loss: 0.098966
Train Epoch: 1 [5223424/8742051 (59.8%)]	Loss: 0.103632
Train Epoch: 1 [5274624/8742051 (60.3%)]	Loss: 0.098927
Train Epoch: 1 [5325824/8742051 (60.9%)]	Loss: 0.112485
Train Epoch: 1 [5377024/8742051 (61.5%)]	Loss: 0.126228
Train Epoch: 1 [5428224/8742051 (62.1%)]	Loss: 0.100072
Train Epoch: 1 [5479424/8742051 (62.7%)]	Loss: 0.117794
Train Epoch: 1 [5530624/8742051 (63.3%)]	Loss: 0.103531
Train Epoch: 1 [5581824/8742051 (63.9%)]	Loss: 0.107044
Train Epoch: 1 [5633024/8742051 (64.4%)]	Loss: 0.106443
Train Epoch: 1 [5684224/8742051 (65.0%)]	Loss: 0.102200
Train Epoch: 1 [5735424/8742051 (65.6%)]	Loss: 0.113797
Train Epoch: 1 [5786624/8742051 (66.2%)]	Loss: 0.099309
Train Epoch: 1 [5837824/8742051 (66.8%)]	Loss: 0.103683
Train Epoch: 1 [5889024/8742051 (67.4%)]	Loss: 0.100370
Train Epoch: 1 [5940224/8742051 (68.0%)]	Loss: 0.114682
Train Epoch: 1 [5991424/8742051 (68.5%)]	Loss: 0.106465
Train Epoch: 1 [6042624/8742051 (69.1%)]	Loss: 0.120773
Train Epoch: 1 [6093824/8742051 (69.7%)]	Loss: 0.113331
Train Epoch: 1 [6145024/8742051 (70.3%)]	Loss: 0.123132
Train Epoch: 1 [6196224/8742051 (70.9%)]	Loss: 0.112436
Train Epoch: 1 [6247424/8742051 (71.5%)]	Loss: 0.107859
Train Epoch: 1 [6298624/8742051 (72.0%)]	Loss: 0.109131
Train Epoch: 1 [6349824/8742051 (72.6%)]	Loss: 0.112496
Train Epoch: 1 [6401024/8742051 (73.2%)]	Loss: 0.113538
Train Epoch: 1 [6452224/8742051 (73.8%)]	Loss: 0.109318
Train Epoch: 1 [6503424/8742051 (74.4%)]	Loss: 0.119930
Train Epoch: 1 [6554624/8742051 (75.0%)]	Loss: 0.116739
Train Epoch: 1 [6605824/8742051 (75.6%)]	Loss: 0.110838
Train Epoch: 1 [6657024/8742051 (76.1%)]	Loss: 0.108037
Train Epoch: 1 [6708224/8742051 (76.7%)]	Loss: 0.118030
Train Epoch: 1 [6759424/8742051 (77.3%)]	Loss: 0.113309
Train Epoch: 1 [6810624/8742051 (77.9%)]	Loss: 0.107579
Train Epoch: 1 [6861824/8742051 (78.5%)]	Loss: 0.113480
Train Epoch: 1 [6913024/8742051 (79.1%)]	Loss: 0.102768
Train Epoch: 1 [6964224/8742051 (79.7%)]	Loss: 0.123459
Train Epoch: 1 [7015424/8742051 (80.2%)]	Loss: 0.118550
Train Epoch: 1 [7066624/8742051 (80.8%)]	Loss: 0.117647
Train Epoch: 1 [7117824/8742051 (81.4%)]	Loss: 0.097296
Train Epoch: 1 [7169024/8742051 (82.0%)]	Loss: 0.109433
Train Epoch: 1 [7220224/8742051 (82.6%)]	Loss: 0.102494
Train Epoch: 1 [7271424/8742051 (83.2%)]	Loss: 0.103127
Train Epoch: 1 [7322624/8742051 (83.8%)]	Loss: 0.112018
Train Epoch: 1 [7373824/8742051 (84.3%)]	Loss: 0.111339
Train Epoch: 1 [7425024/8742051 (84.9%)]	Loss: 0.103021
Train Epoch: 1 [7476224/8742051 (85.5%)]	Loss: 0.112661
Train Epoch: 1 [7527424/8742051 (86.1%)]	Loss: 0.109081
Train Epoch: 1 [7578624/8742051 (86.7%)]	Loss: 0.116775
Train Epoch: 1 [7629824/8742051 (87.3%)]	Loss: 0.097211
Train Epoch: 1 [7681024/8742051 (87.9%)]	Loss: 0.129066
Train Epoch: 1 [7732224/8742051 (88.4%)]	Loss: 0.118441
Train Epoch: 1 [7783424/8742051 (89.0%)]	Loss: 0.109770
Train Epoch: 1 [7834624/8742051 (89.6%)]	Loss: 0.106888
Train Epoch: 1 [7885824/8742051 (90.2%)]	Loss: 0.102537
Train Epoch: 1 [7937024/8742051 (90.8%)]	Loss: 0.118441
Train Epoch: 1 [7988224/8742051 (91.4%)]	Loss: 0.109127
Train Epoch: 1 [8039424/8742051 (92.0%)]	Loss: 0.121276
Train Epoch: 1 [8090624/8742051 (92.5%)]	Loss: 0.117505
Train Epoch: 1 [8141824/8742051 (93.1%)]	Loss: 0.109872
Train Epoch: 1 [8193024/8742051 (93.7%)]	Loss: 0.116406
Train Epoch: 1 [8244224/8742051 (94.3%)]	Loss: 0.105391
Train Epoch: 1 [8295424/8742051 (94.9%)]	Loss: 0.103793
Train Epoch: 1 [8346624/8742051 (95.5%)]	Loss: 0.098064
Train Epoch: 1 [8397824/8742051 (96.1%)]	Loss: 0.106241
Train Epoch: 1 [8449024/8742051 (96.6%)]	Loss: 0.103197
Train Epoch: 1 [8500224/8742051 (97.2%)]	Loss: 0.108270
Train Epoch: 1 [8551424/8742051 (97.8%)]	Loss: 0.112910
Train Epoch: 1 [8602624/8742051 (98.4%)]	Loss: 0.099119
Train Epoch: 1 [8653824/8742051 (99.0%)]	Loss: 0.098120
Train Epoch: 1 [8705024/8742051 (99.6%)]	Loss: 0.109529
Train Epoch: 2 [1024/8742051 (0.0%)]	Loss: 0.110410
Train Epoch: 2 [52224/8742051 (0.6%)]	Loss: 0.099647
Train Epoch: 2 [103424/8742051 (1.2%)]	Loss: 0.117188
Train Epoch: 2 [154624/8742051 (1.8%)]	Loss: 0.097954
Train Epoch: 2 [205824/8742051 (2.4%)]	Loss: 0.102589
Train Epoch: 2 [257024/8742051 (2.9%)]	Loss: 0.106103
Train Epoch: 2 [308224/8742051 (3.5%)]	Loss: 0.115833
Train Epoch: 2 [359424/8742051 (4.1%)]	Loss: 0.128239
Train Epoch: 2 [410624/8742051 (4.7%)]	Loss: 0.102271
Train Epoch: 2 [461824/8742051 (5.3%)]	Loss: 0.102520
Train Epoch: 2 [513024/8742051 (5.9%)]	Loss: 0.124293
Train Epoch: 2 [564224/8742051 (6.5%)]	Loss: 0.107838
Train Epoch: 2 [615424/8742051 (7.0%)]	Loss: 0.108626
Train Epoch: 2 [666624/8742051 (7.6%)]	Loss: 0.114077
Train Epoch: 2 [717824/8742051 (8.2%)]	Loss: 0.118101
Train Epoch: 2 [769024/8742051 (8.8%)]	Loss: 0.121972
Train Epoch: 2 [820224/8742051 (9.4%)]	Loss: 0.102866
Train Epoch: 2 [871424/8742051 (10.0%)]	Loss: 0.121976
Train Epoch: 2 [922624/8742051 (10.6%)]	Loss: 0.100303
Train Epoch: 2 [973824/8742051 (11.1%)]	Loss: 0.104852
Train Epoch: 2 [1025024/8742051 (11.7%)]	Loss: 0.108955
Train Epoch: 2 [1076224/8742051 (12.3%)]	Loss: 0.106934
Train Epoch: 2 [1127424/8742051 (12.9%)]	Loss: 0.110229
Train Epoch: 2 [1178624/8742051 (13.5%)]	Loss: 0.111657
Train Epoch: 2 [1229824/8742051 (14.1%)]	Loss: 0.101290
Train Epoch: 2 [1281024/8742051 (14.7%)]	Loss: 0.119598
Train Epoch: 2 [1332224/8742051 (15.2%)]	Loss: 0.104958
Train Epoch: 2 [1383424/8742051 (15.8%)]	Loss: 0.120496
Train Epoch: 2 [1434624/8742051 (16.4%)]	Loss: 0.121019
Train Epoch: 2 [1485824/8742051 (17.0%)]	Loss: 0.105048
Train Epoch: 2 [1537024/8742051 (17.6%)]	Loss: 0.106636
Train Epoch: 2 [1588224/8742051 (18.2%)]	Loss: 0.121049
Train Epoch: 2 [1639424/8742051 (18.8%)]	Loss: 0.103761
Train Epoch: 2 [1690624/8742051 (19.3%)]	Loss: 0.125745
Train Epoch: 2 [1741824/8742051 (19.9%)]	Loss: 0.101187
Train Epoch: 2 [1793024/8742051 (20.5%)]	Loss: 0.099505
Train Epoch: 2 [1844224/8742051 (21.1%)]	Loss: 0.110662
Train Epoch: 2 [1895424/8742051 (21.7%)]	Loss: 0.099465
Train Epoch: 2 [1946624/8742051 (22.3%)]	Loss: 0.102466
Train Epoch: 2 [1997824/8742051 (22.9%)]	Loss: 0.104512
Train Epoch: 2 [2049024/8742051 (23.4%)]	Loss: 0.110253
Train Epoch: 2 [2100224/8742051 (24.0%)]	Loss: 0.106972
Train Epoch: 2 [2151424/8742051 (24.6%)]	Loss: 0.110349
Train Epoch: 2 [2202624/8742051 (25.2%)]	Loss: 0.107288
Train Epoch: 2 [2253824/8742051 (25.8%)]	Loss: 0.111535
Train Epoch: 2 [2305024/8742051 (26.4%)]	Loss: 0.117340
Train Epoch: 2 [2356224/8742051 (27.0%)]	Loss: 0.103138
Train Epoch: 2 [2407424/8742051 (27.5%)]	Loss: 0.118698
Train Epoch: 2 [2458624/8742051 (28.1%)]	Loss: 0.111350
Train Epoch: 2 [2509824/8742051 (28.7%)]	Loss: 0.104921
Train Epoch: 2 [2561024/8742051 (29.3%)]	Loss: 0.094852
Train Epoch: 2 [2612224/8742051 (29.9%)]	Loss: 0.105375
Train Epoch: 2 [2663424/8742051 (30.5%)]	Loss: 0.106040
Train Epoch: 2 [2714624/8742051 (31.1%)]	Loss: 0.124940
Train Epoch: 2 [2765824/8742051 (31.6%)]	Loss: 0.107608
Train Epoch: 2 [2817024/8742051 (32.2%)]	Loss: 0.106398
Train Epoch: 2 [2868224/8742051 (32.8%)]	Loss: 0.096248
Train Epoch: 2 [2919424/8742051 (33.4%)]	Loss: 0.104366
Train Epoch: 2 [2970624/8742051 (34.0%)]	Loss: 0.103916
Train Epoch: 2 [3021824/8742051 (34.6%)]	Loss: 0.112699
Train Epoch: 2 [3073024/8742051 (35.2%)]	Loss: 0.101713
Train Epoch: 2 [3124224/8742051 (35.7%)]	Loss: 0.113099
Train Epoch: 2 [3175424/8742051 (36.3%)]	Loss: 0.101233
Train Epoch: 2 [3226624/8742051 (36.9%)]	Loss: 0.106443
Train Epoch: 2 [3277824/8742051 (37.5%)]	Loss: 0.119672
Train Epoch: 2 [3329024/8742051 (38.1%)]	Loss: 0.122022
Train Epoch: 2 [3380224/8742051 (38.7%)]	Loss: 0.108317
Train Epoch: 2 [3431424/8742051 (39.3%)]	Loss: 0.103099
Train Epoch: 2 [3482624/8742051 (39.8%)]	Loss: 0.103563
Train Epoch: 2 [3533824/8742051 (40.4%)]	Loss: 0.112221
Train Epoch: 2 [3585024/8742051 (41.0%)]	Loss: 0.118561
Train Epoch: 2 [3636224/8742051 (41.6%)]	Loss: 0.096706
Train Epoch: 2 [3687424/8742051 (42.2%)]	Loss: 0.112888
Train Epoch: 2 [3738624/8742051 (42.8%)]	Loss: 0.110672
Train Epoch: 2 [3789824/8742051 (43.4%)]	Loss: 0.096296
Train Epoch: 2 [3841024/8742051 (43.9%)]	Loss: 0.097965
Train Epoch: 2 [3892224/8742051 (44.5%)]	Loss: 0.104309
Train Epoch: 2 [3943424/8742051 (45.1%)]	Loss: 0.101278
Train Epoch: 2 [3994624/8742051 (45.7%)]	Loss: 0.126422
Train Epoch: 2 [4045824/8742051 (46.3%)]	Loss: 0.089591
Train Epoch: 2 [4097024/8742051 (46.9%)]	Loss: 0.108610
Train Epoch: 2 [4148224/8742051 (47.5%)]	Loss: 0.099098
Train Epoch: 2 [4199424/8742051 (48.0%)]	Loss: 0.099332
Train Epoch: 2 [4250624/8742051 (48.6%)]	Loss: 0.113440
Train Epoch: 2 [4301824/8742051 (49.2%)]	Loss: 0.108334
Train Epoch: 2 [4353024/8742051 (49.8%)]	Loss: 0.115720
Train Epoch: 2 [4404224/8742051 (50.4%)]	Loss: 0.110751
Train Epoch: 2 [4455424/8742051 (51.0%)]	Loss: 0.118316
Train Epoch: 2 [4506624/8742051 (51.6%)]	Loss: 0.116448
Train Epoch: 2 [4557824/8742051 (52.1%)]	Loss: 0.113529
Train Epoch: 2 [4609024/8742051 (52.7%)]	Loss: 0.120649
Train Epoch: 2 [4660224/8742051 (53.3%)]	Loss: 0.113202
Train Epoch: 2 [4711424/8742051 (53.9%)]	Loss: 0.106603
Train Epoch: 2 [4762624/8742051 (54.5%)]	Loss: 0.094042
Train Epoch: 2 [4813824/8742051 (55.1%)]	Loss: 0.099308
Train Epoch: 2 [4865024/8742051 (55.7%)]	Loss: 0.104052
Train Epoch: 2 [4916224/8742051 (56.2%)]	Loss: 0.095488
Train Epoch: 2 [4967424/8742051 (56.8%)]	Loss: 0.107807
Train Epoch: 2 [5018624/8742051 (57.4%)]	Loss: 0.109082
Train Epoch: 2 [5069824/8742051 (58.0%)]	Loss: 0.125167
Train Epoch: 2 [5121024/8742051 (58.6%)]	Loss: 0.114556
Train Epoch: 2 [5172224/8742051 (59.2%)]	Loss: 0.109440
Train Epoch: 2 [5223424/8742051 (59.8%)]	Loss: 0.111544
Train Epoch: 2 [5274624/8742051 (60.3%)]	Loss: 0.107094
Train Epoch: 2 [5325824/8742051 (60.9%)]	Loss: 0.098572
Train Epoch: 2 [5377024/8742051 (61.5%)]	Loss: 0.101592
Train Epoch: 2 [5428224/8742051 (62.1%)]	Loss: 0.101788
Train Epoch: 2 [5479424/8742051 (62.7%)]	Loss: 0.097950
Train Epoch: 2 [5530624/8742051 (63.3%)]	Loss: 0.093909
Train Epoch: 2 [5581824/8742051 (63.9%)]	Loss: 0.101490
Train Epoch: 2 [5633024/8742051 (64.4%)]	Loss: 0.112255
Train Epoch: 2 [5684224/8742051 (65.0%)]	Loss: 0.103449
Train Epoch: 2 [5735424/8742051 (65.6%)]	Loss: 0.104403
Train Epoch: 2 [5786624/8742051 (66.2%)]	Loss: 0.105993
Train Epoch: 2 [5837824/8742051 (66.8%)]	Loss: 0.108743
Train Epoch: 2 [5889024/8742051 (67.4%)]	Loss: 0.104850
Train Epoch: 2 [5940224/8742051 (68.0%)]	Loss: 0.115211
Train Epoch: 2 [5991424/8742051 (68.5%)]	Loss: 0.098216
Train Epoch: 2 [6042624/8742051 (69.1%)]	Loss: 0.107468
Train Epoch: 2 [6093824/8742051 (69.7%)]	Loss: 0.102120
Train Epoch: 2 [6145024/8742051 (70.3%)]	Loss: 0.105933
Train Epoch: 2 [6196224/8742051 (70.9%)]	Loss: 0.087802
Train Epoch: 2 [6247424/8742051 (71.5%)]	Loss: 0.096911
Train Epoch: 2 [6298624/8742051 (72.0%)]	Loss: 0.102061
Train Epoch: 2 [6349824/8742051 (72.6%)]	Loss: 0.106370
Train Epoch: 2 [6401024/8742051 (73.2%)]	Loss: 0.110907
Train Epoch: 2 [6452224/8742051 (73.8%)]	Loss: 0.100818
Train Epoch: 2 [6503424/8742051 (74.4%)]	Loss: 0.114042
Train Epoch: 2 [6554624/8742051 (75.0%)]	Loss: 0.111654
Train Epoch: 2 [6605824/8742051 (75.6%)]	Loss: 0.105268
Train Epoch: 2 [6657024/8742051 (76.1%)]	Loss: 0.113123
Train Epoch: 2 [6708224/8742051 (76.7%)]	Loss: 0.105166
Train Epoch: 2 [6759424/8742051 (77.3%)]	Loss: 0.095764
Train Epoch: 2 [6810624/8742051 (77.9%)]	Loss: 0.116639
Train Epoch: 2 [6861824/8742051 (78.5%)]	Loss: 0.108392
Train Epoch: 2 [6913024/8742051 (79.1%)]	Loss: 0.110291
Train Epoch: 2 [6964224/8742051 (79.7%)]	Loss: 0.095411
Train Epoch: 2 [7015424/8742051 (80.2%)]	Loss: 0.108169
Train Epoch: 2 [7066624/8742051 (80.8%)]	Loss: 0.095594
Train Epoch: 2 [7117824/8742051 (81.4%)]	Loss: 0.116037
Train Epoch: 2 [7169024/8742051 (82.0%)]	Loss: 0.113357
Train Epoch: 2 [7220224/8742051 (82.6%)]	Loss: 0.113037
Train Epoch: 2 [7271424/8742051 (83.2%)]	Loss: 0.115950
Train Epoch: 2 [7322624/8742051 (83.8%)]	Loss: 0.106528
Train Epoch: 2 [7373824/8742051 (84.3%)]	Loss: 0.107557
Train Epoch: 2 [7425024/8742051 (84.9%)]	Loss: 0.089209
Train Epoch: 2 [7476224/8742051 (85.5%)]	Loss: 0.096168
Train Epoch: 2 [7527424/8742051 (86.1%)]	Loss: 0.115108
Train Epoch: 2 [7578624/8742051 (86.7%)]	Loss: 0.104934
Train Epoch: 2 [7629824/8742051 (87.3%)]	Loss: 0.115583
Train Epoch: 2 [7681024/8742051 (87.9%)]	Loss: 0.107146
Train Epoch: 2 [7732224/8742051 (88.4%)]	Loss: 0.102042
Train Epoch: 2 [7783424/8742051 (89.0%)]	Loss: 0.113982
Train Epoch: 2 [7834624/8742051 (89.6%)]	Loss: 0.095214
Train Epoch: 2 [7885824/8742051 (90.2%)]	Loss: 0.108764
Train Epoch: 2 [7937024/8742051 (90.8%)]	Loss: 0.107713
Train Epoch: 2 [7988224/8742051 (91.4%)]	Loss: 0.107926
Train Epoch: 2 [8039424/8742051 (92.0%)]	Loss: 0.101095
Train Epoch: 2 [8090624/8742051 (92.5%)]	Loss: 0.103485
Train Epoch: 2 [8141824/8742051 (93.1%)]	Loss: 0.097156
Train Epoch: 2 [8193024/8742051 (93.7%)]	Loss: 0.101048
Train Epoch: 2 [8244224/8742051 (94.3%)]	Loss: 0.111616
Train Epoch: 2 [8295424/8742051 (94.9%)]	Loss: 0.103098
Train Epoch: 2 [8346624/8742051 (95.5%)]	Loss: 0.114392
Train Epoch: 2 [8397824/8742051 (96.1%)]	Loss: 0.111762
Train Epoch: 2 [8449024/8742051 (96.6%)]	Loss: 0.117805
Train Epoch: 2 [8500224/8742051 (97.2%)]	Loss: 0.100013
Train Epoch: 2 [8551424/8742051 (97.8%)]	Loss: 0.099275
Train Epoch: 2 [8602624/8742051 (98.4%)]	Loss: 0.109129
Train Epoch: 2 [8653824/8742051 (99.0%)]	Loss: 0.100895
Train Epoch: 2 [8705024/8742051 (99.6%)]	Loss: 0.108670

 ---------------------------------------------------------------------- 


ACC in fold#4 was 0.895


Confusion Matrix in fold#4: 
           nonRipple   Ripple
nonRipple     598959    53620
Ripple        175982  1356951


Classification Report in fold#4: 
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.773        0.962     0.895        0.867         0.906
recall            0.918        0.885     0.895        0.902         0.895
f1-score          0.839        0.922     0.895        0.881         0.897
sample size  652579.000  1532933.000     0.895  2185512.000   2185512.000


PR_AUC in fold#4 was 0.981


ROC_AUC in fold#4 was 0.966

Time (id:5): tot 19:02:35, prev 03:46:52 [hh:mm:ss]: 
i_fold=4 ends.



 ---------------------------------------------------------------------- 


Label Errors Rate:
0.030


 --- 5-fold CV overall metrics --- 


Confusion Matrix (Test; sum; num. folds=5)
           nonRipple   Ripple
nonRipple    2428756   834138
Ripple        311415  7353254


Classification Report (Test; mean; num. folds=5)
              nonRipple       Ripple  accuracy    macro avg  weighted avg
precision         0.904        0.901     0.895        0.902         0.902
recall            0.744        0.959     0.895        0.852         0.895
f1-score          0.806        0.928     0.895        0.867         0.892
sample size  652578.800  1532933.800     0.895  2185512.600   2185512.600


Classification Report (Test; std; num. folds=5)
             nonRipple  Ripple  accuracy  macro avg  weighted avg
precision        0.076   0.035     0.011      0.023         0.009
recall           0.104   0.040     0.011      0.034         0.011
f1-score         0.034   0.007     0.011      0.019         0.014
sample size      0.400   0.400     0.011      0.490         0.490


PRE-REC AUC Score: 0.978 +/- 0.003 (mean +/- std.; n=5)


ROC AUC Score: 0.959 +/- 0.007 (mean +/- std.; n=5)


Saved to: ./data/okada/cleanlab_results/D05-/are_errors.npy


Saved to: ./data/okada/cleanlab_results/D05-/cleaned_labels.npy


Saved to: ./data/okada/cleanlab_results/D05-/pred_probas_ripples.npy

(Moved to: /tmp/2021-0516-1729-D05--conf_mats.csv)
Saved to: ./data/okada/cleanlab_results/D05-/conf_mats.csv
Saved to: ./data/okada/cleanlab_results/D05-/conf_mat_overall_sum.png
(Moved to: /tmp/2021-0516-1729-D05--clf_reports.csv)
Saved to: ./data/okada/cleanlab_results/D05-/clf_reports.csv
(Moved to: /tmp/2021-0516-1729-D05--roc-auc.csv)
Saved to: ./data/okada/cleanlab_results/D05-/roc-auc.csv

Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/01/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/02/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/02/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/02/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/02/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/03/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/03/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/03/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/03/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-1_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-2_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-3_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt2-4_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-1_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-2_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-3_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt6-4_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/04/day1/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/04/day2/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/04/day3/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-1_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-2_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-3_fp16.pkl


Saved to: ./data/okada/04/day4/split/ripples_1kHz_pkl/CNN_labeled/D05-/tt7-4_fp16.pkl

